[["From Vocoders to Code-Excited Linear Prediction: Learning How We Hear What We Hear.", ["Bishnu S. Atal"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/4001.html", 1], ["Semi-Supervised End-to-End Speech Recognition.", ["Shigeki Karita", "Shinji Watanabe", "Tomoharu Iwata", "Atsunori Ogawa", "Marc Delcroix"], "https://doi.org/10.21437/Interspeech.2018-1746", 5], ["Improved Training of End-to-end Attention Models for Speech Recognition.", ["Albert Zeyer", "Kazuki Irie", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2018-1616", 5], ["End-to-end Speech Recognition Using Lattice-free MMI.", ["Hossein Hadian", "Hossein Sameti", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1423", 5], ["Multi-channel Attention for End-to-End Speech Recognition.", ["Stefan Braun", "Daniel Neil", "Jithendar Anumula", "Enea Ceolini", "Shih-Chii Liu"], "https://doi.org/10.21437/Interspeech.2018-1301", 5], ["Quaternion Convolutional Neural Networks for End-to-End Automatic Speech Recognition.", ["Titouan Parcollet", "Ying Zhang", "Mohamed Morchid", "Chiheb Trabelsi", "Georges Linares", "Renato de Mori", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2018-1898", 5], ["Compression of End-to-End Models.", ["Ruoming Pang", "Tara N. Sainath", "Rohit Prabhavalkar", "Suyog Gupta", "Yonghui Wu", "Shuyuan Zhang", "Chung-Cheng Chiu"], "https://doi.org/10.21437/Interspeech.2018-1025", 5], ["Learning Interpretable Control Dimensions for Speech Synthesis by Using External Data.", ["Zack Hodari", "Oliver Watts", "Srikanth Ronanki", "Simon King"], "https://doi.org/10.21437/Interspeech.2018-2075", 5], ["Investigating Accuracy of Pitch-accent Annotations in Neural Network-based Speech Synthesis and Denoising Effects.", ["Hieu-Thi Luong", "Xin Wang", "Junichi Yamagishi", "Nobuyuki Nishizawa"], "https://doi.org/10.21437/Interspeech.2018-1227", 5], ["An Exploration of Local Speaking Rate Variations in Mandarin Read Speech.", ["Guan-Ting Liou", "Chen-Yu Chiang", "Yih-Ru Wang", "Sin-Horng Chen"], "https://doi.org/10.21437/Interspeech.2018-1214", 5], ["BLSTM-CRF Based End-to-End Prosodic Boundary Prediction with Context Sensitive Embeddings in a Text-to-Speech Front-End.", ["Yibin Zheng", "Jianhua Tao", "Zhengqi Wen", "Ya Li"], "https://doi.org/10.21437/Interspeech.2018-1472", 5], ["Wavelet Analysis of Speaker Dependent and Independent Prosody for Voice Conversion.", ["Berrak Sisman", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2018-1499", 5], ["Improving Mongolian Phrase Break Prediction by Using Syllable and Morphological Embeddings with BiLSTM Model.", ["Rui Liu", "Feilong Bao", "Guanglai Gao", "Hui Zhang", "Yonghe Wang"], "https://doi.org/10.21437/Interspeech.2018-1706", 5], ["Improved Supervised Locality Preserving Projection for I-vector Based Speaker Verification.", ["Lanhua You", "Wu Guo", "Yan Song", "Sheng Zhang"], "https://doi.org/10.21437/Interspeech.2018-41", 5], ["Double Joint Bayesian Modeling of DNN Local I-Vector for Text Dependent Speaker Verification with Random Digit Strings.", ["Ziqiang Shi", "Huibin Lin", "Liu Liu", "Rujie Liu"], "https://doi.org/10.21437/Interspeech.2018-1103", 5], ["Fast Variational Bayes for Heavy-tailed PLDA Applied to i-vectors and x-vectors.", ["Anna Silnova", "Niko Brummer", "Daniel Garcia-Romero", "David Snyder", "Lukas Burget"], "https://doi.org/10.21437/Interspeech.2018-2128", 5], ["Integrated Presentation Attack Detection and Automatic Speaker Verification: Common Features and Gaussian Back-end Fusion.", ["Massimiliano Todisco", "Hector Delgado", "Kong-Aik Lee", "Md. Sahidullah", "Nicholas W. D. Evans", "Tomi Kinnunen", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2018-2289", 5], ["A Generalization of PLDA for Joint Modeling of Speaker Identity and Multiple Nuisance Conditions.", ["Luciana Ferrer", "Mitchell McLaren"], "https://doi.org/10.21437/Interspeech.2018-1280", 5], ["An Investigation of Non-linear i-vectors for Speaker Verification.", ["Nanxin Chen", "Jesus Villalba", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2474", 5], ["CNN Based Query by Example Spoken Term Detection.", ["Dhananjay Ram", "Lesly Miculicich Werlen", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2018-1722", 5], ["Learning Acoustic Word Embeddings with Temporal Context for Query-by-Example Speech Search.", ["Yougen Yuan", "Cheung-Chi Leung", "Lei Xie", "Hongjie Chen", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2018-1010", 5], ["Siamese Recurrent Auto-Encoder Representation for Query-by-Example Spoken Term Detection.", ["Ziwei Zhu", "Zhiyong Wu", "Runnan Li", "Helen Meng", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2018-1788", 5], ["Fast Derivation of Cross-lingual Document Vectors from Self-attentive Neural Machine Translation Model.", ["Wei Li", "Brian Mak"], "https://doi.org/10.21437/Interspeech.2018-1459", 5], ["LSTM Based Attentive Fusion of Spectral and Prosodic Information for Keyword Spotting in Hindi Language.", ["Laxmi Pandey", "Karan Nathwani"], "https://doi.org/10.21437/Interspeech.2018-1016", 5], ["Spoken Keyword Detection Using Joint DTW-CNN.", ["Ravi Shankar", "Vikram C. M.", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2018-1436", 5], ["The INTERSPEECH 2018 Computational Paralinguistics Challenge: Atypical & Self-Assessed Affect, Crying & Heart Beats.", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Peter B. Marschik", "Harald Baumeister", "Fengquan Dong", "Simone Hantke", "Florian B. Pokorny", "Eva-Maria Rathner", "Katrin D. Bartl-Pokorny", "Christa Einspieler", "Dajie Zhang", "Alice Baird", "Shahin Amiriparian", "Kun Qian", "Zhao Ren", "Maximilian Schmitt", "Panagiotis Tzirakis", "Stefanos Zafeiriou"], "https://doi.org/10.21437/Interspeech.2018-51", 5], ["An Ensemble of Transfer, Semi-supervised and Supervised Learning Methods for Pathological Heart Sound Classification.", ["Ahmed Imtiaz Humayun", "Md. Tauhiduzzaman Khan", "Shabnam Ghaffarzadegan", "Zhe Feng", "Taufiq Hasan"], "https://doi.org/10.21437/Interspeech.2018-2413", 5], ["Monitoring Infant's Emotional Cry in Domestic Environments Using the Capsule Network Architecture.", ["Mehmet Ali Tugtekin Turan", "Engin Erzin"], "https://doi.org/10.21437/Interspeech.2018-2187", 5], ["Neural Network Architecture That Combines Temporal and Summative Features for Infant Cry Classification in the Interspeech 2018 Computational Paralinguistics Challenge.", ["Mark Huckvale"], "https://doi.org/10.21437/Interspeech.2018-1959", 5], ["Evolving Learning for Analysing Mood-Related Infant Vocalisation.", ["Zixing Zhang", "Jing Han", "Kun Qian", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1914", 5], ["Deep Learning in Paralinguistic Recognition Tasks: Are Hand-crafted Features Still Relevant?", ["Johannes Wagner", "Dominik Schiller", "Andreas Seiderer", "Elisabeth Andre"], "https://doi.org/10.21437/Interspeech.2018-1238", 5], ["Investigation on Joint Representation Learning for Robust Feature Extraction in Speech Emotion Recognition.", ["Danqing Luo", "Yuexian Zou", "Dongyan Huang"], "https://doi.org/10.21437/Interspeech.2018-1832", 5], ["Using Voice Quality Supervectors for Affect Identification.", ["Soo Jin Park", "Amber Afshan", "Zhi Ming Chua", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2018-1401", 5], ["An End-to-End Deep Learning Framework for Speech Emotion Recognition of Atypical Individuals.", ["Dengke Tang", "Junlin Zeng", "Ming Li"], "https://doi.org/10.21437/Interspeech.2018-2581", 5], ["DialogOS: Simple and Extensible Dialogue Modeling.", ["Alexander Koller", "Timo Baumann", "Arne Kohn"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3002.html", 2], ["A Framework for Speech Recognition Benchmarking.", ["Franck Dernoncourt", "Trung Bui", "Walter Chang"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3003.html", 2], ["Flexible Tongue Housed in a Static Model of the Vocal Tract With Jaws, Lips and Teeth.", ["Takayuki Arai"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3004.html", 2], ["Voice Analysis Using Acoustic and Throat Microphones for Speech Therapy.", ["Lani Mathew", "K. Gopakumar"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3005.html", 2], ["A Robust Context-Dependent Speech-to-Speech Phraselator Toolkit for Alexa.", ["Manny Rayner", "Nikos Tsourakis", "Jan Stanek"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3006.html", 2], ["Discriminating Nasals and Approximants in English Language Using Zero Time Windowing.", ["RaviShankar Prasad", "Sudarsana Reddy Kadiri", "Suryakanth V. Gangashetty", "Bayya Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2018-1032", 5], ["Gestural Lenition of Rhotics Captures Variation in Brazilian Portuguese.", ["Phil Howson", "Alexei Kochetov"], "https://doi.org/10.21437/Interspeech.2018-1404", 5], ["Identification and Classification of Fricatives in Speech Using Zero Time Windowing Method.", ["RaviShankar Prasad", "Bayya Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2018-1958", 5], ["GlobalTIMIT: Acoustic-Phonetic Datasets for the World's Languages.", ["Nattanun Chanchaochai", "Christopher Cieri", "Japhet Debrah", "Hongwei Ding", "Yue Jiang", "Sishi Liao", "Mark Liberman", "Jonathan Wright", "Jiahong Yuan", "Juhong Zhan", "Yuqing Zhan"], "https://doi.org/10.21437/Interspeech.2018-1185", 5], ["Structural Effects on Properties of Consonantal Gestures in Tashlhiyt.", ["Anne Hermes", "Doris Mucke", "Bastian Auris", "Rachid Ridouane"], "https://doi.org/10.21437/Interspeech.2018-1074", 5], ["The Retroflex-dental Contrast in Punjabi Stops and Nasals: A Principal Component Analysis of Ultrasound Images.", ["Alexei Kochetov", "Matthew Faytak", "Kiranpreet Nara"], "https://doi.org/10.21437/Interspeech.2018-1457", 5], ["Vowels and Diphthongs in Hangzhou Wu Chinese Dialect.", ["Yang Yue", "Fang Hu"], "https://doi.org/10.21437/Interspeech.2018-1225", 5], ["Resyllabification in Indian Languages and Its Implications in Text-to-speech Systems.", ["Mahesh M", "Jeena J. Prakash", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2018-1176", 5], ["Voice Source Contribution to Prominence Perception: Rd Implementation.", ["Andy Murphy", "Irena Yanushevskaya", "Ailbhe Ni Chasaide", "Christer Gobl"], "https://doi.org/10.21437/Interspeech.2018-2352", 5], ["On the Relationship between Glottal Pulse Shape and Its Spectrum: Correlations of Open Quotient, Pulse Skew and Peak Flow with Source Harmonic Amplitudes.", ["Christer Gobl", "Andy Murphy", "Irena Yanushevskaya", "Ailbhe Ni Chasaide"], "https://doi.org/10.21437/Interspeech.2018-2532", 5], ["The Individual and the System: Assessing the Stability of the Output of a Semi-automatic Forensic Voice Comparison System.", ["Vincent Hughes", "Philip Harrison", "Paul Foulkes", "Peter French", "Colleen Kavanagh", "Eugenia San Segundo Fernandez"], "https://doi.org/10.21437/Interspeech.2018-1649", 5], ["Breathy to Tense Voice Discrimination using Zero-Time Windowing Cepstral Coefficients (ZTWCCs).", ["Sudarsana Reddy Kadiri", "Bayya Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2018-2498", 5], ["Analysis of Breathiness in Contextual Vowel of Voiceless Nasals in Mizo.", ["Pamir Gogoi", "Sishir Kalita", "Parismita Gogoi", "Ratree Wayland", "Priyankoo Sarmah", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2018-1899", 5], ["Infant Emotional Outbursts Detection in Infant-parent Spoken Interactions.", ["Yijia Xu", "Mark Hasegawa-Johnson", "Nancy McElwain"], "https://doi.org/10.21437/Interspeech.2018-2429", 5], ["Deep Neural Networks for Emotion Recognition Combining Audio and Transcripts.", ["Jaejin Cho", "Raghavendra Pappagari", "Purva Kulkarni", "Jesus Villalba", "Yishay Carmiel", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2466", 5], ["Preference-Learning with Qualitative Agreement for Sentence Level Emotional Annotations.", ["Srinivas Parthasarathy", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2018-2478", 5], ["Transfer Learning for Improving Speech Emotion Classification Accuracy.", ["Siddique Latif", "Rajib Rana", "Shahzad Younis", "Junaid Qadir", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2018-1625", 5], ["What Do Classifiers Actually Learn? a Case Study on Emotion Recognition Datasets.", ["Patrick Meyer", "Eric Buschermohle", "Tim Fingscheidt"], "https://doi.org/10.21437/Interspeech.2018-1851", 5], ["State of Mind: Classification through Self-reported Affect and Word Use in Speech.", ["Eva-Maria Rathner", "Yannik Terhorst", "Nicholas Cummins", "Bjorn W. Schuller", "Harald Baumeister"], "https://doi.org/10.21437/Interspeech.2018-2043", 5], ["Exploring Spatio-Temporal Representations by Integrating Attention-based Bidirectional-LSTM-RNNs and FCNs for Speech Emotion Recognition.", ["Ziping Zhao", "Yu Zheng", "Zixing Zhang", "Haishuai Wang", "Yiqin Zhao", "Chao Li"], "https://doi.org/10.21437/Interspeech.2018-1477", 5], ["End-to-end Deep Neural Network Age Estimation.", ["Pegah Ghahremani", "Phani Sankar Nidadavolu", "Nanxin Chen", "Jesus Villalba", "Daniel Povey", "Sanjeev Khudanpur", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2015", 5], ["Improving Gender Identification in Movie Audio Using Cross-Domain Data.", ["Rajat Hebbar", "Krishna Somandepalli", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1462", 5], ["On Learning to Identify Genders from Raw Speech Signal Using CNNs.", ["Selen Hande Kabil", "Hannah Muckenhirn", "Mathew Magimai-Doss"], "https://doi.org/10.21437/Interspeech.2018-1240", 5], ["Denoising and Raw-waveform Networks for Weakly-Supervised Gender Identification on Noisy Speech.", ["Jilt Sebastian", "Manoj Kumar", "Pavan Kumar D. S.", "Mathew Magimai-Doss", "Hema A. Murthy", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-2321", 5], ["The Effect of Exposure to High Altitude and Heat on Speech Articulatory Coordination.", ["James R. Williamson", "Thomas F. Quatieri", "Adam C. Lammert", "Katherine Mitchell", "Katherine Finkelstein", "Nicole Ekon", "Caitlin Dillon", "Robert Kenefick", "Kristin Heaton"], "https://doi.org/10.21437/Interspeech.2018-2372", 5], ["Permutation Invariant Training of Generative Adversarial Network for Monaural Speech Separation.", ["Lianwu Chen", "Meng Yu", "Yanmin Qian", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1603", 5], ["Deep Extractor Network for Target Speaker Recovery from Single Channel Speech Mixtures.", ["Jun Wang", "Jie Chen", "Dan Su", "Lianwu Chen", "Meng Yu", "Yanmin Qian", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1205", 5], ["Joint Localization and Classification of Multiple Sound Sources Using a Multi-task Neural Network.", ["Weipeng He", "Petr Motlicek", "Jean-Marc Odobez"], "https://doi.org/10.21437/Interspeech.2018-1269", 5], ["Detection of Glottal Closure Instants from Speech Signals: A Convolutional Neural Network Based Method.", ["Shuai Yang", "Zhiyong Wu", "Binbin Shen", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1281", 5], ["Robust TDOA Estimation Based on Time-Frequency Masking and Deep Neural Networks.", ["Zhong-Qiu Wang", "Xueliang Zhang", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2018-1652", 5], ["Waveform to Single Sinusoid Regression to Estimate the F0 Contour from Noisy Speech Using Recurrent Deep Neural Networks.", ["Akihiro Kato", "Tomi Kinnunen"], "https://doi.org/10.21437/Interspeech.2018-1671", 5], ["Reducing Interference with Phase Recovery in DNN-based Monaural Singing Voice Separation.", ["Paul Magron", "Konstantinos Drossos", "Stylianos Ioannis Mimilakis", "Tuomas Virtanen"], "https://doi.org/10.21437/Interspeech.2018-1845", 5], ["Nebula: F0 Estimation and Voicing Detection by Modeling the Statistical Properties of Feature Extractors.", ["Kanru Hua"], "https://doi.org/10.21437/Interspeech.2018-1258", 5], ["Real-time Single-channel Dereverberation and Separation with Time-domain Audio Separation Network.", ["Yi Luo", "Nima Mesgarani"], "https://doi.org/10.21437/Interspeech.2018-2290", 5], ["Music Source Activity Detection and Separation Using Deep Attractor Network.", ["Rajath Kumar", "Yi Luo", "Nima Mesgarani"], "https://doi.org/10.21437/Interspeech.2018-2326", 5], ["Improving Mandarin Tone Recognition Using Convolutional Bidirectional Long Short-Term Memory with Attention.", ["Longfei Yang", "Yanlu Xie", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2018-2561", 5], ["Vowel Space as a Tool to Evaluate Articulation Problems.", ["Rob van Son", "Catherine Middag", "Kris Demuynck"], "https://doi.org/10.21437/Interspeech.2018-68", 5], ["Towards a Better Characterization of Parkinsonian Speech: A Multidimensional Acoustic Study.", ["Veronique Delvaux", "Kathy Huet", "Myriam Piccaluga", "Sophie van Malderen", "Bernard Harmegnies"], "https://doi.org/10.21437/Interspeech.2018-1054", 5], ["Self-similarity Matrix Based Intelligibility Assessment of Cleft Lip and Palate Speech.", ["Sishir Kalita", "S. R. Mahadeva Prasanna", "Samarendra Dandapat"], "https://doi.org/10.21437/Interspeech.2018-1125", 5], ["Pitch-Adaptive Front-end Feature for Hypernasality Detection.", ["Akhilesh Kumar Dubey", "S. R. Mahadeva Prasanna", "Samarendra Dandapat"], "https://doi.org/10.21437/Interspeech.2018-1251", 5], ["Detection of Amyotrophic Lateral Sclerosis (ALS) via Acoustic Analysis.", ["Raquel Norel", "Mary Pietrowicz", "Carla Agurto", "Shay Rishoni", "Guillermo A. Cecchi"], "https://doi.org/10.21437/Interspeech.2018-2389", 5], ["Detection of Glottal Activity Errors in Production of Stop Consonants in Children with Cleft Lip and Palate.", ["Vikram C. M.", "S. R. Mahadeva Prasanna", "Ajish K. Abraham", "Pushpavathi M", "Girish K. S"], "https://doi.org/10.21437/Interspeech.2018-1665", 5], ["Cold Fusion: Training Seq2Seq Models Together with Language Models.", ["Anuroop Sriram", "Heewoo Jun", "Sanjeev Satheesh", "Adam Coates"], "https://doi.org/10.21437/Interspeech.2018-1392", 5], ["Investigation on Estimation of Sentence Probability by Combining Forward, Backward and Bi-directional LSTM-RNNs.", ["Kazuki Irie", "Zhihong Lei", "Liuhui Deng", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2018-1766", 4], ["Subword and Crossword Units for CTC Acoustic Models.", ["Thomas Zenkel", "Ramon Sanabria", "Florian Metze", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2018-2057", 5], ["Neural Error Corrective Language Models for Automatic Speech Recognition.", ["Tomohiro Tanaka", "Ryo Masumura", "Hirokazu Masataki", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-1430", 5], ["Entity-Aware Language Model as an Unsupervised Reranker.", ["Mohammad Sadegh Rasooli", "Sarangarajan Parthasarathy"], "https://doi.org/10.21437/Interspeech.2018-62", 5], ["Character-level Language Modeling with Gated Hierarchical Recurrent Neural Networks.", ["Iksoo Choi", "Jinhwan Park", "Wonyong Sung"], "https://doi.org/10.21437/Interspeech.2018-1727", 5], ["Acoustic-Prosodic Indicators of Deception and Trust in Interview Dialogues.", ["Sarah Ita Levitan", "Angel Maredia", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2018-2443", 5], ["Deep Personality Recognition for Deception Detection.", ["Guozhen An", "Sarah Ita Levitan", "Julia Hirschberg", "Rivka Levitan"], "https://doi.org/10.21437/Interspeech.2018-2269", 5], ["Cross-cultural (A)symmetries in Audio-visual Attitude Perception.", ["Hansjorg Mixdorff", "Albert Rilliard", "Tan Lee", "Matthew K. H. Ma", "Angelika Honemann"], "https://doi.org/10.21437/Interspeech.2018-1373", 5], ["An Active Feature Transformation Method for Attitude Recognition of Video Bloggers.", ["Fasih Haider", "Fahim A. Salim", "Owen Conlan", "Saturnino Luz"], "https://doi.org/10.21437/Interspeech.2018-1222", 5], ["Automatic Assessment of Individual Culture Attribute of Power Distance Using a Social Context-Enhanced Prosodic Network Representation.", ["Fu-Sheng Tsai", "Hao-Chun Yang", "Wei-Wen Chang", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2018-1523", 5], ["Analysis and Detection of Phonation Modes in Singing Voice using Excitation Source Features and Single Frequency Filtering Cepstral Coefficients (SFFCC).", ["Sudarsana Reddy Kadiri", "Bayya Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2018-2502", 5], ["A Deep Learning Method for Pathological Voice Detection Using Convolutional Deep Belief Networks.", ["Huiyi Wu", "John J. Soraghan", "Anja Lowit", "Gaetano Di Caterina"], "https://doi.org/10.21437/Interspeech.2018-1351", 5], ["Dysarthric Speech Recognition Using Time-delay Neural Network Based Denoising Autoencoder.", ["Chitralekha Bhat", "Biswajit Das", "Bhavik Vachhani", "Sunil Kumar Kopparapu"], "https://doi.org/10.21437/Interspeech.2018-1754", 5], ["A Multitask Learning Approach to Assess the Dysarthria Severity in Patients with Parkinson's Disease.", ["Juan Camilo Vasquez-Correa", "Tomas Arias-Vergara", "Juan Rafael Orozco-Arroyave", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2018-1988", 5], ["The Use of Machine Learning and Phonetic Endophenotypes to Discover Genetic Variants Associated with Speech Sound Disorder.", ["Jason Lilley", "Erin Crowgey", "H. Timothy Bunnell"], "https://doi.org/10.21437/Interspeech.2018-2398", 5], ["Whistle-blowing ASRs: Evaluating the Need for More Inclusive Speech Recognition Systems.", ["Meredith Moore", "Hemanth Venkateswara", "Sethuraman Panchanathan"], "https://doi.org/10.21437/Interspeech.2018-2391", 5], ["Data Augmentation Using Healthy Speech for Dysarthric Speech Recognition.", ["Bhavik Vachhani", "Chitralekha Bhat", "Sunil Kumar Kopparapu"], "https://doi.org/10.21437/Interspeech.2018-1751", 5], ["Improving Sparse Representations in Exemplar-Based Voice Conversion with a Phoneme-Selective Objective Function.", ["Shaojin Ding", "Guanlong Zhao", "Christopher Liberatore", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2018-1272", 5], ["Learning Structured Dictionaries for Exemplar-based Voice Conversion.", ["Shaojin Ding", "Christopher Liberatore", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2018-1295", 5], ["Exemplar-Based Spectral Detail Compensation for Voice Conversion.", ["Yu-Huai Peng", "Hsin-Te Hwang", "Yi-Chiao Wu", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2018-1662", 5], ["Whispered Speech to Neutral Speech Conversion Using Bidirectional LSTMs.", ["G. Nisha Meenakshi", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1487", 5], ["Voice Conversion Across Arbitrary Speakers Based on a Single Target-Speaker Utterance.", ["Songxiang Liu", "Jinghua Zhong", "Lifa Sun", "Xixin Wu", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1504", 5], ["Multi-target Voice Conversion without Parallel Data by Adversarially Learning Disentangled Audio Representations.", ["Ju-Chieh Chou", "Cheng-chieh Yeh", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2018-1830", 5], ["Attention-based Sequence Classification for Affect Detection.", ["Cristina Gorrostieta", "Richard Brutti", "Kye Taylor", "Avi Shapiro", "Joseph Moran", "Ali Azarbayejani", "John Kane"], "https://doi.org/10.21437/Interspeech.2018-1610", 5], ["Computational Paralinguistics: Automatic Assessment of Emotions, Mood and Behavioural State from Acoustics of Speech.", ["Zafi Sherhan Syed", "Julien Schroeter", "Kirill A. Sidorov", "A. David Marshall"], "https://doi.org/10.21437/Interspeech.2018-2019", 5], ["Investigating Utterance Level Representations for Detecting Intent from Acoustics.", ["Sai Krishna Rallabandi", "Bhavya Karki", "Carla Viegas", "Eric Nyberg", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2018-2149", 5], ["LSTM Based Cross-corpus and Cross-task Acoustic Emotion Recognition.", ["Heysem Kaya", "Dmitrii Fedotov", "Ali Yesilkanat", "Oxana Verkholyak", "Yang Zhang", "Alexey Karpov"], "https://doi.org/10.21437/Interspeech.2018-2298", 5], ["Implementing Fusion Techniques for the Classification of Paralinguistic Information.", ["Bogdan Vlasenko", "Jilt Sebastian", "Pavan Kumar D. S.", "Mathew Magimai-Doss"], "https://doi.org/10.21437/Interspeech.2018-2360", 5], ["General Utterance-Level Feature Extraction for Classifying Crying Sounds, Atypical & Self-Assessed Affect and Heart Beats.", ["Gabor Gosztolya", "Tamas Grosz", "Laszlo Toth"], "https://doi.org/10.21437/Interspeech.2018-1076", 5], ["Self-Assessed Affect Recognition Using Fusion of Attentional BLSTM and Static Acoustic Features.", ["Bo-Hao Su", "Sung-Lin Yeh", "Ming-Ya Ko", "Huan-Yu Chen", "Shun-Chang Zhong", "Jeng-Lin Li", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2018-2261", 5], ["Vocalic, Lexical and Prosodic Cues for the INTERSPEECH 2018 Self-Assessed Affect Challenge.", ["Claude Montacie", "Marie-Jose Caraty"], "https://doi.org/10.21437/Interspeech.2018-1331", 5], ["Intonation tutor by SPIRE (In-SPIRE): An Online Tool for an Automatic Feedback to the Second Language Learners in Learning Intonation.", ["Anand P. A", "Chiranjeevi Yarra", "N. K. Kausthubha", "Prasanta Kumar Ghosh"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3008.html", 2], ["Game-based Spoken Dialog Language Learning Applications for Young Students.", ["Keelan Evanini", "Veronika Timpe-Laughlin", "Eugene Tsuprun", "Ian Blood", "Jeremy Lee", "James V. Bruno", "Vikram Ramanarayanan", "Patrick L. Lange", "David Suendermann-Oeft"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3045.html", 2], ["The IBM Virtual Voice Creator.", ["Alexander Sorin", "Slava Shechtman", "Zvi Kons", "Ron Hoory", "Shay Ben-David", "Joe Pavitt", "Shai Rozenberg", "Carmel Rabinovitz", "Tal Drory"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3011.html", 2], ["Mobile Application for Learning Languages for the Unlettered.", ["Gayathri G", "N. Mohana", "Radhika Pal", "Hema A. Murthy"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3012.html", 2], ["Mandarin-English Code-switching Speech Recognition.", ["Haihua Xu", "Van Tung Pham", "Zin Tun Kyaw", "Zhi Hao Lim", "Eng Siong Chng", "Haizhou Li"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3014.html", 2], ["Joint Learning of Domain Classification and Out-of-Domain Detection with Dynamic Class Weighting for Satisficing False Acceptance Rates.", ["Joo-Kyung Kim", "Young-Bum Kim"], "https://doi.org/10.21437/Interspeech.2018-1581", 5], ["Analyzing Vocal Tract Movements During Speech Accommodation.", ["Sankar Mukherjee", "Thierry Legou", "Leonardo Lancia", "Pauline Hilt", "Alice Tomassini", "Luciano Fadiga", "Alessandro DAusilio", "Leonardo Badino", "Noel Nguyen"], "https://doi.org/10.21437/Interspeech.2018-2084", 5], ["Cross-Lingual Multi-Task Neural Architecture for Spoken Language Understanding.", ["Yujiang Li", "Xuemin Zhao", "Weiqun Xu", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1039", 5], ["Statistical Model Compression for Small-Footprint Natural Language Understanding.", ["Grant P. Strimel", "Kanthashree Mysore Sathyendra", "Stanislav Peshterliev"], "https://doi.org/10.21437/Interspeech.2018-1333", 5], ["Comparison of an End-to-end Trainable Dialogue System with a Modular Statistical Dialogue System.", ["Norbert Braunschweiler", "Alexandros Papangelis"], "https://doi.org/10.21437/Interspeech.2018-1679", 5], ["A Discriminative Acoustic-Prosodic Approach for Measuring Local Entrainment.", ["Megan M. Willi", "Stephanie A. Borrie", "Tyson S. Barrett", "Ming Tu", "Visar Berisha"], "https://doi.org/10.21437/Interspeech.2018-1419", 5], ["Investigating Speech Features for Continuous Turn-Taking Prediction Using LSTMs.", ["Matthew Roddy", "Gabriel Skantze", "Naomi Harte"], "https://doi.org/10.21437/Interspeech.2018-2124", 5], ["Classification of Correction Turns in Multilingual Dialogue Corpus.", ["Ivan Kraljevski", "Diane Hirschfeld"], "https://doi.org/10.21437/Interspeech.2018-1348", 5], ["Contextual Slot Carryover for Disparate Schemas.", ["Chetan Naik", "Arpit Gupta", "Hancheng Ge", "Lambert Mathias", "Ruhi Sarikaya"], "https://doi.org/10.21437/Interspeech.2018-1035", 5], ["Capsule Networks for Low Resource Spoken Language Understanding.", ["Vincent Renkens", "Hugo Van hamme"], "https://doi.org/10.21437/Interspeech.2018-1013", 5], ["Intent Discovery Through Unsupervised Semantic Text Clustering.", ["Padmasundari", "Srinivas Bangalore"], "https://doi.org/10.21437/Interspeech.2018-2436", 5], ["Multimodal Polynomial Fusion for Detecting Driver Distraction.", ["Yulun Du", "Alan W. Black", "Louis-Philippe Morency", "Maxine Eskenazi"], "https://doi.org/10.21437/Interspeech.2018-2011", 5], ["Engagement Recognition in Spoken Dialogue via Neural Network by Aggregating Different Annotators' Models.", ["Koji Inoue", "Divesh Lala", "Katsuya Takanashi", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2018-2067", 5], ["A First Investigation of the Timing of Turn-taking in Ruuli.", ["Tuarik Buanzur", "Margaret Zellers", "Saudah Namyalo", "Alena Witzlack-Makarevich"], "https://doi.org/10.21437/Interspeech.2018-1254", 5], ["Spoofing Detection Using Adaptive Weighting Framework and Clustering Analysis.", ["Yuanjun Zhao", "Roberto Togneri", "Victor Sreeram"], "https://doi.org/10.21437/Interspeech.2018-1042", 5], ["Exploration of Compressed ILPR Features for Replay Attack Detection.", ["Sarfaraz Jelil", "Sishir Kalita", "S. R. Mahadeva Prasanna", "Rohit Sinha"], "https://doi.org/10.21437/Interspeech.2018-1297", 5], ["Detection of Replay-Spoofing Attacks Using Frequency Modulation Features.", ["Tharshini Gunendradasan", "Buddhi Wickramasinghe", "Phu Ngoc Le", "Eliathamby Ambikairajah", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2018-1473", 5], ["Effectiveness of Speech Demodulation-Based Features for Replay Detection.", ["Madhu R. Kamble", "Hemlata Tak", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1675", 5], ["Novel Variable Length Energy Separation Algorithm Using Instantaneous Amplitude Features for Replay Detection.", ["Madhu R. Kamble", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1687", 5], ["Feature with Complementarity of Statistics and Principal Information for Spoofing Detection.", ["Ji-Chen Yang", "Changhuai You", "Qianhua He"], "https://doi.org/10.21437/Interspeech.2018-1693", 5], ["Multiple Phase Information Combination for Replay Attacks Detection.", ["Dongbo Li", "Longbiao Wang", "Jianwu Dang", "Meng Liu", "Zeyan Oo", "Seiichi Nakagawa", "Haotian Guan", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2018-2001", 5], ["Frequency Domain Linear Prediction Features for Replay Spoofing Attack Detection.", ["Buddhi Wickramasinghe", "Saad Irtza", "Eliathamby Ambikairajah", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2018-1574", 5], ["Auditory Filterbank Learning for Temporal Modulation Features in Replay Spoof Speech Detection.", ["Hardik B. Sailor", "Madhu R. Kamble", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1651", 5], ["Deep Siamese Architecture Based Replay Detection for Secure Voice Biometric.", ["Kaavya Sriskandaraja", "Vidhyasaharan Sethu", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2018-1819", 5], ["A Deep Identity Representation for Noise Robust Spoofing Detection.", ["Alejandro Gomez Alanis", "Antonio M. Peinado", "Jose A. Gonzalez", "Angel M. Gomez"], "https://doi.org/10.21437/Interspeech.2018-1909", 5], ["End-To-End Audio Replay Attack Detection Using Deep Convolutional Networks with Attention.", ["Francis Tom", "Mohit Jain", "Prasenjit Dey"], "https://doi.org/10.21437/Interspeech.2018-2279", 5], ["Decision-level Feature Switching as a Paradigm for Replay Attack Detection.", ["M. S. Saranya", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2018-1494", 5], ["Modulation Dynamic Features for the Detection of Replay Attacks.", ["Gajan Suthokumar", "Vidhyasaharan Sethu", "Chamith Wijenayake", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2018-1846", 5], ["On the Usefulness of the Speech Phase Spectrum for Pitch Extraction.", ["Erfan Loweimi", "Jon Barker", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2018-1062", 5], ["Time-regularized Linear Prediction for Noise-robust Extraction of the Spectral Envelope of Speech.", ["Manu Airaksinen", "Lauri Juvela", "Okko Rasanen", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2018-1230", 5], ["Auditory Filterbank Learning Using ConvRBM for Infant Cry Classification.", ["Hardik B. Sailor", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1536", 5], ["Effectiveness of Dynamic Features in INCA and Temporal Context-INCA.", ["Nirmesh J. Shah", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1538", 5], ["Singing Voice Phoneme Segmentation by Hierarchically Inferring Syllable and Phoneme Onset Positions.", ["Rong Gong", "Xavier Serra"], "https://doi.org/10.21437/Interspeech.2018-1224", 5], ["Novel Empirical Mode Decomposition Cepstral Features for Replay Spoof Detection.", ["Prasad Tapkir", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1661", 5], ["Novel Linear Frequency Residual Cepstral Features for Replay Attack Detection.", ["Hemlata Tak", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1702", 5], ["Analysis of sparse representation based feature on speech mode classification.", ["Kumud Tripathi", "K. Sreenivasa Rao"], "https://doi.org/10.21437/Interspeech.2018-1921", 5], ["Multicomponent 2-D AM-FM Modeling of Speech Spectrograms.", ["Jitendra Kumar Dhiman", "Neeraj Sharma", "Chandra Sekhar Seelamantula"], "https://doi.org/10.21437/Interspeech.2018-1937", 5], ["An Optimization Framework for Recovery of Speech from Phase-Encoded Spectrograms.", ["Abhilash Sainathan", "Sunil Rudresh", "Chandra Sekhar Seelamantula"], "https://doi.org/10.21437/Interspeech.2018-1987", 5], ["Speaker Recognition with Nonlinear Distortion: Clipping Analysis and Impact.", ["Wei Xia", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-2430", 5], ["Linear Prediction Residual based Short-term Cepstral Features for Replay Attacks Detection.", ["Madhusudan Singh", "Debadatta Pati"], "https://doi.org/10.21437/Interspeech.2018-1128", 5], ["Analysis of Variational Mode Functions for Robust Detection of Vowels.", ["Surbhi Sakshi", "Avinash Kumar", "Gayadhar Pradhan"], "https://doi.org/10.21437/Interspeech.2018-1947", 5], ["Improving Attention Based Sequence-to-Sequence Models for End-to-End English Conversational Speech Recognition.", ["Chao Weng", "Jia Cui", "Guangsen Wang", "Jun Wang", "Chengzhu Yu", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1030", 5], ["Segmental Encoder-Decoder Models for Large Vocabulary Automatic Speech Recognition.", ["Eugen Beck", "Mirko Hannemann", "Patrick Dotsch", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2018-1212", 5], ["Acoustic Modeling with DFSMN-CTC and Joint CTC-CE Learning.", ["Shiliang Zhang", "Ming Lei"], "https://doi.org/10.21437/Interspeech.2018-1049", 5], ["End-to-End Speech Command Recognition with Capsule Network.", ["Jaesung Bae", "Dae-Shik Kim"], "https://doi.org/10.21437/Interspeech.2018-1888", 5], ["End-to-End Speech Recognition from the Raw Waveform.", ["Neil Zeghidour", "Nicolas Usunier", "Gabriel Synnaeve", "Ronan Collobert", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2018-2414", 5], ["A Multistage Training Framework for Acoustic-to-Word Model.", ["Chengzhu Yu", "Chunlei Zhang", "Chao Weng", "Jia Cui", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1452", 5], ["Syllable-Based Sequence-to-Sequence Speech Recognition with the Transformer in Mandarin Chinese.", ["Shiyu Zhou", "Linhao Dong", "Shuang Xu", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2018-1107", 5], ["Densely Connected Networks for Conversational Speech Recognition.", ["Kyu J. Han", "Akshay Chandrashekaran", "Jungsuk Kim", "Ian Lane"], "https://doi.org/10.21437/Interspeech.2018-1486", 5], ["Multi-Head Decoder for End-to-End Speech Recognition.", ["Tomoki Hayashi", "Shinji Watanabe", "Tomoki Toda", "Kazuya Takeda"], "https://doi.org/10.21437/Interspeech.2018-1655", 5], ["Compressing End-to-end ASR Networks by Tensor-Train Decomposition.", ["Takuma Mori", "Andros Tjandra", "Sakriani Sakti", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2018-1543", 5], ["Speech2Vec: A Sequence-to-Sequence Framework for Learning Word Embeddings from Speech.", ["Yu-An Chung", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2018-2341", 5], ["Extending Recurrent Neural Aligner for Streaming End-to-End Speech Recognition in Mandarin.", ["Linhao Dong", "Shiyu Zhou", "Wei Chen", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2018-1086", 5], ["Joint Noise and Reverberation Adaptive Learning for Robust Speaker DOA Estimation with an Acoustic Vector Sensor.", ["Disong Wang", "Yuexian Zou"], "https://doi.org/10.21437/Interspeech.2018-1135", 5], ["Multiple Concurrent Sound Source Tracking Based on Observation-Guided Adaptive Particle Filter.", ["Hong Liu", "Haipeng Lan", "Bing Yang", "Cheng Pang"], "https://doi.org/10.21437/Interspeech.2018-1248", 5], ["Harmonic-Percussive Source Separation of Polyphonic Music by Suppressing Impulsive Noise Events.", ["Gurunath Reddy M.", "K. Sreenivasa Rao", "Partha Pratim Das"], "https://doi.org/10.21437/Interspeech.2018-1310", 5], ["Speaker Activity Detection and Minimum Variance Beamforming for Source Separation.", ["Enea Ceolini", "Jithendar Anumula", "Adrian E. G. Huber", "Ilya Kiselev", "Shih-Chii Liu"], "https://doi.org/10.21437/Interspeech.2018-1606", 5], ["Sparsity-Constrained Weight Mapping for Head-Related Transfer Functions Individualization from Anthropometric Features.", ["Xiaoke Qi", "Jianhua Tao"], "https://doi.org/10.21437/Interspeech.2018-1615", 5], ["Speech Source Separation Using ICA in Constant Q Transform Domain.", ["Dheeraj Sai D. V. L. N", "Kishor K. S", "Sri Rama Murty Kodukula"], "https://doi.org/10.21437/Interspeech.2018-1732", 5], ["Multi-talker Speech Separation Based on Permutation Invariant Training and Beamforming.", ["Lu Yin", "Ziteng Wang", "Risheng Xia", "Junfeng Li", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1739", 5], ["Expectation-Maximization Algorithms for Itakura-Saito Nonnegative Matrix Factorization.", ["Paul Magron", "Tuomas Virtanen"], "https://doi.org/10.21437/Interspeech.2018-1840", 5], ["Subband Weighting for Binaural Speech Source Localization.", ["Girija Ramesan Karthik", "Parth Suresh", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-2173", 5], ["Universal Tendencies for Cross-Linguistic Prosodic Tendencies: A Review and Some New Proposals.", ["Jacqueline Vaissiere"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/4002.html", 1], ["Learning to Adapt: A Meta-learning Approach for Speaker Adaptation.", ["Ondrej Klejch", "Joachim Fainberg", "Peter Bell"], "https://doi.org/10.21437/Interspeech.2018-1244", 5], ["Speaker Adaptation and Adaptive Training for Jointly Optimised Tandem Systems.", ["Yu Wang", "Chao Zhang", "Mark J. F. Gales", "Philip C. Woodland"], "https://doi.org/10.21437/Interspeech.2018-2432", 5], ["Comparison of BLSTM-Layer-Specific Affine Transformations for Speaker Adaptation.", ["Markus Kitza", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2018-2022", 5], ["Correlational Networks for Speaker Normalization in Automatic Speech Recognition.", ["Rini A. Sharon", "Sandeep Reddy Kothinti", "Srinivasan Umesh"], "https://doi.org/10.21437/Interspeech.2018-1612", 5], ["Machine Speech Chain with One-shot Speaker Adaptation.", ["Andros Tjandra", "Sakriani Sakti", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2018-1558", 5], ["Domain Adaptation Using Factorized Hidden Layer for Robust Automatic Speech Recognition.", ["Khe Chai Sim", "Arun Narayanan", "Ananya Misra", "Anshuman Tripathi", "Golan Pundak", "Tara N. Sainath", "Parisa Haghani", "Bo Li", "Michiel Bacchiani"], "https://doi.org/10.21437/Interspeech.2018-2246", 5], ["Waveform-Based Speaker Representations for Speech Synthesis.", ["Moquan Wan", "Gilles Degottex", "Mark J. F. Gales"], "https://doi.org/10.21437/Interspeech.2018-1154", 5], ["Incremental TTS for Japanese Language.", ["Tomoya Yanagita", "Sakriani Sakti", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2018-1561", 5], ["Transfer Learning Based Progressive Neural Networks for Acoustic Modeling in Statistical Parametric Speech Synthesis.", ["Ruibo Fu", "Jianhua Tao", "Yibin Zheng", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2018-1265", 5], ["A Unified Framework for the Generation of Glottal Signals in Deep Learning-based Parametric Speech Synthesis Systems.", ["Min-Jae Hwang", "Eunwoo Song", "Jin-Seob Kim", "Hong-Goo Kang"], "https://doi.org/10.21437/Interspeech.2018-1590", 5], ["Acoustic Modeling Using Adversarially Trained Variational Recurrent Neural Network for Speech Synthesis.", ["Joun Yeop Lee", "Sung Jun Cheon", "Byoung Jin Choi", "Nam Soo Kim", "Eunwoo Song"], "https://doi.org/10.21437/Interspeech.2018-1598", 5], ["On the Application and Compression of Deep Time Delay Neural Network for Embedded Statistical Parametric Speech Synthesis.", ["Yibin Zheng", "Jianhua Tao", "Zhengqi Wen", "Ruibo Fu"], "https://doi.org/10.21437/Interspeech.2018-1970", 5], ["Integrating Recurrence Dynamics for Speech Emotion Recognition.", ["Efthymios Tzinis", "Georgios Paraskevopoulos", "Christos Baziotis", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2018-1377", 5], ["Towards Temporal Modelling of Categorical Speech Emotion Recognition.", ["Wenjing Han", "Huabin Ruan", "Xiaomin Chen", "Zhixiang Wang", "Haifeng Li", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1858", 5], ["Emotion Recognition from Human Speech Using Temporal Information and Deep Learning.", ["John Kim", "Rif A. Saurous"], "https://doi.org/10.21437/Interspeech.2018-1132", 4], ["Role of Regularization in the Prediction of Valence from Speech.", ["Kusha Sridhar", "Srinivas Parthasarathy", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2018-2508", 5], ["Learning Spontaneity to Improve Emotion Recognition in Speech.", ["Karttikeya Mangalam", "Tanaya Guha"], "https://doi.org/10.21437/Interspeech.2018-1872", 5], ["Predicting Categorical Emotions by Jointly Learning Primary and Secondary Emotions through Multitask Learning.", ["Reza Lotfian", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2018-2464", 5], ["Picture Naming or Word Reading: Does the Modality Affect Speech Motor Adaptation and Its Transfer?", ["Tiphaine Caudrelier", "Pascal Perrier", "Jean-Luc Schwartz", "Amelie Rochet-Capellan"], "https://doi.org/10.21437/Interspeech.2018-1760", 5], ["Measuring the Band Importance Function for Mandarin Chinese with a Bayesian Adaptive Procedure.", ["Yufan Du", "Yi Shen", "Hongying Yang", "Xihong Wu", "Jing Chen"], "https://doi.org/10.21437/Interspeech.2018-1825", 5], ["Wide Learning for Auditory Comprehension.", ["Elnaz Shafaei-Bajestan", "R. Harald Baayen"], "https://doi.org/10.21437/Interspeech.2018-2420", 5], ["Analyzing Reaction Time Sequences from Human Participants in Auditory Experiments.", ["Louis ten Bosch", "Mirjam Ernestus", "Lou Boves"], "https://doi.org/10.21437/Interspeech.2018-1728", 5], ["Prediction of Perceived Speech Quality Using Deep Machine Listening.", ["Jasper Ooster", "Rainer Huber", "Bernd T. Meyer"], "https://doi.org/10.21437/Interspeech.2018-1374", 5], ["Prediction of Subjective Listening Effort from Acoustic Data with Non-Intrusive Deep Models.", ["Paul Kranzusch", "Rainer Huber", "Melanie Kruger", "Birger Kollmeier", "Bernd T. Meyer"], "https://doi.org/10.21437/Interspeech.2018-1375", 5], ["A Case Study on the Importance of Belief State Representation for Dialogue Policy Management.", ["Margarita Kotti", "Vassilios Diakoloukas", "Alexandros Papangelis", "Michail Lagoudakis", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2018-1293", 5], ["Prediction of Turn-taking Using Multitask Learning with Prediction of Backchannels and Fillers.", ["Kohei Hara", "Koji Inoue", "Katsuya Takanashi", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2018-1442", 5], ["Conversational Analysis Using Utterance-level Attention-based Bidirectional Recurrent Neural Networks.", ["Chandrakant Bothe", "Sven Magg", "Cornelius Weber", "Stefan Wermter"], "https://doi.org/10.21437/Interspeech.2018-2527", 5], ["A Comparative Study of Statistical Conversion of Face to Voice Based on Their Subjective Impressions.", ["Yasuhito Ohsugi", "Daisuke Saito", "Nobuaki Minematsu"], "https://doi.org/10.21437/Interspeech.2018-2005", 5], ["Follow-up Question Generation Using Pattern-based Seq2seq with a Small Corpus for Interview Coaching.", ["Ming-Hsiang Su", "Chung-Hsien Wu", "Kun-Yi Huang", "Qian-Bei Hong", "Huai-Hung Huang"], "https://doi.org/10.21437/Interspeech.2018-1007", 5], ["Coherence Models for Dialogue.", ["Alessandra Cervone", "Evgeny A. Stepanov", "Giuseppe Riccardi"], "https://doi.org/10.21437/Interspeech.2018-2446", 5], ["Indian Languages ASR: A Multilingual Phone Recognition Framework with IPA Based Common Phone-set, Predicted Articulatory Features and Feature fusion.", ["K. E. Manjunath", "K. Sreenivasa Rao", "Dinesh Babu Jayagopi", "V. Ramasubramanian"], "https://doi.org/10.21437/Interspeech.2018-2529", 5], ["Rapid Collection of Spontaneous Speech Corpora Using Telephonic Community Forums.", ["Agha Ali Raza", "Awais Athar", "Shan Randhawa", "Zain Tariq", "Muhammad Bilal Saleem", "Haris Bin Zia", "Umar Saif", "Roni Rosenfeld"], "https://doi.org/10.21437/Interspeech.2018-1139", 5], ["Effect of TTS Generated Audio on OOV Detection and Word Error Rate in ASR for Low-resource Languages.", ["Savitha Murthy", "Dinkar Sitaram", "Sunayana Sitaram"], "https://doi.org/10.21437/Interspeech.2018-1555", 5], ["Development of Large Vocabulary Speech Recognition System with Keyword Search for Manipuri.", ["Tanvina Patel", "Krishna D. N", "Noor Fathima", "Nisar Shah", "Mahima C", "Deepak Kumar", "Anuroop Iyengar"], "https://doi.org/10.21437/Interspeech.2018-2133", 5], ["Robust Mizo Continuous Speech Recognition.", ["Abhishek Dey", "Biswajit Dev Sarma", "Wendy Lalhminghlui", "Lalnunsiami Ngente", "Parismita Gogoi", "Priyankoo Sarmah", "S. R. Mahadeva Prasanna", "Rohit Sinha", "S. R. Nirmala"], "https://doi.org/10.21437/Interspeech.2018-2125", 5], ["Semi-supervised and Active-learning Scenarios: Efficient Acoustic Model Refinement for a Low Resource Indian Language.", ["Maharajan Chellapriyadharshini", "Anoop Toffy", "Srinivasa Raghavan K. M.", "V. Ramasubramanian"], "https://doi.org/10.21437/Interspeech.2018-2486", 5], ["Automatic Speech Recognition with Articulatory Information and a Unified Dictionary for Hindi, Marathi, Bengali and Oriya.", ["Debadatta Dash", "Myung Jong Kim", "Kristin Teplansky", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2018-2122", 5], ["Captaina: Integrated Pronunciation Practice and Data Collection Portal.", ["Aku Rouhe", "Reima Karhila", "Aija Elg", "Minnaleena Toivola", "Peter Smit", "Anna-Riikka Smolander", "Mikko Kurimo"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3015.html", 2], ["auMina\u2122 - Enterprise Speech Analytics.", ["Umesh Sachdev", "Rajagopal Jayaraman", "Zainab Millwala"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3016.html", 2], ["HoloCompanion: An MR Friend for EveryOne.", ["Annam Naresh", "Rushabh Gandhi", "Mallikarjuna Rao Bellamkonda", "Mithun Das Gupta"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3017.html", 2], ["akeira\u2122 - Virtual Assistant.", ["Umesh Sachdev", "Rajagopal Jayaraman", "Zainab Millwala"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3018.html", 2], ["Brain-Computer Interface using Electroencephalogram Signatures of Eye Blinks.", ["Srihari Maruthachalam", "Sidharth Aggarwal", "Mari Ganesh Kumar", "Mriganka Sur", "Hema A. Murthy"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3019.html", 2], ["Voice Comparison and Rhythm: Behavioral Differences between Target and Non-target Comparisons.", ["Moez Ajili", "Jean-Francois Bonastre", "Solange Rossato"], "https://doi.org/10.21437/Interspeech.2018-61", 5], ["Co-whitening of I-vectors for Short and Long Duration Speaker Verification.", ["Longting Xu", "Kong-Aik Lee", "Haizhou Li", "Zhen Yang"], "https://doi.org/10.21437/Interspeech.2018-1246", 5], ["Compensation for Domain Mismatch in Text-independent Speaker Recognition.", ["Fahimeh Bahmaninezhad", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-1446", 5], ["Joint Learning of J-Vector Extractor and Joint Bayesian Model for Text Dependent Speaker Verification.", ["Ziqiang Shi", "Liu Liu", "Huibin Lin", "Rujie Liu"], "https://doi.org/10.21437/Interspeech.2018-1500", 5], ["Latent Factor Analysis of Deep Bottleneck Features for Speaker Verification with Random Digit Strings.", ["Ziqiang Shi", "Huibin Lin", "Liu Liu", "Rujie Liu"], "https://doi.org/10.21437/Interspeech.2018-1422", 5], ["VoxCeleb2: Deep Speaker Recognition.", ["Joon Son Chung", "Arsha Nagrani", "Andrew Zisserman"], "https://doi.org/10.21437/Interspeech.2018-1929", 5], ["Supervised I-vector Modeling - Theory and Applications.", ["Shreyas Ramoji", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2018-2012", 5], ["LOCUST - Longitudinal Corpus and Toolset for Speaker Verification.", ["Evgeny Dmitriev", "Yulia Kim", "Anastasia Matveeva", "Claude Montacie", "Yannick Boulard", "Yadviga Sinyavskaya", "Yulia Zhukova", "Adam Zarazinski", "Egor Akhanov", "Ilya I. Viksnin", "Andrei A. Shlykov", "Maria Usova"], "https://doi.org/10.21437/Interspeech.2018-2412", 5], ["Analysis of Language Dependent Front-End for Speaker Recognition.", ["Srikanth R. Madikeri", "Subhadeep Dey", "Petr Motlicek"], "https://doi.org/10.21437/Interspeech.2018-2071", 5], ["Robust Speaker Recognition from Distant Speech under Real Reverberant Environments Using Speaker Embeddings.", ["Mahesh Kumar Nandwana", "Julien van Hout", "Mitchell McLaren", "Allen R. Stauffer", "Colleen Richey", "Aaron Lawson", "Martin Graciarena"], "https://doi.org/10.21437/Interspeech.2018-2221", 5], ["Investigation on Bandwidth Extension for Speaker Recognition.", ["Phani Sankar Nidadavolu", "Cheng-I Lai", "Jesus Villalba", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2394", 5], ["On Learning Vocal Tract System Related Speaker Discriminative Information from Raw Signal Using CNNs.", ["Hannah Muckenhirn", "Mathew Magimai-Doss", "Sebastien Marcel"], "https://doi.org/10.21437/Interspeech.2018-1696", 5], ["On Convolutional LSTM Modeling for Joint Wake-Word Detection and Text Dependent Speaker Verification.", ["Rajath Kumar", "Vaishnavi Yeruva", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2018-1759", 5], ["Cosine Metric Learning for Speaker Verification in the I-vector Space.", ["Zhongxin Bai", "Xiao-Lei Zhang", "Jingdong Chen"], "https://doi.org/10.21437/Interspeech.2018-1593", 5], ["An Unsupervised Neural Prediction Framework for Learning Speaker Embeddings Using Recurrent Neural Networks.", ["Arindam Jati", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2018-1363", 5], ["A New Framework for Supervised Speech Enhancement in the Time Domain.", ["Ashutosh Pandey", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2018-1223", 5], ["Speech Enhancement Using the Minimum-probability-of-error Criterion.", ["Jishnu Sadasivan", "Subhadip Mukherjee", "Chandra Sekhar Seelamantula"], "https://doi.org/10.21437/Interspeech.2018-1294", 5], ["Exploring the Relationship between Conic Affinity of NMF Dictionaries and Speech Enhancement Metrics.", ["Pavlos Papadopoulos", "Colin Vaz", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1387", 5], ["Using Shifted Real Spectrum Mask as Training Target for Supervised Speech Separation.", ["Yun Liu", "Hui Zhang", "Xueliang Zhang"], "https://doi.org/10.21437/Interspeech.2018-1650", 5], ["Enhancement of Noisy Speech Signal by Non-Local Means Estimation of Variational Mode Functions.", ["Nagapuri Srinivas", "Gayadhar Pradhan", "Syed Shahnawazuddin"], "https://doi.org/10.21437/Interspeech.2018-1928", 5], ["Phase-locked Loop (PLL) Based Phase Estimation in Single Channel Speech Enhancement.", ["Priya Pallavi", "Ch. V. Rama Rao"], "https://doi.org/10.21437/Interspeech.2018-1950", 4], ["Cycle-Consistent Speech Enhancement.", ["Zhong Meng", "Jinyu Li", "Yifan Gong", "Biing-Hwang Fred Juang"], "https://doi.org/10.21437/Interspeech.2018-2409", 5], ["Visual Speech Enhancement.", ["Aviv Gabbay", "Asaph Shamir", "Shmuel Peleg"], "https://doi.org/10.21437/Interspeech.2018-1955", 5], ["Implementation of Digital Hearing Aid as a Smartphone Application.", ["Saketh Sharma", "Nitya Tiwari", "Prem C. Pandey"], "https://doi.org/10.21437/Interspeech.2018-2031", 5], ["Bone-Conduction Sensor Assisted Noise Estimation for Improved Speech Enhancement.", ["Ching Hua Lee", "Bhaskar D. Rao", "Harinath Garudadri"], "https://doi.org/10.21437/Interspeech.2018-1046", 5], ["Artificial Bandwidth Extension with Memory Inclusion Using Semi-supervised Stacked Auto-encoders.", ["Pramod B. Bachhav", "Massimiliano Todisco", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2018-2213", 5], ["Large Vocabulary Concatenative Resynthesis.", ["Soumi Maiti", "Joey Ching", "Michael I. Mandel"], "https://doi.org/10.21437/Interspeech.2018-2383", 5], ["Concatenative Resynthesis with Improved Training Signals for Speech Enhancement.", ["Ali Raza Syed", "Viet Anh Trinh", "Michael I. Mandel"], "https://doi.org/10.21437/Interspeech.2018-2439", 5], ["Comparison of Syllabification Algorithms and Training Strategies for Robust Word Count Estimation across Different Languages and Recording Conditions.", ["Okko Rasanen", "Shreyas Seshadri", "Marisa Casillas"], "https://doi.org/10.21437/Interspeech.2018-1047", 5], ["A Comparison of Input Types to a Deep Neural Network-based Forced Aligner.", ["Matthew C. Kelley", "Benjamin V. Tucker"], "https://doi.org/10.21437/Interspeech.2018-1115", 5], ["Joint Learning Using Denoising Variational Autoencoders for Voice Activity Detection.", ["Youngmoon Jung", "Younggwan Kim", "Yeunju Choi", "Hoirin Kim"], "https://doi.org/10.21437/Interspeech.2018-1151", 5], ["Information Bottleneck Based Percussion Instrument Diarization System for Taniavartanam Segments of Carnatic Music Concerts.", ["Nauman Dawalatabad", "Jom Kuriakose", "Chellu Chandra Sekhar", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2018-1203", 5], ["Robust Voice Activity Detection Using Frequency Domain Long-Term Differential Entropy.", ["Debayan Ghosh", "Muralishankar R", "Sanjeev Gurugopinath"], "https://doi.org/10.21437/Interspeech.2018-1431", 5], ["Device-directed Utterance Detection.", ["Sri Harish Reddy Mallidi", "Roland Maas", "Kyle Goehner", "Ariya Rastrow", "Spyros Matsoukas", "Bjorn Hoffmeister"], "https://doi.org/10.21437/Interspeech.2018-1531", 4], ["Acoustic-Prosodic Features of Tabla Bol Recitation and Correspondence with the Tabla Imitation.", ["Rohit M. A", "Preeti Rao"], "https://doi.org/10.21437/Interspeech.2018-1692", 5], ["Who Said That? a Comparative Study of Non-negative Matrix Factorization Techniques.", ["Teun F. Krikke", "Frank Broz", "David Lane"], "https://doi.org/10.21437/Interspeech.2018-1807", 5], ["AVA-Speech: A Densely Labeled Dataset of Speech Activity in Movies.", ["Sourish Chaudhuri", "Joseph Roth", "Daniel P. W. Ellis", "Andrew C. Gallagher", "Liat Kaver", "Radhika Marvin", "Caroline Pantofaru", "Nathan Reale", "Loretta Guarino Reid", "Kevin W. Wilson", "Zhonghua Xi"], "https://doi.org/10.21437/Interspeech.2018-2028", 5], ["Audiovisual Speech Activity Detection with Advanced Long Short-Term Memory.", ["Fei Tao", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2018-2490", 5], ["Towards Automatic Speech Identification from Vocal Tract Shape Dynamics in Real-time MRI.", ["Pramit Saha", "Praneeth Srungarapu", "Sidney Fels"], "https://doi.org/10.21437/Interspeech.2018-2537", 5], ["Structured Word Embedding for Low Memory Neural Network Language Model.", ["Kaiyu Shi", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2018-1057", 5], ["Role Play Dialogue Aware Language Models Based on Conditional Hierarchical Recurrent Encoder-Decoder.", ["Ryo Masumura", "Tomohiro Tanaka", "Atsushi Ando", "Hirokazu Masataki", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-2185", 5], ["Efficient Keyword Spotting Using Time Delay Neural Networks.", ["Samuel Myer", "Vikrant Singh Tomar"], "https://doi.org/10.21437/Interspeech.2018-1979", 5], ["Automatic DNN Node Pruning Using Mixture Distribution-based Group Regularization.", ["Tsukasa Yoshida", "Takafumi Moriya", "Kazuho Watanabe", "Yusuke Shinohara", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-2062", 5], ["Conditional-Computation-Based Recurrent Neural Networks for Computationally Efficient Acoustic Modelling.", ["Raffaele Tavarone", "Leonardo Badino"], "https://doi.org/10.21437/Interspeech.2018-2195", 5], ["Leveraging Translations for Speech Transcription in Low-resource Settings.", ["Antonios Anastasopoulos", "David Chiang"], "https://doi.org/10.21437/Interspeech.2018-2162", 5], ["Sequence-to-sequence Neural Network Model with 2D Attention for Learning Japanese Pitch Accents.", ["Antoine Bruguier", "Heiga Zen", "Arkady Arkhangorodsky"], "https://doi.org/10.21437/Interspeech.2018-1381", 4], ["Task Specific Sentence Embeddings for ASR Error Detection.", ["Sahar Ghannay", "Yannick Esteve", "Nathalie Camelin"], "https://doi.org/10.21437/Interspeech.2018-2211", 5], ["Low-Latency Neural Speech Translation.", ["Jan Niehues", "Ngoc-Quan Pham", "Thanh-Le Ha", "Matthias Sperber", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2018-1055", 5], ["Low-Resource Speech-to-Text Translation.", ["Sameer Bansal", "Herman Kamper", "Karen Livescu", "Adam Lopez", "Sharon Goldwater"], "https://doi.org/10.21437/Interspeech.2018-1326", 5], ["VoiceGuard: Secure and Private Speech Processing.", ["Ferdinand Brasser", "Tommaso Frassetto", "Korbinian Riedhammer", "Ahmad-Reza Sadeghi", "Thomas Schneider", "Christian Weinert"], "https://doi.org/10.21437/Interspeech.2018-2032", 5], ["Deep Learning based Situated Goal-oriented Dialogue Systems.", ["Dilek Hakkani-Tur"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/4005.html", 1], ["Single-channel Speech Dereverberation via Generative Adversarial Training.", ["Chenxing Li", "Tieqiang Wang", "Shuang Xu", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2018-1234", 5], ["Single-Channel Dereverberation Using Direct MMSE Optimization and Bidirectional LSTM Networks.", ["Wolfgang Mack", "Soumitro Chakrabarty", "Fabian-Robert Stoter", "Sebastian Braun", "Bernd Edler", "Emanuel A. P. Habets"], "https://doi.org/10.21437/Interspeech.2018-1296", 5], ["Single-channel Late Reverberation Power Spectral Density Estimation Using Denoising Autoencoders.", ["Ina Kodrasi", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2018-1660", 5], ["A Non-convolutive NMF Model for Speech Dereverberation.", ["Nikhil Mohanan", "Rajbabu Velmurugan", "Preeti Rao"], "https://doi.org/10.21437/Interspeech.2018-1834", 5], ["Cross-Corpora Convolutional Deep Neural Network Dereverberation Preprocessing for Speaker Verification and Speech Enhancement.", ["Peter Guzewich", "Stephen A. Zahorian", "Xiao Chen", "Hao Zhang"], "https://doi.org/10.21437/Interspeech.2018-2238", 5], ["Dereverberation and Beamforming in Robust Far-Field Speaker Recognition.", ["Ladislav Mosner", "Oldrich Plchot", "Pavel Matejka", "Ondrej Novotny", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2018-2306", 5], ["Comparing the Max and Noisy-Or Pooling Functions in Multiple Instance Learning for Weakly Supervised Sequence Learning Tasks.", ["Yun Wang", "Juncheng Li", "Florian Metze"], "https://doi.org/10.21437/Interspeech.2018-990", 5], ["A Simple Model for Detection of Rare Sound Events.", ["Weiran Wang", "Chieh-Chi Kao", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2018-2338", 5], ["Temporal Transformer Networks for Acoustic Scene Classification.", ["Teng Zhang", "Kailai Zhang", "Ji Wu"], "https://doi.org/10.21437/Interspeech.2018-1152", 5], ["Temporal Attentive Pooling for Acoustic Event Detection.", ["Xugang Lu", "Peng Shen", "Sheng Li", "Yu Tsao", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2018-1552", 4], ["R-CRNN: Region-based Convolutional Recurrent Neural Network for Audio Event Detection.", ["Chieh-Chi Kao", "Weiran Wang", "Ming Sun", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2018-2323", 5], ["Detecting Media Sound Presence in Acoustic Scenes.", ["Constantinos Papayiannis", "Justice Amoh", "Viktor Rozgic", "Shiva Sundaram", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2018-2559", 5], ["S4D: Speaker Diarization Toolkit in Python.", ["Pierre-Alexandre Broux", "Florent Desnous", "Anthony Larcher", "Simon Petitrenaud", "Jean Carrive", "Sylvain Meignier"], "https://doi.org/10.21437/Interspeech.2018-1232", 5], ["Multimodal Speaker Segmentation and Diarization Using Lexical and Acoustic Cues via Sequence to Sequence Neural Networks.", ["Tae Jin Park", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2018-1364", 5], ["Combined Speaker Clustering and Role Recognition in Conversational Speech.", ["Nikolaos Flemotomos", "Pavlos Papadopoulos", "James Gibson", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1654", 5], ["The ACLEW DiViMe: An Easy-to-use Diarization Tool.", ["Adrien Le Franc", "Eric Riebling", "Julien Karadayi", "Yun Wang", "Camila Scaff", "Florian Metze", "Alejandrina Cristia"], "https://doi.org/10.21437/Interspeech.2018-2324", 5], ["Automatic Detection of Multi-speaker Fragments with High Time Resolution.", ["Evdokia Kazimirova", "Andrey Belyaev"], "https://doi.org/10.21437/Interspeech.2018-1878", 5], ["Neural Speech Turn Segmentation and Affinity Propagation for Speaker Diarization.", ["Ruiqing Yin", "Herve Bredin", "Claude Barras"], "https://doi.org/10.21437/Interspeech.2018-1750", 5], ["Pitch or Phonation: on the Glottalization in Tone Productions in the Ruokeng Hui Chinese Dialect.", ["Minghui Zhang", "Fang Hu"], "https://doi.org/10.21437/Interspeech.2018-1638", 5], ["Speaker-specific Structure in German Voiceless Stop Voice Onset Times.", ["Marc Antony Hullebus", "Stephen J. Tobin", "Adamantios I. Gafos"], "https://doi.org/10.21437/Interspeech.2018-2288", 5], ["Creak in the Respiratory Cycle.", ["Katlin Aare", "Partel Lippus", "Marcin Wlodarczak", "Mattias Heldner"], "https://doi.org/10.21437/Interspeech.2018-2165", 5], ["Acoustic Analysis of Whispery Voice Disguise in Mandarin Chinese.", ["Cuiling Zhang", "Bin Li", "Si Chen", "Yike Yang"], "https://doi.org/10.21437/Interspeech.2018-2598", 4], ["The Zurich Corpus of Vowel and Voice Quality, Version 1.0.", ["Dieter Maurer", "Christian dHeureuse", "Heidy Suter", "Volker Dellwo", "Daniel Friedrichs", "Thayabaran Kathiresan"], "https://doi.org/10.21437/Interspeech.2018-1542", 5], ["Weighting of Coda Voicing Cues: Glottalisation and Vowel Duration.", ["Joshua Penney", "Felicity Cox", "Anita Szakay"], "https://doi.org/10.21437/Interspeech.2018-1677", 5], ["Revealing Spatiotemporal Brain Dynamics of Speech Production Based on EEG and Eye Movement.", ["Bin Zhao", "Jinfeng Huang", "Gaoyan Zhang", "Jianwu Dang", "Minbo Chen", "YingjianFu", "Longbiao Wang"], "https://doi.org/10.21437/Interspeech.2018-1908", 5], ["Neural Response Development During Distributional Learning.", ["Natalie Boll-Avetisyan", "Jessie S. Nixon", "Tomas O. Lentz", "Liquan Liu", "Sandrien van Ommen", "Cagri Coltekin", "Jacolien van Rij"], "https://doi.org/10.21437/Interspeech.2018-2072", 5], ["Learning Two Tone Languages Enhances the Brainstem Encoding of Lexical Tones.", ["Akshay Raj Maggu", "Wenqing Zong", "Vina Law", "Patrick C. M. Wong"], "https://doi.org/10.21437/Interspeech.2018-2130", 5], ["Perceptual Sensitivity to Spectral Change in Australian English Close Front Vowels: An Electroencephalographic Investigation.", ["Daniel Williams", "Paola Escudero", "Adamantios I. Gafos"], "https://doi.org/10.21437/Interspeech.2018-2505", 5], ["Effective Acoustic Cue Learning Is Not Just Statistical, It Is Discriminative.", ["Jessie S. Nixon"], "https://doi.org/10.21437/Interspeech.2018-1024", 5], ["Analyzing EEG Signals in Auditory Speech Comprehension Using Temporal Response Functions and Generalized Additive Models.", ["Kimberley Mulder", "Louis ten Bosch", "Lou Boves"], "https://doi.org/10.21437/Interspeech.2018-1676", 5], ["Information Encoding by Deep Neural Networks: What Can We Learn?", ["Louis ten Bosch", "Lou Boves"], "https://doi.org/10.21437/Interspeech.2018-1896", 5], ["Scalable Factorized Hierarchical Variational Autoencoder Training.", ["Wei-Ning Hsu", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2018-1034", 5], ["State Gradients for RNN Memory Analysis.", ["Lyan Verwimp", "Hugo Van hamme", "Vincent Renkens", "Patrick Wambacq"], "https://doi.org/10.21437/Interspeech.2018-1153", 5], ["Exploring How Phone Classification Neural Networks Learn Phonetic Information by Visualising and Interpreting Bottleneck Features.", ["Linxue Bai", "Philip Weber", "Peter Jancovic", "Martin J. Russell"], "https://doi.org/10.21437/Interspeech.2018-2462", 5], ["Memory Time Span in LSTMs for Multi-Speaker Source Separation.", ["Jeroen Zegers", "Hugo Van hamme"], "https://doi.org/10.21437/Interspeech.2018-2082", 5], ["Visualizing Phoneme Category Adaptation in Deep Neural Networks.", ["Odette Scharenborg", "Sebastian Tiesmeyer", "Mark Hasegawa-Johnson", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-1707", 5], ["Early Vocabulary Development Through Picture-based Software Solutions.", ["G. R. Kasthuri", "Prabha Ramanathan", "Hema A. Murthy", "Namita Jacob", "Anil Prabhakar"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3022.html", 2], ["Automatic Detection of Expressiveness in Oral Reading.", ["Kamini Sabu", "Kanhaiya Kumar", "Preeti Rao"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3026.html", 2], ["PannoMulloKathan: Voice Enabled Mobile App for Agricultural Commodity Price Dissemination in Bengali Language.", ["Madhab Pal", "Rajib Roy", "Soma Khan", "Milton Samirakshma Bepari", "Joyanta Basu"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3027.html", 2], ["Visualizing Punctuation Restoration in Speech Transcripts with Prosograph.", ["Alp Oktem", "Mireia Farrus", "Antonio Bonafonte"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3028.html", 2], ["CACTAS - Collaborative Audio Categorization and Transcription for ASR Systems.", ["Mithul Mathivanan", "Kinnera Saranu", "Abhishek Pandey", "Jithendra Vepa"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3029.html", 2], ["FACTS: A Hierarchical Task-based Control Model of Speech Incorporating Sensory Feedback.", ["Benjamin Parrell", "Vikram Ramanarayanan", "Srikantan S. Nagarajan", "John F. Houde"], "https://doi.org/10.21437/Interspeech.2018-2087", 5], ["Sensorimotor Response to Tongue Displacement Imagery by Talkers with Parkinson's Disease.", ["William F. Katz", "Patrick Reidy", "Divya Prabhakaran"], "https://doi.org/10.21437/Interspeech.2018-2592", 5], ["Automatic Pronunciation Evaluation of Singing.", ["Chitralekha Gupta", "Haizhou Li", "Ye Wang"], "https://doi.org/10.21437/Interspeech.2018-1267", 5], ["Classification of Nonverbal Human Produced Audio Events: A Pilot Study.", ["Rachel E. Bouserhal", "Philippe Chabot", "Milton Sarria Paja", "Patrick Cardinal", "Jeremie Voix"], "https://doi.org/10.21437/Interspeech.2018-2299", 5], ["UltraFit: A Speaker-friendly Headset for Ultrasound Recordings in Speech Science.", ["Lorenzo Spreafico", "Michael Pucher", "Anna Matosova"], "https://doi.org/10.21437/Interspeech.2018-995", 4], ["Articulatory Consequences of Vocal Effort Elicitation Method.", ["Elisabet Eir Cortes", "Marcin Wlodarczak", "Juraj Simko"], "https://doi.org/10.21437/Interspeech.2018-1038", 5], ["Age-related Effects on Sensorimotor Control of Speech Production.", ["Anne Hermes", "Jane Mertens", "Doris Mucke"], "https://doi.org/10.21437/Interspeech.2018-1233", 5], ["An Ultrasound Study of Gemination in Coronal Stops in Eastern Oromo.", ["Maida Percival", "Alexei Kochetov", "Yoonjung Kang"], "https://doi.org/10.21437/Interspeech.2018-2512", 5], ["Processing Transition Regions of Glottal Stop Substituted /S/ for Intelligibility Enhancement of Cleft Palate Speech.", ["Protima Nomo Sudro", "Sishir Kalita", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2018-1646", 5], ["Reconstructing Neutral Speech from Tracheoesophageal Speech.", ["Abinay Reddy N", "M. V. Achuth Rao", "G. Nisha Meenakshi", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1907", 5], ["Automatic Evaluation of Soft Articulatory Contact for Stuttering Treatment.", ["Keiko Ochi", "Koichi Mori", "Naomi Sakai"], "https://doi.org/10.21437/Interspeech.2018-2544", 5], ["Korean Singing Voice Synthesis Based on an LSTM Recurrent Neural Network.", ["Juntae Kim", "Heejin Choi", "Jinuk Park", "Minsoo Hahn", "Sang-Jin Kim", "Jong-Jin Kim"], "https://doi.org/10.21437/Interspeech.2018-1575", 5], ["The Trajectory of Voice Onset Time with Vocal Aging.", ["Xuanda Chen", "Ziyu Xiong", "Jian Hu"], "https://doi.org/10.21437/Interspeech.2018-60", 5], ["The Fifth 'CHiME' Speech Separation and Recognition Challenge: Dataset, Task and Baselines.", ["Jon Barker", "Shinji Watanabe", "Emmanuel Vincent", "Jan Trmal"], "https://doi.org/10.21437/Interspeech.2018-1768", 5], ["Voices Obscured in Complex Environmental Settings (VOiCES) Corpus.", ["Colleen Richey", "Maria Auxiliadora Barrios", "Zeb Armstrong", "Chris Bartels", "Horacio Franco", "Martin Graciarena", "Aaron Lawson", "Mahesh Kumar Nandwana", "Allen R. Stauffer", "Julien van Hout", "Paul Gamble", "Jeffrey Hetherly", "Cory Stephenson", "Karl Ni"], "https://doi.org/10.21437/Interspeech.2018-1454", 5], ["Building State-of-the-art Distant Speech Recognition Using the CHiME-4 Challenge with a Setup of Speech Enhancement Baseline.", ["Szu-Jui Chen", "Aswin Shanmugam Subramanian", "Hainan Xu", "Shinji Watanabe"], "https://doi.org/10.21437/Interspeech.2018-1262", 5], ["Unsupervised Adaptation with Interpretable Disentangled Representations for Distant Conversational Speech Recognition.", ["Wei-Ning Hsu", "Hao Tang", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2018-1097", 5], ["Investigating Generative Adversarial Networks Based Speech Dereverberation for Robust Speech Recognition.", ["Ke Wang", "Junbo Zhang", "Sining Sun", "Yujun Wang", "Fei Xiang", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2018-1780", 5], ["Monaural Multi-Talker Speech Recognition with Attention Mechanism and Gated Convolutional Networks.", ["Xuankai Chang", "Yanmin Qian", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1547", 5], ["Weighting Time-Frequency Representation of Speech Using Auditory Saliency for Automatic Speech Recognition.", ["Cong-Thanh Do", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2018-1721", 5], ["Acoustic Modeling from Frequency Domain Representations of Speech.", ["Pegah Ghahremani", "Hossein Hadian", "Hang Lv", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1453", 5], ["Non-Uniform Spectral Smoothing for Robust Children's Speech Recognition.", ["Ishwar Chandra Yadav", "Avinash Kumar", "Syed Shahnawazuddin", "Gayadhar Pradhan"], "https://doi.org/10.21437/Interspeech.2018-1828", 5], ["Bidirectional Long-Short Term Memory Network-based Estimation of Reliable Spectral Component Locations.", ["Aaron Nicolson", "Kuldip K. Paliwal"], "https://doi.org/10.21437/Interspeech.2018-1134", 5], ["Speech Emotion Recognition by Combining Amplitude and Phase Information Using Convolutional Neural Network.", ["Lili Guo", "Longbiao Wang", "Jianwu Dang", "Linjuan Zhang", "Haotian Guan", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2018-2156", 5], ["Bubble Cooperative Networks for Identifying Important Speech Cues.", ["Viet Anh Trinh", "Brian McFee", "Michael I. Mandel"], "https://doi.org/10.21437/Interspeech.2018-2377", 5], ["Real-Time Scoring of an Oral Reading Assessment on Mobile Devices.", ["Jian Cheng"], "https://doi.org/10.21437/Interspeech.2018-34", 5], ["A Deep Learning Approach to Assessing Non-native Pronunciation of English Using Phone Distances.", ["Konstantinos Kyriakopoulos", "Kate Knill", "Mark J. F. Gales"], "https://doi.org/10.21437/Interspeech.2018-1087", 5], ["Paired Phone-Posteriors Approach to ESL Pronunciation Quality Assessment.", ["Yujia Xiao", "Frank K. Soong", "Wenping Hu"], "https://doi.org/10.21437/Interspeech.2018-1270", 5], ["Investigating the Role of L1 in Automatic Pronunciation Evaluation of L2 Speech.", ["Ming Tu", "Anna Grabek", "Julie Liss", "Visar Berisha"], "https://doi.org/10.21437/Interspeech.2018-1350", 5], ["Impact of ASR Performance on Free Speaking Language Assessment.", ["Kate Knill", "Mark J. F. Gales", "Konstantinos Kyriakopoulos", "Andrey Malinin", "Anton Ragni", "Yu Wang", "Andrew Caines"], "https://doi.org/10.21437/Interspeech.2018-1312", 5], ["Automatic Miscue Detection Using RNN Based Models with Data Augmentation.", ["Yoon Seok Hong", "Kyung Seo Ki", "Gahgene Gweon"], "https://doi.org/10.21437/Interspeech.2018-1644", 5], ["A Study of Objective Measurement of Comprehensibility through Native Speakers' Shadowing of Learners' Utterances.", ["Yusuke Inoue", "Suguru Kabashima", "Daisuke Saito", "Nobuaki Minematsu", "Kumi Kanamura", "Yutaka Yamauchi"], "https://doi.org/10.21437/Interspeech.2018-1860", 5], ["Factorized Deep Neural Network Adaptation for Automatic Scoring of L2 Speech in English Speaking Tests.", ["Dean Luo", "Chunxiao Zhang", "Linzhong Xia", "Lixin Wang"], "https://doi.org/10.21437/Interspeech.2018-2138", 5], ["On the Difficulties of Automatic Speech Recognition for Kindergarten-Aged Children.", ["Gary Yeung", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2018-2297", 5], ["Improved Acoustic Modelling for Automatic Literacy Assessment of Children.", ["Mauro Nicolao", "Michiel Sanders", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2018-2118", 5], ["Anomaly Detection Approach for Pronunciation Verification of Disordered Speech Using Speech Attribute Features.", ["Mostafa Ali Shahin", "Beena Ahmed", "Jim X. Ji", "Kirrie J. Ballard"], "https://doi.org/10.21437/Interspeech.2018-1319", 5], ["Effectiveness of Voice Quality Features in Detecting Depression.", ["Amber Afshan", "Jinxi Guo", "Soo Jin Park", "Vijay Ravi", "Jonathan Flint", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2018-1399", 5], ["Fusing Text-dependent Word-level i-Vector Models to Screen 'at Risk' Child Speech.", ["Prasanna V. Kothalkar", "Johanna Rudolph", "Christine Dollaghan", "Jennifer McGlothlin", "Thomas F. Campbell", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-1465", 5], ["Testing Paradigms for Assistive Hearing Devices in Diverse Acoustic Environments.", ["Ram Charan Chandra Shekar", "Hussnain Ali", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-1471", 5], ["Detection of Dementia from Responses to Atypical Questions Asked by Embodied Conversational Agents.", ["Tsuyoki Ujiro", "Hiroki Tanaka", "Hiroyoshi Adachi", "Hiroaki Kazui", "Manabu Ikeda", "Takashi Kudo", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2018-1514", 5], ["Acoustic Features Associated with Sustained Vowel and Continuous Speech Productions by Chinese Children with Functional Articulation Disorders.", ["Wang Zhang", "Xiangquan Gui", "Tianqi Wang", "Manwa L. Ng", "Feng Yang", "Lan Wang", "Nan Yan"], "https://doi.org/10.21437/Interspeech.2018-1521", 5], ["Estimation of Hypernasality Scores from Cleft Lip and Palate Speech.", ["Vikram C. M.", "Ayush Tripathi", "Sishir Kalita", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2018-1631", 5], ["Detecting Alzheimer's Disease Using Gated Convolutional Neural Network from Audio Data.", ["Tifani Warnita", "Nakamasa Inoue", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2018-1713", 5], ["Automatic Detection of Orofacial Impairment in Stroke.", ["Andrea Bandini", "Jordan R. Green", "Brian Richburg", "Yana Yunusova"], "https://doi.org/10.21437/Interspeech.2018-2475", 5], ["Detecting Depression with Audio/Text Sequence Modeling of Interviews.", ["Tuka Al Hanai", "Mohammad M. Ghassemi", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2018-2522", 5], ["Discourse Marker Detection for Hesitation Events on Mandarin Conversation.", ["Yu-Wun Wang", "Hen-Hsen Huang", "Kuan-Yu Chen", "Hsin-Hsi Chen"], "https://doi.org/10.21437/Interspeech.2018-2129", 5], ["Acoustic and Perceptual Characteristics of Mandarin Speech in Homosexual and Heterosexual Male Speakers.", ["Puyang Geng", "Wentao Gu", "Hiroya Fujisaki"], "https://doi.org/10.21437/Interspeech.2018-2225", 5], ["Automatic Question Detection from Acoustic and Phonetic Features Using Feature-wise Pre-training.", ["Atsushi Ando", "Reine Asakawa", "Ryo Masumura", "Hosana Kamiyama", "Satoshi Kobashikawa", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-1755", 5], ["Improving Response Time of Active Speaker Detection Using Visual Prosody Information Prior to Articulation.", ["Fasih Haider", "Saturnino Luz", "Carl Vogel", "Nick Campbell"], "https://doi.org/10.21437/Interspeech.2018-2310", 5], ["Audio-Visual Prediction of Head-Nod and Turn-Taking Events in Dyadic Interactions.", ["Bekir Berker Turker", "Engin Erzin", "Yucel Yemez", "T. Metin Sezgin"], "https://doi.org/10.21437/Interspeech.2018-2215", 5], ["Analyzing Effect of Physical Expression on English Proficiency for Multimodal Computer-Assisted Language Learning.", ["Haoran Wu", "Yuya Chiba", "Takashi Nose", "Akinori Ito"], "https://doi.org/10.21437/Interspeech.2018-1425", 5], ["Analysis of the Effect of Speech-Laugh on Speaker Recognition System.", ["Sri Harsha Dumpala", "Ashish Panda", "Sunil Kumar Kopparapu"], "https://doi.org/10.21437/Interspeech.2018-2090", 5], ["Vocal Biomarkers for Cognitive Performance Estimation in a Working Memory Task.", ["Jennifer Sloboda", "Adam C. Lammert", "James R. Williamson", "Christopher J. Smalt", "Daryush D. Mehta", "C. O. L. Ian Curry", "Kristin Heaton", "Jeff Palmer", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2018-2418", 5], ["Lexical and Acoustic Deep Learning Model for Personality Recognition.", ["Guozhen An", "Rivka Levitan"], "https://doi.org/10.21437/Interspeech.2018-2263", 5], ["Open Problems in Speech Recognition.", ["Bhuvana Ramabhadran"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/4006.html", 1], ["Evolution of Neural Network Architectures for Speech Recognition.", ["Herve Bourlard"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/4003.html", 1], ["Layer Trajectory LSTM.", ["Jinyu Li", "Changliang Liu", "Yifan Gong"], "https://doi.org/10.21437/Interspeech.2018-1485", 5], ["Semi-tied Units for Efficient Gating in LSTM and Highway Networks.", ["Chao Zhang", "Philip C. Woodland"], "https://doi.org/10.21437/Interspeech.2018-2158", 5], ["Gaussian Process Neural Networks for Speech Recognition.", ["Max W. Y. Lam", "Shoukang Hu", "Xurong Xie", "Shansong Liu", "Jianwei Yu", "Rongfeng Su", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1823", 5], ["Acoustic Modeling with Densely Connected Residual Network for Multichannel Speech Recognition.", ["Jian Tang", "Yan Song", "Lirong Dai", "Ian Vince McLoughlin"], "https://doi.org/10.21437/Interspeech.2018-1089", 5], ["Gated Recurrent Unit Based Acoustic Modeling with Future Context.", ["Jie Li", "Xiaorui Wang", "Yuanyuan Zhao", "Yan Li"], "https://doi.org/10.21437/Interspeech.2018-1544", 5], ["Output-Gate Projected Gated Recurrent Unit for Speech Recognition.", ["Gaofeng Cheng", "Daniel Povey", "Lu Huang", "Ji Xu", "Sanjeev Khudanpur", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1403", 5], ["Performance Analysis of the 2017 NIST Language Recognition Evaluation.", ["Seyed Omid Sadjadi", "Timothee Kheyrkhah", "Craig S. Greenberg", "Elliot Singer", "Douglas A. Reynolds", "Lisa P. Mason", "Jaime Hernandez-Cordero"], "https://doi.org/10.21437/Interspeech.2018-69", 5], ["Using Deep Neural Networks for Identification of Slavic Languages from Acoustic Signal.", ["Lukas Mateju", "Petr Cerva", "Jindrich Zdansky", "Radek Safarik"], "https://doi.org/10.21437/Interspeech.2018-1165", 5], ["Adding New Classes without Access to the Original Training Data with Applications to Language Identification.", ["Hagai Taitelbaum", "Ehud Ben-Reuven", "Jacob Goldberger"], "https://doi.org/10.21437/Interspeech.2018-1342", 5], ["Feature Representation of Short Utterances Based on Knowledge Distillation for Spoken Language Identification.", ["Peng Shen", "Xugang Lu", "Sheng Li", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2018-1519", 5], ["Sub-band Envelope Features Using Frequency Domain Linear Prediction for Short Duration Language Identification.", ["Sarith Fernando", "Vidhyasaharan Sethu", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2018-1805", 5], ["Effectiveness of Single-Channel BLSTM Enhancement for Language Identification.", ["Peter Sibbern Frederiksen", "Jesus Villalba", "Shinji Watanabe", "Zheng-Hua Tan", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2458", 5], ["Articulation Rate as a Speaker Discriminant in British English.", ["Erica Gold"], "https://doi.org/10.21437/Interspeech.2018-1384", 5], ["Truncation and Compression in Southern German and Australian English.", ["Jenny Yu", "Katharina Zahner"], "https://doi.org/10.21437/Interspeech.2018-2513", 5], ["Prominence-based Evaluation of L2 Prosody.", ["Heini Kallio", "Antti Suni", "Paivi Virkkunen", "Juraj Simko"], "https://doi.org/10.21437/Interspeech.2018-1873", 5], ["Length Contrast and Covarying Features: Whistled Speech as a Case Study.", ["Rachid Ridouane", "Giuseppina Turco", "Julien Meyer"], "https://doi.org/10.21437/Interspeech.2018-1060", 5], ["Information Structure, Affect and Prenuclear Prominence in American English.", ["Eleanor Chodroff", "Jennifer Cole"], "https://doi.org/10.21437/Interspeech.2018-1529", 5], ["Effects of User Controlled Speech Rate on Intelligibility in Noisy Environments.", ["John S. Novak III", "Robert V. Kenyon"], "https://doi.org/10.21437/Interspeech.2018-63", 5], ["Binaural Speech Intelligibility Estimation Using Deep Neural Networks.", ["Kazuhiro Kondo", "Kazuya Taira", "Yosuke Kobayashi"], "https://doi.org/10.21437/Interspeech.2018-27", 5], ["Multi-resolution Gammachirp Envelope Distortion Index for Intelligibility Prediction of Noisy Speech.", ["Katsuhiko Yamamoto", "Toshio Irino", "Narumi Ohashi", "Shoko Araki", "Keisuke Kinoshita", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2018-1291", 5], ["Speech Intelligibility Enhancement Based on a Non-causal Wavenet-like Model.", ["P. V. Muhammed Shifas", "Vassilis Tsiaras", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2018-2119", 5], ["Quality-Net: An End-to-End Non-intrusive Speech Quality Assessment Model Based on BLSTM.", ["Szu-Wei Fu", "Yu Tsao", "Hsin-Te Hwang", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2018-1802", 5], ["Global SNR Estimation of Speech Signals Using Entropy and Uncertainty Estimates from Dropout Networks.", ["Rohith Aralikatti", "Dilip Kumar Margam", "Tanay Sharma", "Abhinav Thanda", "Shankar M. Venkatesan"], "https://doi.org/10.21437/Interspeech.2018-1884", 5], ["Detecting Packet-Loss Concealment Using Formant Features and Decision Tree Learning.", ["Gabriel Mittag", "Sebastian Moller"], "https://doi.org/10.21437/Interspeech.2018-1098", 5], ["UltraSuite: A Repository of Ultrasound and Acoustic Data from Child Speech Therapy Sessions.", ["Aciel Eshky", "Manuel Sam Ribeiro", "Joanne Cleland", "Korin Richmond", "Zoe Roxburgh", "James M. Scobbie", "Alan Wrench"], "https://doi.org/10.21437/Interspeech.2018-1736", 5], ["Detecting Signs of Dementia Using Word Vector Representations.", ["Bahman Mirheidari", "Daniel Blackburn", "Traci Walker", "Annalena Venneri", "Markus Reuber", "Heidi Christensen"], "https://doi.org/10.21437/Interspeech.2018-1764", 5], ["Classification of Huntington Disease Using Acoustic and Lexical Features.", ["Matthew Perez", "Wenyu Jin", "Duc Le", "Noelle Carlozzi", "Praveen Dayalu", "Angela Roberts", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2018-2029", 5], ["The PRIORI Emotion Dataset: Linking Mood to Emotion Detected In-the-Wild.", ["Soheil Khorram", "Mimansa Jaiswal", "John Gideon", "Melvin G. McInnis", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2018-2355", 5], ["Language Features for Automated Evaluation of Cognitive Behavior Psychotherapy Sessions.", ["Nikolaos Flemotomos", "Victor R. Martinez", "James Gibson", "David C. Atkins", "Torrey Creed", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1518", 5], ["Automatic Early Detection of Amyotrophic Lateral Sclerosis from Intelligible Speech Using Convolutional Neural Networks.", ["Kwanghoon An", "Myung Jong Kim", "Kristin Teplansky", "Jordan R. Green", "Thomas Campbell", "Yana Yunusova", "Daragh Heitzman", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2018-2496", 5], ["A Study of Lexical and Prosodic Cues to Segmentation in a Hindi-English Code-switched Discourse.", ["Preeti Rao", "Mugdha Pandya", "Kamini Sabu", "Kanhaiya Kumar", "Nandini Bondale"], "https://doi.org/10.21437/Interspeech.2018-1600", 5], ["Building a Unified Code-Switching ASR System for South African Languages.", ["Emre Yilmaz", "Astik Biswas", "Ewald van der Westhuizen", "Febe de Wet", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2018-1966", 5], ["Study of Semi-supervised Approaches to Improving English-Mandarin Code-Switching Speech Recognition.", ["Pengcheng Guo", "Haihua Xu", "Lei Xie", "Eng Siong Chng"], "https://doi.org/10.21437/Interspeech.2018-1974", 5], ["Acoustic and Textual Data Augmentation for Improved ASR of Code-Switching Speech.", ["Emre Yilmaz", "Henk van den Heuvel", "David A. van Leeuwen"], "https://doi.org/10.21437/Interspeech.2018-52", 5], ["The Role of Cognate Words, POS Tags and Entrainment in Code-Switching.", ["Victor Soto", "Nishmar Cestero", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2018-1099", 5], ["Homophone Identification and Merging for Code-switched Speech Recognition.", ["Brij Mohan Lal Srivastava", "Sunayana Sitaram"], "https://doi.org/10.21437/Interspeech.2018-1171", 5], ["Code-switching in Indic Speech Synthesisers.", ["Anju Leela Thomas", "Anusha Prakash", "Arun Baby", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2018-1178", 5], ["A Novel Approach for Effective Recognition of the Code-Switched Data on Monolingual Language Model.", ["Ganji Sreeram", "Rohit Sinha"], "https://doi.org/10.21437/Interspeech.2018-1259", 5], ["Hierarchical Accent Determination and Application in a Large Scale ASR System.", ["Ramya Viswanathan", "Periyasamy Paramasivam", "Jithendra Vepa"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3030.html", 2], ["Toward Scalable Dialog Technology for Conversational Language Learning: Case Study of the TOEFL\u00ae MOOC.", ["Vikram Ramanarayanan", "David Pautler", "Patrick L. Lange", "Eugene Tsuprun", "Rutuja Ubale", "Keelan Evanini", "David Suendermann-Oeft"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3032.html", 2], ["Machine Learning Powered Data Platform for High-Quality Speech and NLP Workflows.", ["Joao Freitas", "Jorge Ribeiro", "Daan Baldewijns", "Sara Oliveira", "Daniela Braga"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3033.html", 2], ["Fully Automatic Speaker Separation System, with Automatic Enrolling of Recurrent Speakers.", ["Raphael Cohen", "Orgad Keller", "Jason Levy", "Russell Levy", "Micha Breakstone", "Amit Ashkenazi"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3034.html", 2], ["Online Speech Translation System for Tamil.", ["Madhavaraj Ayyavu", "Shiva Kumar H. R", "Ramakrishnan A. G"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3035.html", 2], ["Unsupervised Vocal Tract Length Warped Posterior Features for Non-Parallel Voice Conversion.", ["Nirmesh J. Shah", "Maulik C. Madhavi", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1712", 5], ["Voice Conversion with Conditional SampleRNN.", ["Cong Zhou", "Michael Horgan", "Vivek Kumar", "Cristina Vasco", "Dan Darcy"], "https://doi.org/10.21437/Interspeech.2018-1121", 5], ["A Voice Conversion Framework with Tandem Feature Sparse Representation and Speaker-Adapted WaveNet Vocoder.", ["Berrak Sisman", "Mingyang Zhang", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2018-1131", 5], ["WaveNet Vocoder with Limited Training Data for Voice Conversion.", ["Li-Juan Liu", "Zhen-Hua Ling", "Yuan Jiang", "Ming Zhou", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2018-1190", 5], ["Collapsed Speech Segment Detection and Suppression for WaveNet Vocoder.", ["Yi-Chiao Wu", "Kazuhiro Kobayashi", "Tomoki Hayashi", "Patrick Lumban Tobing", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2018-1210", 5], ["High-quality Voice Conversion Using Spectrogram-Based WaveNet Vocoder.", ["Kuan Chen", "Bo Chen", "Jiahao Lai", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2018-1528", 5], ["Spanish Statistical Parametric Speech Synthesis Using a Neural Vocoder.", ["Antonio Bonafonte", "Santiago Pascual", "Georgina Dorca"], "https://doi.org/10.21437/Interspeech.2018-2417", 4], ["Experiments with Training Corpora for Statistical Text-to-speech Systems.", ["Monika Podsiadlo", "Victor Ungureanu"], "https://doi.org/10.21437/Interspeech.2018-2400", 5], ["Multi-task WaveNet: A Multi-task Generative Model for Statistical Parametric Speech Synthesis without Fundamental Frequency Conditions.", ["Yu Gu", "Yongguo Kang"], "https://doi.org/10.21437/Interspeech.2018-1506", 5], ["Speaker-independent Raw Waveform Model for Glottal Excitation.", ["Lauri Juvela", "Vassilis Tsiaras", "Bajibabu Bollepalli", "Manu Airaksinen", "Junichi Yamagishi", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2018-1635", 5], ["A New Glottal Neural Vocoder for Speech Synthesis.", ["Yang Cui", "Xi Wang", "Lei He", "Frank K. Soong"], "https://doi.org/10.21437/Interspeech.2018-1757", 5], ["Exemplar-based Speech Waveform Generation.", ["Oliver Watts", "Cassia Valentini-Botinhao", "Felipe Espic", "Simon King"], "https://doi.org/10.21437/Interspeech.2018-1857", 5], ["Frequency Domain Variants of Velvet Noise and Their Application to Speech Processing and Synthesis.", ["Hideki Kawahara", "Ken-Ichi Sakakibara", "Masanori Morise", "Hideki Banno", "Tomoki Toda", "Toshio Irino"], "https://doi.org/10.21437/Interspeech.2018-43", 5], ["Joint Learning of Interactive Spoken Content Retrieval and Trainable User Simulator.", ["Pei-Hung Chung", "Kuan Tung", "Ching-Lun Tai", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2018-1346", 5], ["Attention-based End-to-End Models for Small-Footprint Keyword Spotting.", ["Changhao Shan", "Junbo Zhang", "Yujun Wang", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2018-1777", 5], ["Prediction of Aesthetic Elements in Karnatic Music: A Machine Learning Approach.", ["Ragesh Rajan M", "Ashwin Vijayakumar", "Deepu Vijayasenan"], "https://doi.org/10.21437/Interspeech.2018-991", 5], ["Topic and Keyword Identification for Low-resourced Speech Using Cross-Language Transfer Learning.", ["Wenda Chen", "Mark Hasegawa-Johnson", "Nancy F. Chen"], "https://doi.org/10.21437/Interspeech.2018-1283", 5], ["Automatic Speech Recognition and Topic Identification from Speech for Almost-Zero-Resource Languages.", ["Matthew Wiesner", "Chunxi Liu", "Lucas Ondel", "Craig Harman", "Vimal Manohar", "Jan Trmal", "Zhongqiang Huang", "Najim Dehak", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1836", 5], ["Play Duration Based User-Entity Affinity Modeling in Spoken Dialog System.", ["Bo Xiao", "Nicholas Monath", "Shankar Ananthakrishnan", "Abishek Ravi"], "https://doi.org/10.21437/Interspeech.2018-1100", 5], ["Empirical Analysis of Score Fusion Application to Combined Neural Networks for Open Vocabulary Spoken Term Detection.", ["Shi-wook Lee", "Kazuyo Tanaka", "Yoshiaki Itoh"], "https://doi.org/10.21437/Interspeech.2018-1776", 5], ["Phonological Posterior Hashing for Query by Example Spoken Term Detection.", ["Afsaneh Asaei", "Dhananjay Ram", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2018-1973", 5], ["Term Extraction via Neural Sequence Labeling a Comparative Evaluation of Strategies Using Recurrent Neural Networks.", ["Maren Kucza", "Jan Niehues", "Thomas Zenkel", "Alex Waibel", "Sebastian Stuker"], "https://doi.org/10.21437/Interspeech.2018-2017", 5], ["Semi-supervised Learning for Information Extraction from Dialogue.", ["Anjuli Kannan", "Kai Chen", "Diana Jaunzeikare", "Alvin Rajkomar"], "https://doi.org/10.21437/Interspeech.2018-1318", 5], ["Slot Filling with Delexicalized Sentence Generation.", ["Youhyun Shin", "Kang Min Yoo", "Sang-goo Lee"], "https://doi.org/10.21437/Interspeech.2018-1808", 5], ["Music Genre Recognition Using Deep Neural Networks and Transfer Learning.", ["Deepanway Ghosal", "Maheshkumar H. Kolekar"], "https://doi.org/10.21437/Interspeech.2018-2045", 5], ["Efficient Voice Trigger Detection for Low Resource Hardware.", ["Siddharth Sigtia", "Rob Haynes", "Hywel Richards", "Erik Marchi", "John Bridle"], "https://doi.org/10.21437/Interspeech.2018-2204", 5], ["A Novel Normalization Method for Autocorrelation Function for Pitch Detection and for Speech Activity Detection.", ["Qiguang Lin", "Yiwen Shao"], "https://doi.org/10.21437/Interspeech.2018-45", 5], ["Estimation of the Vocal Tract Length of Vowel Sounds Based on the Frequency of the Significant Spectral Valley.", ["T. V. Ananthapadmanabha", "Ramakrishnan A. G."], "https://doi.org/10.21437/Interspeech.2018-1105", 5], ["Deep Learning Techniques for Koala Activity Detection.", ["Ivan Himawan", "Michael Towsey", "Bradley Law", "Paul Roe"], "https://doi.org/10.21437/Interspeech.2018-1143", 5], ["Glottal Closure Instant Detection from Speech Signal Using Voting Classifier and Recursive Feature Elimination.", ["Jindrich Matousek", "Daniel Tihelka"], "https://doi.org/10.21437/Interspeech.2018-1147", 5], ["Assessing Speaker Engagement in 2-Person Debates: Overlap Detection in United States Presidential Debates.", ["Midia Yousefi", "Navid Shokouhi", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-1463", 5], ["All-Conv Net for Bird Activity Detection: Significance of Learned Pooling.", ["Arjun Pankajakshan", "Anshul Thakur", "Daksh Thapar", "Padmanabhan Rajan", "Aditya Nigam"], "https://doi.org/10.21437/Interspeech.2018-1522", 5], ["Deep Convex Representations: Feature Representations for Bioacoustics Classification.", ["Anshul Thakur", "Vinayak Abrol", "Pulkit Sharma", "Padmanabhan Rajan"], "https://doi.org/10.21437/Interspeech.2018-1705", 5], ["Detection of Glottal Excitation Epochs in Speech Signal Using Hilbert Envelope.", ["Hirak Dasgupta", "Prem C. Pandey", "K. S. Nataraj"], "https://doi.org/10.21437/Interspeech.2018-2014", 5], ["Analyzing Thai Tone Distribution through Functional Data Analysis.", ["Hong Zhang"], "https://doi.org/10.21437/Interspeech.2018-2115", 5], ["Articulatory Feature Classification Using Convolutional Neural Networks.", ["Danny Merkx", "Odette Scharenborg"], "https://doi.org/10.21437/Interspeech.2018-2275", 5], ["A New Frequency Coverage Metric and a New Subband Encoding Model, with an Application in Pitch Estimation.", ["Shoufeng Lin"], "https://doi.org/10.21437/Interspeech.2018-2590", 5], ["Improved Epoch Extraction from Telephonic Speech Using Chebfun and Zero Frequency Filtering.", ["B. Ganga Gowri", "Soman K. P", "D. Govind"], "https://doi.org/10.21437/Interspeech.2018-1173", 5], ["An Empirical Analysis of the Correlation of Syntax and Prosody.", ["Arne Kohn", "Timo Baumann", "Oskar Dorfler"], "https://doi.org/10.21437/Interspeech.2018-2530", 5], ["Analysing the Focus of a Hierarchical Attention Network: the Importance of Enjambments When Classifying Post-modern Poetry.", ["Timo Baumann", "Hussein Hussein", "Burkhard Meyer-Sickendiek"], "https://doi.org/10.21437/Interspeech.2018-2533", 5], ["Language-Dependent Melody Embeddings.", ["Daniil Kocharov", "Alla Menshikova"], "https://doi.org/10.21437/Interspeech.2018-1962", 4], ["Stress Distribution of Given Information in Chinese Reading Texts.", ["Yuan Jia", "Xiaoxiao Ma"], "https://doi.org/10.21437/Interspeech.2018-1602", 5], ["Acoustic-prosodic Entrainment in Structural Metadata Events.", ["Vera Cabarrao", "Fernando Batista", "Helena Moniz", "Isabel Trancoso", "Ana Isabel Mata"], "https://doi.org/10.21437/Interspeech.2018-2366", 5], ["Formant Measures of Vowels Adjacent to Alveolar and Retroflex Consonants in Arrernte: Stressed and Unstressed Position.", ["Marija Tabain", "Richard Beare", "Andrew Butcher"], "https://doi.org/10.21437/Interspeech.2018-1126", 5], ["Automatic Assessment of L2 English Word Prosody Using Weighted Distances of F0 and Intensity Contours.", ["Quy-Thao Truong", "Tsuneo Kato", "Seiichi Yamamoto"], "https://doi.org/10.21437/Interspeech.2018-1386", 5], ["Homogeneity vs Heterogeneity in Indian English: Investigating Influences of L1 on f0 Range.", ["Olga Maxwell", "Elinor Payne", "Rosey Billington"], "https://doi.org/10.21437/Interspeech.2018-1476", 5], ["Emotional Prosody Perception in Mandarin-speaking Congenital Amusics.", ["Yixin Zhang", "Tianzhu Geng", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2018-91", 5], ["Cultural Differences in Pattern Matching: Multisensory Recognition of Socio-affective Prosody.", ["Takaaki Shochi", "Jean-Luc Rouas", "Marine Guerry", "Donna Erickson"], "https://doi.org/10.21437/Interspeech.2018-1795", 5], ["Speech Processing in the Human Brain Meets Deep Learning.", ["Nima Mesgarani"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/4007.html", 1], ["ESPnet: End-to-End Speech Processing Toolkit.", ["Shinji Watanabe", "Takaaki Hori", "Shigeki Karita", "Tomoki Hayashi", "Jiro Nishitoba", "Yuya Unno", "Nelson Enrique Yalta Soplin", "Jahn Heymann", "Matthew Wiesner", "Nanxin Chen", "Adithya Renduchintala", "Tsubasa Ochiai"], "https://doi.org/10.21437/Interspeech.2018-1456", 5], ["A GPU-based WFST Decoder with Exact Lattice Generation.", ["Zhehuai Chen", "Justin Luitjens", "Hainan Xu", "Yiming Wang", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1339", 5], ["Automatic Speech Recognition System Development in the \"Wild\".", ["Anton Ragni", "Mark J. F. Gales"], "https://doi.org/10.21437/Interspeech.2018-1085", 5], ["Semantic Lattice Processing in Contextual Automatic Speech Recognition for Google Assistant.", ["Leonid Velikovich", "Ian Williams", "Justin Scheiner", "Petar S. Aleksic", "Pedro J. Moreno", "Michael Riley"], "https://doi.org/10.21437/Interspeech.2018-2453", 5], ["Contextual Speech Recognition in End-to-end Neural Network Systems Using Beam Search.", ["Ian Williams", "Anjuli Kannan", "Petar S. Aleksic", "David Rybach", "Tara N. Sainath"], "https://doi.org/10.21437/Interspeech.2018-2416", 5], ["Forward-Backward Attention Decoder.", ["Masato Mimura", "Shinsuke Sakai", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2018-1160", 5], ["Learning Discriminative Features for Speaker Identification and Verification.", ["Sarthak Yadav", "Atul Rai"], "https://doi.org/10.21437/Interspeech.2018-1015", 5], ["Triplet Loss Based Cosine Similarity Metric Learning for Text-independent Speaker Recognition.", ["Sergey Novoselov", "Vadim Shchemelinin", "Andrey Shulipa", "Alexander Kozlov", "Ivan Kremnev"], "https://doi.org/10.21437/Interspeech.2018-1209", 5], ["Speaker Embedding Extraction with Phonetic Information.", ["Yi Liu", "Liang He", "Jia Liu", "Michael T. Johnson"], "https://doi.org/10.21437/Interspeech.2018-1226", 5], ["Attentive Statistics Pooling for Deep Speaker Embedding.", ["Koji Okabe", "Takafumi Koshinaka", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2018-993", 5], ["Robust and Discriminative Speaker Embedding via Intra-Class Distance Variance Regularization.", ["Nam Le", "Jean-Marc Odobez"], "https://doi.org/10.21437/Interspeech.2018-1685", 5], ["Deep Discriminative Embeddings for Duration Robust Speaker Verification.", ["Na Li", "Deyi Tuo", "Dan Su", "Zhifeng Li", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1769", 5], ["Impact of Different Speech Types on Listening Effort.", ["Olympia Simantiraki", "Martin Cooke", "Simon King"], "https://doi.org/10.21437/Interspeech.2018-1358", 5], ["Who Are You Listening to? Towards a Dynamic Measure of Auditory Attention to Speech-on-speech.", ["Moira-Phoebe Huet", "Christophe Micheyl", "Etienne Gaudrain", "Etienne Parizet"], "https://doi.org/10.21437/Interspeech.2018-2053", 4], ["Investigating the Role of Familiar Face and Voice Cues in Speech Processing in Noise.", ["Jeesun Kim", "Sonya Karisma", "Vincent Aubanel", "Chris Davis"], "https://doi.org/10.21437/Interspeech.2018-1812", 4], ["The Conversation Continues: the Effect of Lyrics and Music Complexity of Background Music on Spoken-Word Recognition.", ["Odette Scharenborg", "Martha Larson"], "https://doi.org/10.21437/Interspeech.2018-1088", 5], ["Loud and Shouted Speech Perception at Variable Distances in a Forest.", ["Julien Meyer", "Fanny Meunier", "Laure Dentel", "Noelia Do Carmo Blanco", "Frederic Sebe"], "https://doi.org/10.21437/Interspeech.2018-2089", 5], ["Phoneme Resistance and Phoneme Confusion in Noise: Impact of Dyslexia.", ["Noelia Do Carmo Blanco", "Julien Meyer", "Michel Hoen", "Fanny Meunier"], "https://doi.org/10.21437/Interspeech.2018-1271", 5], ["Conditional End-to-End Audio Transforms.", ["Albert Haque", "Michelle Guo", "Prateek Verma"], "https://doi.org/10.21437/Interspeech.2018-38", 5], ["Detection of Glottal Closure Instants in Degraded Speech Using Single Frequency Filtering Analysis.", ["Gunnam Aneeja", "Sudarsana Reddy Kadiri", "Bayya Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2018-1018", 5], ["Tone Recognition Using Lifters and CTC.", ["Loren Lugosch", "Vikrant Singh Tomar"], "https://doi.org/10.21437/Interspeech.2018-2293", 5], ["Epoch Extraction from Pathological Children Speech Using Single Pole Filtering Approach.", ["Vikram C. M.", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2018-1613", 5], ["Automated Classification of Vowel-Gesture Parameters Using External Broadband Excitation.", ["Balamurali B. T", "Jer-Ming Chen"], "https://doi.org/10.21437/Interspeech.2018-1756", 4], ["Estimation of Fundamental Frequency from Singing Voice Using Harmonics of Impulse-like Excitation Source.", ["Sudarsana Reddy Kadiri", "Bayya Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2018-2495", 5], ["Investigating the Effect of Audio Duration on Dementia Detection Using Acoustic Features.", ["Jochen Weiner", "Miguel Angrick", "Srinivasan Umesh", "Tanja Schultz"], "https://doi.org/10.21437/Interspeech.2018-57", 5], ["An Interlocutor-Modulated Attentional LSTM for Differentiating between Subgroups of Autism Spectrum Disorder.", ["Yun-Shao Lin", "Susan Shur-Fen Gau", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2018-1288", 5], ["Recognition of Echolalic Autistic Child Vocalisations Utilising Convolutional Recurrent Neural Networks.", ["Shahin Amiriparian", "Alice Baird", "Sahib Julka", "Alyssa Alcorn", "Sandra Ottl", "Suncica Petrovic", "Eloise Ainger", "Nicholas Cummins", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1772", 5], ["Modeling Interpersonal Influence of Verbal Behavior in Couples Therapy Dyadic Interactions.", ["Sandeep Nallan Chakravarthula", "Brian R. Baucom", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2018-1562", 5], ["Computational Modeling of Conversational Humor in Psychotherapy.", ["Anil Ramakrishna", "Timothy Greer", "David C. Atkins", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1583", 5], ["Multimodal I-vectors to Detect and Evaluate Parkinson's Disease.", ["Nicanor Garcia", "Juan Camilo Vasquez-Correa", "Juan Rafael Orozco-Arroyave", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2018-2295", 5], ["Overview of the 2018 Spoken CALL Shared Task.", ["Claudia Baur", "Andrew Caines", "Cathy Chua", "Johanna Gerlach", "Mengjie Qian", "Manny Rayner", "Martin J. Russell", "Helmer Strik", "Xizi Wei"], "https://doi.org/10.21437/Interspeech.2018-97", 5], ["The CSU-K Rule-Based System for the 2nd Edition Spoken CALL Shared Task.", ["Dominik Julg", "Mario Kunstek", "Cem Philipp Freimoser", "Kay Berkling", "Mengjie Qian"], "https://doi.org/10.21437/Interspeech.2018-1000", 5], ["Liulishuo's System for the Spoken CALL Shared Task 2018.", ["Huy Nguyen", "Lei Chen", "Ramon Prieto", "Chuan Wang", "Yang Liu"], "https://doi.org/10.21437/Interspeech.2018-1309", 5], ["An Optimization Based Approach for Solving Spoken CALL Shared Task.", ["Mohammad Ateeq", "Abualsoud Hanani", "Aziz Qaroush"], "https://doi.org/10.21437/Interspeech.2018-1328", 5], ["The University of Birmingham 2018 Spoken CALL Shared Task Systems.", ["Mengjie Qian", "Xizi Wei", "Peter Jancovic", "Martin J. Russell"], "https://doi.org/10.21437/Interspeech.2018-1372", 5], ["Improvements to an Automated Content Scoring System for Spoken CALL Responses: the ETS Submission to the Second Spoken CALL Shared Task.", ["Keelan Evanini", "Matthew Mulholland", "Rutuja Ubale", "Yao Qian", "Robert A. Pugh", "Vikram Ramanarayanan", "Aoife Cahill"], "https://doi.org/10.21437/Interspeech.2018-2362", 5], ["Extracting Speaker's Gender, Accent, Age and Emotional State from Speech.", ["Nagendra Kumar Goel", "Mousmita Sarma", "Tejendra Kushwah", "Dharmesh Agarwal", "Zikra Iqbal", "Surbhi Chauhan"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3036.html", 2], ["Determining Speaker Location from Speech in a Practical Environment.", ["B. H. V. S. Narayanamurthy", "J. V. Satyanarayana", "Bayya Yegnanarayana"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3042.html", 2], ["An Automatic Speech Transcription System for Manipuri Language.", ["Tanvina Patel", "Krishna D. N", "Noor Fathima", "Nisar Shah", "Mahima C", "Deepak Kumar", "Anuroop Iyengar"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3043.html", 2], ["SPIRE-SST: An Automatic Web-based Self-learning Tool for Syllable Stress Tutoring (SST) to the Second Language Learners.", ["Chiranjeevi Yarra", "Anand P. A", "N. K. Kausthubha", "Prasanta Kumar Ghosh"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3009.html", 2], ["Glotto Vibrato Graph: A Device and Method for Recording, Analysis and Visualization of Glottal Activity.", ["Kishalay Chakraborty", "Senjam Shantirani Devi", "Sanjeevan Devnath", "S. R. Mahadeva Prasanna", "Priyankoo Sarmah"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3046.html", 2], ["Multi-Modal Data Augmentation for End-to-end ASR.", ["Adithya Renduchintala", "Shuoyang Ding", "Matthew Wiesner", "Shinji Watanabe"], "https://doi.org/10.21437/Interspeech.2018-2456", 5], ["Multi-task Learning with Augmentation Strategy for Acoustic-to-word Attention-based Encoder-decoder Speech Recognition.", ["Takafumi Moriya", "Sei Ueno", "Yusuke Shinohara", "Marc Delcroix", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-1866", 5], ["Training Augmentation with Adversarial Examples for Robust Speech Recognition.", ["Sining Sun", "Ching-Feng Yeh", "Mari Ostendorf", "Mei-Yuh Hwang", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2018-1247", 5], ["Data Augmentation Improves Recognition of Foreign Accented Speech.", ["Takashi Fukuda", "Raul Fernandez", "Andrew Rosenberg", "Samuel Thomas", "Bhuvana Ramabhadran", "Alexander Sorin", "Gakuto Kurata"], "https://doi.org/10.21437/Interspeech.2018-1211", 5], ["Speaker Adaptive Training and Mixup Regularization for Neural Network Acoustic Models in Automatic Speech Recognition.", ["Natalia A. Tomashenko", "Yuri Y. Khokhlov", "Yannick Esteve"], "https://doi.org/10.21437/Interspeech.2018-2209", 5], ["Neural Language Codes for Multilingual Acoustic Models.", ["Markus Muller", "Sebastian Stuker", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2018-1241", 5], ["Encoder Transfer for Attention-based Acoustic-to-word Speech Recognition.", ["Sei Ueno", "Takafumi Moriya", "Masato Mimura", "Shinsuke Sakai", "Yusuke Shinohara", "Yoshikazu Yamaguchi", "Yushi Aono", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2018-1424", 5], ["Empirical Evaluation of Speaker Adaptation on DNN Based Acoustic Model.", ["Ke Wang", "Junbo Zhang", "Yujun Wang", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2018-1897", 5], ["Improving DNNs Trained with Non-Native Transcriptions Using Knowledge Distillation and Target Interpolation.", ["Amit Das", "Mark Hasegawa-Johnson"], "https://doi.org/10.21437/Interspeech.2018-1450", 5], ["Improving Cross-Lingual Knowledge Transferability Using Multilingual TDNN-BLSTM with Language-Dependent Pre-Final Layer.", ["Siyuan Feng", "Tan Lee"], "https://doi.org/10.21437/Interspeech.2018-1182", 5], ["Auxiliary Feature Based Adaptation of End-to-end ASR Systems.", ["Marc Delcroix", "Shinji Watanabe", "Atsunori Ogawa", "Shigeki Karita", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2018-1438", 5], ["Leveraging Native Language Information for Improved Accented Speech Recognition.", ["Shahram Ghorbani", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-1378", 5], ["Improved Accented Speech Recognition Using Accent Embeddings and Multi-task Learning.", ["Abhinav Jain", "Minali Upreti", "Preethi Jyothi"], "https://doi.org/10.21437/Interspeech.2018-1864", 5], ["Fast Language Adaptation Using Phonological Information.", ["Sibo Tong", "Philip N. Garner", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2018-1990", 5], ["Naturalness Improvement Algorithm for Reconstructed Glossectomy Patient's Speech Using Spectral Differential Modification in Voice Conversion.", ["Hiroki Murakami", "Sunao Hara", "Masanobu Abe", "Masaaki Sato", "Shogo Minagi"], "https://doi.org/10.21437/Interspeech.2018-1239", 5], ["Audio-visual Voice Conversion Using Deep Canonical Correlation Analysis for Deep Bottleneck Features.", ["Satoshi Tamura", "Kento Horio", "Hajime Endo", "Satoru Hayamizu", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2018-2286", 5], ["An Investigation of Convolution Attention Based Models for Multilingual Speech Synthesis of Indian Languages.", ["Pallavi Baljekar", "Sai Krishna Rallabandi", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2018-1869", 5], ["The Effect of Real-Time Constraints on Automatic Speech Animation.", ["Danny Websdale", "Sarah Taylor", "Ben Milner"], "https://doi.org/10.21437/Interspeech.2018-2066", 5], ["Joint Learning of Facial Expression and Head Pose from Speech.", ["David Greenwood", "Iain Matthews", "Stephen D. Laycock"], "https://doi.org/10.21437/Interspeech.2018-2587", 5], ["Acoustic-dependent Phonemic Transcription for Text-to-speech Synthesis.", ["Kevin Vythelingum", "Yannick Esteve", "Olivier Rosec"], "https://doi.org/10.21437/Interspeech.2018-1306", 5], ["Multimodal Speech Synthesis Architecture for Unsupervised Speaker Adaptation.", ["Hieu-Thi Luong", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2018-1791", 5], ["Articulatory-to-speech Conversion Using Bi-directional Long Short-term Memory.", ["Fumiaki Taguchi", "Tokihiko Kaburagi"], "https://doi.org/10.21437/Interspeech.2018-999", 5], ["Implementation of Respiration in Articulatory Synthesis Using a Pressure-Volume Lung Model.", ["Keisuke Tanihara", "Shogo Yonekura", "Yasuo Kuniyoshi"], "https://doi.org/10.21437/Interspeech.2018-1080", 5], ["Learning and Modeling Unit Embeddings for Improving HMM-based Unit Selection Speech Synthesis.", ["Xiao Zhou", "Zhen-Hua Ling", "Zhi-Ping Zhou", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2018-1198", 5], ["Deep Metric Learning for the Target Cost in Unit-Selection Speech Synthesizer.", ["Ruibo Fu", "Jianhua Tao", "Yibin Zheng", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2018-1305", 5], ["DNN-based Speech Synthesis for Small Data Sets Considering Bidirectional Speech-Text Conversion.", ["Kentaro Sone", "Toru Nakashika"], "https://doi.org/10.21437/Interspeech.2018-1460", 5], ["A Weighted Superposition of Functional Contours Model for Modelling Contextual Prominence of Elementary Prosodic Contours.", ["Branislav Gerazov", "Gerard Bailly", "Yi Xu"], "https://doi.org/10.21437/Interspeech.2018-1286", 5], ["LSTBM: A Novel Sequence Representation of Speech Spectra Using Restricted Boltzmann Machine with Long Short-Term Memory.", ["Toru Nakashika"], "https://doi.org/10.21437/Interspeech.2018-1753", 5], ["Should Code-switching Models Be Asymmetric?", ["Barbara E. Bullock", "Gualberto A. Guzman", "Jacqueline Serigos", "Almeida Jacqueline Toribio"], "https://doi.org/10.21437/Interspeech.2018-1284", 5], ["Cross-language Perception of Mandarin Lexical Tones by Mongolian-speaking Bilinguals in the Inner Mongolia Autonomous Region, China.", ["Kimiko Tsukada", "Yu Rong"], "https://doi.org/10.21437/Interspeech.2018-48", 5], ["Automatically Measuring L2 Speech Fluency without the Need of ASR: A Proof-of-concept Study with Japanese Learners of French.", ["Lionel Fontan", "Maxime Le Coz", "Sylvain Detey"], "https://doi.org/10.21437/Interspeech.2018-1336", 5], ["Analysis of L2 Learners' Progress of Distinguishing Mandarin Tone 2 and Tone 3.", ["Yue Sun", "Win Thuzar Kyaw", "Jinsong Zhang", "Yoshinori Sagisaka"], "https://doi.org/10.21437/Interspeech.2018-1983", 5], ["Unsupervised Discovery of Non-native Phonetic Patterns in L2 English Speech for Mispronunciation Detection and Diagnosis.", ["Xu Li", "Shaoguang Mao", "Xixin Wu", "Kun Li", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-2027", 5], ["Wuxi Speakers' Production and Perception of Coda Nasals in Mandarin.", ["Lei Wang", "Jie Cui", "Ying Chen"], "https://doi.org/10.21437/Interspeech.2018-2224", 4], ["The Diphthongs of Formal Nigerian English: A Preliminary Acoustic Analysis.", ["Natalia Dyrenko", "Robert Fuchs"], "https://doi.org/10.21437/Interspeech.2018-2373", 5], ["Characterizing Rhythm Differences between Strong and Weak Accented L2 Speech.", ["Chris Davis", "Jeesun Kim"], "https://doi.org/10.21437/Interspeech.2018-1798", 5], ["Analysis of Phone Errors Attributable to Phonological Effects Associated With Language Acquisition Through Bottleneck Feature Visualisations.", ["Eva Fringi", "Martin J. Russell"], "https://doi.org/10.21437/Interspeech.2018-2422", 5], ["Category Similarity in Multilingual Pronunciation Training.", ["Jacques C. Koreman"], "https://doi.org/10.21437/Interspeech.2018-1938", 5], ["Talker Diarization in the Wild: the Case of Child-centered Daylong Audio-recordings.", ["Alejandrina Cristia", "Shobhana Ganesh", "Marisa Casillas", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2018-2078", 5], ["Automated Classification of Children's Linguistic versus Non-Linguistic Vocalisations.", ["Zixing Zhang", "Alejandrina Cristia", "Anne A. Warlaumont", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-2523", 5], ["Pitch Characteristics of L2 English Speech by Chinese Speakers: A Large-scale Study.", ["Jiahong Yuan", "Qiusi Dong", "Fei Wu", "Huan Luan", "Xiaofei Yang", "Hui Lin", "Yang Liu"], "https://doi.org/10.21437/Interspeech.2018-1556", 5], ["Dual Language Models for Code Switched Speech Recognition.", ["Saurabh Garg", "Tanmay Parekh", "Preethi Jyothi"], "https://doi.org/10.21437/Interspeech.2018-1343", 5], ["Multilingual Neural Network Acoustic Modelling for ASR of Under-Resourced English-isiZulu Code-Switched Speech.", ["Astik Biswas", "Febe de Wet", "Ewald van der Westhuizen", "Emre Yilmaz", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2018-1711", 5], ["Fast ASR-free and Almost Zero-resource Keyword Spotting Using DTW and CNNs for Humanitarian Monitoring.", ["Raghav Menon", "Herman Kamper", "John Quinn", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2018-1580", 5], ["Text-Dependent Speech Enhancement for Small-Footprint Robust Keyword Detection.", ["Meng Yu", "Xuan Ji", "Yi Gao", "Lianwu Chen", "Jie Chen", "Jimeng Zheng", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1668", 5], ["Improved ASR for Under-resourced Languages through Multi-task Learning with Acoustic Landmarks.", ["Di He", "Boon Pang Lim", "Xuesong Yang", "Mark Hasegawa-Johnson", "Deming Chen"], "https://doi.org/10.21437/Interspeech.2018-1124", 5], ["Cross-language Phoneme Mapping for Low-resource Languages: An Exploration of Benefits and Trade-offs.", ["Nick K. Chibuye", "Todd Rosenstock", "Brian DeRenzi"], "https://doi.org/10.21437/Interspeech.2018-2454", 5], ["User-centric Evaluation of Automatic Punctuation in ASR Closed Captioning.", ["Mate Akos Tundik", "Gyorgy Szaszak", "Gabor Gosztolya", "Andras Beke"], "https://doi.org/10.21437/Interspeech.2018-1352", 5], ["Punctuation Prediction Model for Conversational Speech.", ["Piotr Zelasko", "Piotr Szymanski", "Jan Mizgajski", "Adrian Szymczak", "Yishay Carmiel", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-1096", 5], ["BUT OpenSAT 2017 Speech Recognition System.", ["Martin Karafiat", "Murali Karthick Baskar", "Igor Szoke", "Vladimir Malenovsky", "Karel Vesely", "Frantisek Grezl", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2018-2457", 5], ["Visual Recognition of Continuous Cued Speech Using a Tandem CNN-HMM Approach.", ["Li Liu", "Thomas Hueber", "Gang Feng", "Denis Beautemps"], "https://doi.org/10.21437/Interspeech.2018-2434", 5], ["Building Large-vocabulary Speaker-independent Lipreading Systems.", ["Kwanchiva Thangthai", "Richard W. Harvey"], "https://doi.org/10.21437/Interspeech.2018-2112", 5], ["CRIM's System for the MGB-3 English Multi-Genre Broadcast Media Transcription.", ["Vishwa Gupta", "Gilles Boulianne"], "https://doi.org/10.21437/Interspeech.2018-2079", 5], ["Sampling Strategies in Siamese Networks for Unsupervised Speech Representation Learning.", ["Rachid Riad", "Corentin Dancette", "Julien Karadayi", "Neil Zeghidour", "Thomas Schatz", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2018-2384", 5], ["Compact Feedforward Sequential Memory Networks for Small-footprint Keyword Spotting.", ["Mengzhe Chen", "Shiliang Zhang", "Ming Lei", "Yong Liu", "Haitao Yao", "Jie Gao"], "https://doi.org/10.21437/Interspeech.2018-1204", 5], ["Multilingual Bottleneck Features for Subword Modeling in Zero-resource Languages.", ["Enno Hermann", "Sharon Goldwater"], "https://doi.org/10.21437/Interspeech.2018-2334", 5], ["Exploiting Speaker and Phonetic Diversity of Mismatched Language Resources for Unsupervised Subword Modeling.", ["Siyuan Feng", "Tan Lee"], "https://doi.org/10.21437/Interspeech.2018-1081", 5], ["Unsupervised Word Segmentation from Speech with Attention.", ["Pierre Godard", "Marcely Zanon Boito", "Lucas Ondel", "Alexandre Berard", "Francois Yvon", "Aline Villavicencio", "Laurent Besacier"], "https://doi.org/10.21437/Interspeech.2018-1308", 5], ["Learning Word Embeddings: Unsupervised Methods for Fixed-size Representations of Variable-length Speech Segments.", ["Nils Holzenberger", "Mingxing Du", "Julien Karadayi", "Rachid Riad", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2018-2364", 5], ["Full Bayesian Hidden Markov Model Variational Autoencoder for Acoustic Unit Discovery.", ["Thomas Glarner", "Patrick Hanebrink", "Janek Ebbers", "Reinhold Haeb-Umbach"], "https://doi.org/10.21437/Interspeech.2018-2148", 5], ["Unspeech: Unsupervised Speech Context Embeddings.", ["Benjamin Milde", "Chris Biemann"], "https://doi.org/10.21437/Interspeech.2018-2194", 5], ["Impact of Aliasing on Deep CNN-Based End-to-End Acoustic Models.", ["Yuan Gong", "Christian Poellabauer"], "https://doi.org/10.21437/Interspeech.2018-1371", 5], ["Keyword Based Speaker Localization: Localizing a Target Speaker in a Multi-speaker Environment.", ["Sunit Sivasankaran", "Emmanuel Vincent", "Dominique Fohr"], "https://doi.org/10.21437/Interspeech.2018-1526", 5], ["End-to-End Speech Separation with Unfolded Iterative Phase Reconstruction.", ["Zhong-Qiu Wang", "Jonathan Le Roux", "DeLiang Wang", "John R. Hershey"], "https://doi.org/10.21437/Interspeech.2018-1629", 5], ["PhaseNet: Discretized Phase Modeling with Deep Neural Networks for Audio Source Separation.", ["Naoya Takahashi", "Purvi Agrawal", "Nabarun Goswami", "Yuki Mitsufuji"], "https://doi.org/10.21437/Interspeech.2018-1773", 5], ["Integrating Spectral and Spatial Features for Multi-Channel Speaker Separation.", ["Zhong-Qiu Wang", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2018-1940", 5], ["DNN Driven Speaker Independent Audio-Visual Mask Estimation for Speech Separation.", ["Mandar Gogate", "Ahsan Adeel", "Ricard Marxer", "Jon Barker", "Amir Hussain"], "https://doi.org/10.21437/Interspeech.2018-2516", 5], ["Exploring Temporal Reduction in Dialectal Spanish: A Large-scale Study of Lenition of Voiced Stops and Coda-s.", ["Ioana Vasilescu", "Nidia Hernandez", "Bianca Vieru", "Lori Lamel"], "https://doi.org/10.21437/Interspeech.2018-1256", 5], ["Dialect-geographical Acoustic-Tonetics: Five Disyllabic Tone Sandhi Patterns in Cognate Words from the Wu Dialects of Zh\u00e8Ji\u0101Ng Province.", ["Phil Rose"], "https://doi.org/10.21437/Interspeech.2018-1130", 5], ["Regional Variation of /r/ in Swiss German Dialects.", ["Adrian Leemann", "Stephan Schmid", "Dieter Studer-Joho", "Marie-Jose Kolly"], "https://doi.org/10.21437/Interspeech.2018-1065", 5], ["Variation in the FACE Vowel across West Yorkshire: Implications for Forensic Speaker Comparisons.", ["Kate Earnshaw", "Erica Gold"], "https://doi.org/10.21437/Interspeech.2018-1944", 5], ["The 'West Yorkshire Regional English Database': Investigations into the Generalizability of Reference Populations for Forensic Speaker Comparison Casework.", ["Erica Gold", "Sula Ross", "Kate Earnshaw"], "https://doi.org/10.21437/Interspeech.2018-65", 5], ["Studying Vowel Variation in French-Algerian Arabic Code-switched Speech.", ["Jane Wottawa", "Djegdjiga Amazouz", "Martine Adda-Decker", "Lori Lamel"], "https://doi.org/10.21437/Interspeech.2018-2381", 5], ["Fearless Steps: Apollo-11 Corpus Advancements for Speech Technologies from Earth to the Moon.", ["John H. L. Hansen", "Abhijeet Sangwan", "Aditya Joglekar", "Ahmet Emin Bulut", "Lakshmish Kaushik", "Chengzhu Yu"], "https://doi.org/10.21437/Interspeech.2018-1942", 5], ["A Knowledge Driven Structural Segmentation Approach for Play-Talk Classification During Autism Assessment.", ["Manoj Kumar", "Pooja Chebolu", "So Hyun Kim", "Kassandra Martinez", "Catherine Lord", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1516", 5], ["An Open Source Emotional Speech Corpus for Human Robot Interaction Applications.", ["Jesin James", "Li Tian", "Catherine Inez Watson"], "https://doi.org/10.21437/Interspeech.2018-1349", 5], ["Speech Database and Protocol Validation Using Waveform Entropy.", ["Itshak Lapidot", "Hector Delgado", "Massimiliano Todisco", "Nicholas W. D. Evans", "Jean-Francois Bonastre"], "https://doi.org/10.21437/Interspeech.2018-2330", 5], ["A French-Spanish Multimodal Speech Communication Corpus Incorporating Acoustic Data, Facial, Hands and Arms Gestures Information.", ["Lucas D. Terissi", "Gonzalo D. Sad", "Mauricio Cerda", "Slim Ouni", "Rodrigo Galvez", "Juan Carlos Gomez", "Bernard Girau", "Nancy Hitschfeld-Kahler"], "https://doi.org/10.21437/Interspeech.2018-2212", 5], ["L2-ARCTIC: A Non-native English Speech Corpus.", ["Guanlong Zhao", "Sinem Sonsaat", "Alif Silpachai", "Ivana Lucic", "Evgeny Chukharev-Hudilainen", "John Levis", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2018-1110", 5], ["ZCU-NTIS Speaker Diarization System for the DIHARD 2018 Challenge.", ["Zbynek Zajic", "Marie Kunesova", "Jan Zelinka", "Marek Hruz"], "https://doi.org/10.21437/Interspeech.2018-1252", 5], ["Speaker Diarization with Enhancing Speech for the First DIHARD Challenge.", ["Lei Sun", "Jun Du", "Chao Jiang", "Xueyang Zhang", "Shan He", "Bing Yin", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2018-1742", 5], ["BUT System for DIHARD Speech Diarization Challenge 2018.", ["Mireia Diez", "Federico Landini", "Lukas Burget", "Johan Rohdin", "Anna Silnova", "Katerina Zmolikova", "Ondrej Novotny", "Karel Vesely", "Ondrej Glembek", "Oldrich Plchot", "Ladislav Mosner", "Pavel Matejka"], "https://doi.org/10.21437/Interspeech.2018-1749", 5], ["Estimation of the Number of Speakers with Variational Bayesian PLDA in the DIHARD Diarization Challenge.", ["Ignacio Vinals", "Pablo Gimeno", "Alfonso Ortega", "Antonio Miguel", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2018-1841", 5], ["Diarization is Hard: Some Experiences and Lessons Learned for the JHU Team in the Inaugural DIHARD Challenge.", ["Gregory Sell", "David Snyder", "Alan McCree", "Daniel Garcia-Romero", "Jesus Villalba", "Matthew Maciejewski", "Vimal Manohar", "Najim Dehak", "Daniel Povey", "Shinji Watanabe", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1893", 5], ["The EURECOM Submission to the First DIHARD Challenge.", ["Jose Patino", "Hector Delgado", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2018-2172", 5], ["Joint Discriminative Embedding Learning, Speech Activity and Overlap Detection for the DIHARD Speaker Diarization Challenge.", ["Valter Akira Miasato Filho", "Diego Augusto Silva", "Luis Gustavo Depra Cuozzo"], "https://doi.org/10.21437/Interspeech.2018-2304", 5], ["Multilingual Grapheme-to-Phoneme Conversion with Global Character Vectors.", ["Jinfu Ni", "Yoshinori Shiga", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2018-1626", 5], ["A Hybrid Approach to Grapheme to Phoneme Conversion in Assamese.", ["Somnath Roy", "Shakuntala Mahanta"], "https://doi.org/10.21437/Interspeech.2018-1694", 5], ["Investigation of Using Disentangled and Interpretable Representations for One-shot Cross-lingual Voice Conversion.", ["Seyed Hamidreza Mohammadi", "Taehwan Kim"], "https://doi.org/10.21437/Interspeech.2018-2525", 5], ["Using Pupillometry to Measure the Cognitive Load of Synthetic Speech.", ["Avashna Govender", "Simon King"], "https://doi.org/10.21437/Interspeech.2018-1174", 5], ["Measuring the Cognitive Load of Synthetic Speech Using a Dual Task Paradigm.", ["Avashna Govender", "Simon King"], "https://doi.org/10.21437/Interspeech.2018-1199", 5], ["Attentive Sequence-to-Sequence Learning for Diacritic Restoration of Yor\u00f9B\u00e1 Language Text.", ["Iroro Orife"], "https://doi.org/10.21437/Interspeech.2018-42", 5], ["Gated Convolutional Neural Network for Sentence Matching.", ["Peixin Chen", "Wu Guo", "Zhi Chen", "Jian Sun", "Lanhua You"], "https://doi.org/10.21437/Interspeech.2018-70", 5], ["On Training and Evaluation of Grapheme-to-Phoneme Mappings with Limited Data.", ["Dravyansh Sharma"], "https://doi.org/10.21437/Interspeech.2018-1920", 5], ["The Perception and Analysis of the Likeability and Human Likeness of Synthesized Speech.", ["Alice Baird", "Emilia Parada-Cabaleiro", "Simone Hantke", "Felix Burkhardt", "Nicholas Cummins", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1093", 5], ["Word Emphasis Prediction for Expressive Text to Speech.", ["Yosi Mass", "Slava Shechtman", "Moran Mordechay", "Ron Hoory", "Oren Sar Shalom", "Guy Lev", "David Konopnicki"], "https://doi.org/10.21437/Interspeech.2018-1159", 5], ["A Comparison of Speaker-based and Utterance-based Data Selection for Text-to-Speech Synthesis.", ["Kai-Zhan Lee", "Erica Cooper", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2018-1313", 5], ["Data Requirements, Selection and Augmentation for DNN-based Speech Synthesis from Crowdsourced Data.", ["Markus Toman", "Geoffrey S. Meltzner", "Rupal Patel"], "https://doi.org/10.21437/Interspeech.2018-1316", 5], ["Lightly Supervised vs. Semi-supervised Training of Acoustic Model on Luxembourgish for Low-resource Automatic Speech Recognition.", ["Karel Vesely", "Carlos Segura", "Igor Szoke", "Jordi Luque", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2018-2361", 5], ["Investigation on the Combination of Batch Normalization and Dropout in BLSTM-based Acoustic Modeling for ASR.", ["Wenjie Li", "Gaofeng Cheng", "Fengpei Ge", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1597", 5], ["Inference-Invariant Transformation of Batch Normalization for Domain Adaptation of Acoustic Models.", ["Masayuki Suzuki", "Tohru Nagano", "Gakuto Kurata", "Samuel Thomas"], "https://doi.org/10.21437/Interspeech.2018-1563", 5], ["Active Learning for LF-MMI Trained Neural Networks in ASR.", ["Yanhua Long", "Hong Ye", "Yijie Li", "Jiaen Liang"], "https://doi.org/10.21437/Interspeech.2018-1162", 5], ["An Investigation of Mixup Training Strategies for Acoustic Models in ASR.", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Dmitry Popov", "Natalia A. Tomashenko", "Ivan Sorokin", "Alexander Zatvornitskiy"], "https://doi.org/10.21437/Interspeech.2018-2191", 5], ["Comparison of Unsupervised Modulation Filter Learning Methods for ASR.", ["Purvi Agrawal", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2018-1972", 5], ["Improved Training for Online End-to-end Speech Recognition Systems.", ["Suyoun Kim", "Michael L. Seltzer", "Jinyu Li", "Rui Zhao"], "https://doi.org/10.21437/Interspeech.2018-2517", 5], ["Combining Natural Gradient with Hessian Free Methods for Sequence Training.", ["Adnan Haider", "Philip C. Woodland"], "https://doi.org/10.21437/Interspeech.2018-2335", 5], ["Lattice-free State-level Minimum Bayes Risk Training of Acoustic Models.", ["Naoyuki Kanda", "Yusuke Fujita", "Kenji Nagamatsu"], "https://doi.org/10.21437/Interspeech.2018-79", 5], ["A Study of Enhancement, Augmentation and Autoencoder Methods for Domain Adaptation in Distant Speech Recognition.", ["Hao Tang", "Wei-Ning Hsu", "Francois Grondin", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2018-2030", 5], ["Multilingual Deep Neural Network Training Using Cyclical Learning Rate.", ["Andreas Soeborg Kirkedal", "Yeon-Jun Kim"], "https://doi.org/10.21437/Interspeech.2018-1891", 5], ["Development of the CUHK Dysarthric Speech Recognition System for the UA Speech Corpus.", ["Jianwei Yu", "Xurong Xie", "Shansong Liu", "Shoukang Hu", "Max W. Y. Lam", "Xixin Wu", "Ka Ho Wong", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1541", 5], ["Automatic Evaluation of Speech Intelligibility Based on I-vectors in the Context of Head and Neck Cancers.", ["Imed Laaridh", "Corinne Fredouille", "Alain Ghio", "Muriel Lalain", "Virginie Woisard"], "https://doi.org/10.21437/Interspeech.2018-1266", 5], ["Dysarthric Speech Recognition Using Convolutional LSTM Neural Network.", ["Myung Jong Kim", "Beiming Cao", "Kwanghoon An", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2018-2250", 5], ["Perceptual and Automatic Evaluations of the Intelligibility of Speech Degraded by Noise Induced Hearing Loss Simulation.", ["Imed Laaridh", "Julien Tardieu", "Cynthia Magnen", "Pascal Gaillard", "Jerome Farinas", "Julien Pinquier"], "https://doi.org/10.21437/Interspeech.2018-1264", 5], ["Articulatory Features for ASR of Pathological Speech.", ["Emre Yilmaz", "Vikramjit Mitra", "Chris Bartels", "Horacio Franco"], "https://doi.org/10.21437/Interspeech.2018-67", 5], ["Mining Multimodal Repositories for Speech Affecting Diseases.", ["M. Joana Correia", "Bhiksha Raj", "Isabel Trancoso", "Francisco Teixeira"], "https://doi.org/10.21437/Interspeech.2018-1806", 5], ["Long Distance Voice Channel Diagnosis Using Deep Neural Networks.", ["Zhen Qin", "Tom Ko", "Guangjian Tian"], "https://doi.org/10.21437/Interspeech.2018-1428", 4], ["Speech Recognition for Medical Conversations.", ["Chung-Cheng Chiu", "Anshuman Tripathi", "Katherine Chou", "Chris Co", "Navdeep Jaitly", "Diana Jaunzeikare", "Anjuli Kannan", "Patrick Nguyen", "Hasim Sak", "Ananth Sankar", "Justin Tansuwan", "Nathan Wan", "Yonghui Wu", "Xuedong Zhang"], "https://doi.org/10.21437/Interspeech.2018-40", 5], ["Prosodic Focus Acquisition in French Early Cochlear Implanted Children.", ["Chadi Farah", "Stephane Roman", "Mariapaola DImperio"], "https://doi.org/10.21437/Interspeech.2018-1320", 5], ["The Role of Temporal Variation in Narrative Organization.", ["Nassima Fezza"], "https://doi.org/10.21437/Interspeech.2018-1725", 5], ["Interaction Mechanisms between Glottal Source and Vocal Tract in Pitch Glides.", ["Tiina Murtola", "Jarmo Malinen"], "https://doi.org/10.21437/Interspeech.2018-1827", 5], ["Relating Articulatory Motions in Different Speaking Rates.", ["Astha Singh", "G. Nisha Meenakshi", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1862", 5], ["Estimation of the Asymmetry Parameter of the Glottal Flow Waveform Using the Electroglottographic Signal.", ["Joao Cabral"], "https://doi.org/10.21437/Interspeech.2018-2371", 5], ["Classification of Disorders in Vocal Folds Using Electroglottographic Signal.", ["Tanumay Mandal", "K. Sreenivasa Rao", "Sanjay Kumar Gupta"], "https://doi.org/10.21437/Interspeech.2018-1967", 5], ["Automatic Glottis Localization and Segmentation in Stroboscopic Videos Using Deep Neural Network.", ["M. V. Achuth Rao", "Rahul Krishnamurthy", "Pebbili Gopikishore", "Veeramani Priyadharshini", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-2572", 5], ["Respiratory and Respiratory Muscular Control in JL1's and JL2's Text Reading Utilizing 4-RSTs and a Soft Respiratory Mask with a Two-Way Bulb.", ["Toshiko Isei-Jaakkola", "Keiko Ochi", "Keikichi Hirose"], "https://doi.org/10.21437/Interspeech.2018-1948", 5], ["A Preliminary Study on Tonal Coarticulation in Continuous Speech.", ["Lixia Hao", "Wei Zhang", "Yanlu Xie", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2018-1849", 5], ["Speech and Language Processing for Learning and Wellbeing.", ["Helen Meng"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/4004.html", 1], ["Far-Field Speech Recognition Using Multivariate Autoregressive Models.", ["Sriram Ganapathy", "Madhumita Harish"], "https://doi.org/10.21437/Interspeech.2018-2003", 5], ["Efficient Implementation of the Room Simulator for Training Deep Neural Network Acoustic Models.", ["Chanwoo Kim", "Ehsan Variani", "Arun Narayanan", "Michiel Bacchiani"], "https://doi.org/10.21437/Interspeech.2018-2566", 5], ["Stream Attention for Distributed Multi-Microphone Speech Recognition.", ["Xiaofei Wang", "Ruizhi Li", "Hynek Hermansky"], "https://doi.org/10.21437/Interspeech.2018-1037", 5], ["Recognizing Overlapped Speech in Meetings: A Multichannel Separation Approach Using Neural Networks.", ["Takuya Yoshioka", "Hakan Erdogan", "Zhuo Chen", "Xiong Xiao", "Fil Alleva"], "https://doi.org/10.21437/Interspeech.2018-2284", 5], ["Integrating Neural Network Based Beamforming and Weighted Prediction Error Dereverberation.", ["Lukas Drude", "Christoph Boddeker", "Jahn Heymann", "Reinhold Haeb-Umbach", "Keisuke Kinoshita", "Marc Delcroix", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2018-2196", 5], ["A Probability Weighted Beamformer for Noise Robust ASR.", ["Suliang Bu", "Yunxin Zhao", "Mei-Yuh Hwang", "Sining Sun"], "https://doi.org/10.21437/Interspeech.2018-2427", 5], ["Effects of Dimensional Input on Paralinguistic Information Perceived from Synthesized Dialogue Speech with Neural Network.", ["Masaki Yokoyama", "Tomohiro Nagata", "Hiroki Mori"], "https://doi.org/10.21437/Interspeech.2018-2042", 4], ["Neural MultiVoice Models for Expressing Novel Personalities in Dialog.", ["Shereen Oraby", "Lena Reed", "Sharath T. S.", "Shubhangi Tandon", "Marilyn A. Walker"], "https://doi.org/10.21437/Interspeech.2018-2174", 5], ["Expressive Speech Synthesis Using Sentiment Embeddings.", ["Igor Jauk", "Jaime Lorenzo-Trueba", "Junichi Yamagishi", "Antonio Bonafonte"], "https://doi.org/10.21437/Interspeech.2018-2467", 5], ["Expressive Speech Synthesis via Modeling Expressions with Variational Autoencoder.", ["Kei Akuzawa", "Yusuke Iwasawa", "Yutaka Matsuo"], "https://doi.org/10.21437/Interspeech.2018-1113", 5], ["Rapid Style Adaptation Using Residual Error Embedding for Expressive Speech Synthesis.", ["Xixin Wu", "Yuewen Cao", "Mu Wang", "Songxiang Liu", "Shiyin Kang", "Zhiyong Wu", "Xunying Liu", "Dan Su", "Dong Yu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1991", 5], ["EMPHASIS: An Emotional Phoneme-based Acoustic Model for Speech Synthesis System.", ["Hao Li", "Yongguo Kang", "Zhenyu Wang"], "https://doi.org/10.21437/Interspeech.2018-1511", 5], ["Bags in Bag: Generating Context-Aware Bags for Tracking Emotions from Speech.", ["Jing Han", "Zixing Zhang", "Maximilian Schmitt", "Zhao Ren", "Fabien Ringeval", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-996", 5], ["An Attention Pooling Based Representation Learning Method for Speech Emotion Recognition.", ["Pengcheng Li", "Yan Song", "Ian Vince McLoughlin", "Wu Guo", "Lirong Dai"], "https://doi.org/10.21437/Interspeech.2018-1242", 5], ["Predicting Arousal and Valence from Waveforms and Spectrograms Using Deep Neural Networks.", ["Zixiaofan Yang", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2018-2397", 5], ["Emotion Identification from Raw Speech Signals Using DNNs.", ["Mousmita Sarma", "Pegah Ghahremani", "Daniel Povey", "Nagendra Kumar Goel", "Kandarpa Kumar Sarma", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-1353", 5], ["Encoding Individual Acoustic Features Using Dyad-Augmented Deep Variational Representations for Dialog-level Emotion Recognition.", ["Jeng-Lin Li", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2018-1455", 5], ["Variational Autoencoders for Learning Latent Representations of Speech Emotion: A Preliminary Study.", ["Siddique Latif", "Rajib Rana", "Junaid Qadir", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2018-1568", 5], ["Phoneme-to-Articulatory Mapping Using Bidirectional Gated RNN.", ["Theo Biasutto-Lervat", "Slim Ouni"], "https://doi.org/10.21437/Interspeech.2018-1202", 5], ["Tongue Segmentation with Geometrically Constrained Snake Model.", ["Zhihua Su", "Jianguo Wei", "Qiang Fang", "Jianrong Wang", "Kiyoshi Honda"], "https://doi.org/10.21437/Interspeech.2018-1108", 5], ["Low Resource Acoustic-to-articulatory Inversion Using Bi-directional Long Short Term Memory.", ["Aravind Illa", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1843", 5], ["Automatic Visual Augmentation for Concatenation Based Synthesized Articulatory Videos from Real-time MRI Data for Spoken Language Training.", ["Chandana S", "Chiranjeevi Yarra", "Ritu Aggarwal", "Sanjeev Kumar Mittal", "N. K. Kausthubha", "Raseena K. T", "Astha Singh", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1570", 5], ["Air-Tissue Boundary Segmentation in Real-Time Magnetic Resonance Imaging Video Using Semantic Segmentation with Fully Convolutional Networks.", ["C. A. Valliappan", "Renuka Mannem", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1939", 5], ["Noise Robust Acoustic to Articulatory Speech Inversion.", ["Nadee Seneviratne", "Ganesh Sivaraman", "Vikramjit Mitra", "Carol Y. Espy-Wilson"], "https://doi.org/10.21437/Interspeech.2018-1509", 5], ["Designing a Pneumatic Bionic Voice Prosthesis - A Statistical Approach for Source Excitation Generation.", ["Farzaneh Ahmadi", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2018-1043", 5], ["A Neural Model to Predict Parameters for a Generalized Command Response Model of Intonation.", ["Bastian Schnell", "Philip N. Garner"], "https://doi.org/10.21437/Interspeech.2018-1904", 5], ["Articulation-to-Speech Synthesis Using Articulatory Flesh Point Sensors' Orientation Information.", ["Beiming Cao", "Myung Jong Kim", "Jun R. Wang", "Jan P. H. van Santen", "Ted Mau", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2018-2484", 5], ["Effectiveness of Generative Adversarial Network for Non-Audible Murmur-to-Whisper Speech Conversion.", ["Neil Shah", "Nirmesh J. Shah", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1565", 5], ["Investigating Objective Intelligibility in Real-Time EMG-to-Speech Conversion.", ["Lorenz Diener", "Tanja Schultz"], "https://doi.org/10.21437/Interspeech.2018-2080", 5], ["Domain-Adversarial Training for Session Independent EMG-based Speech Recognition.", ["Michael Wand", "Tanja Schultz", "Jurgen Schmidhuber"], "https://doi.org/10.21437/Interspeech.2018-2318", 5], ["Multi-Task Learning of Speech Recognition and Speech Synthesis Parameters for Ultrasound-based Silent Speech Interfaces.", ["Laszlo Toth", "Gabor Gosztolya", "Tamas Grosz", "Alexandra Marko", "Tamas Gabor Csapo"], "https://doi.org/10.21437/Interspeech.2018-1078", 5], ["Transcription Correction for Indian Languages Using Acoustic Signatures.", ["Jeena J. Prakash", "Golda Brunet Rajan", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2018-1188", 5], ["BUT System for Low Resource Indian Language ASR.", ["Bhargav Pulugundla", "Murali Karthick Baskar", "Santosh Kesiraju", "Ekaterina Egorova", "Martin Karafiat", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2018-1302", 5], ["DA-IICT/IIITV System for Low Resource Speech Recognition Challenge 2018.", ["Hardik B. Sailor", "Maddala Venkata Siva Krishna", "Diksha Chhabra", "Ankur T. Patil", "Madhu R. Kamble", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1553", 5], ["An Exploration towards Joint Acoustic Modeling for Indian Languages: IIIT-H Submission for Low Resource Speech Recognition Challenge for Indian Languages, INTERSPEECH 2018.", ["Hari Krishna Vydana", "Krishna Gurugubelli", "Vishnu Vidyadhara Raju Vegesna", "Anil Kumar Vuppala"], "https://doi.org/10.21437/Interspeech.2018-1584", 5], ["TDNN-based Multilingual Speech Recognition System for Low Resource Indian Languages.", ["Noor Fathima", "Tanvina Patel", "Mahima C", "Anuroop Iyengar"], "https://doi.org/10.21437/Interspeech.2018-2117", 5], ["Articulatory and Stacked Bottleneck Features for Low Resource Speech Recognition.", ["Vishwas M. Shetty", "Rini A. Sharon", "Basil Abraham", "Tejaswi Seeram", "Anusha Prakash", "Nithya Ravi", "Srinivasan Umesh"], "https://doi.org/10.21437/Interspeech.2018-2226", 5], ["ISI ASR System for the Low Resource Speech Recognition Challenge for Indian Languages.", ["Jayadev Billa"], "https://doi.org/10.21437/Interspeech.2018-2473", 5], ["An Automated Assistant for Medical Scribes.", ["Gregory P. Finley", "Erik Edwards", "Amanda Robinson", "Najmeh Sadoughi", "James Fone", "Mark Miller", "David Suendermann-Oeft", "Michael Brenndoerfer", "Nico Axtmann"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3047.html", 2], ["AGROASSAM: A Web Based Assamese Speech Recognition Application for Retrieving Agricultural Commodity Price and Weather Information.", ["Abhishek Dey", "Abhash Deka", "Siddika Imani", "Barsha Deka", "Rohit Sinha", "S. R. Mahadeva Prasanna", "Priyankoo Sarmah", "K. Samudravijaya", "S. R. Nirmala"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3048.html", 2], ["Voice-powered Solutions with Cloud AI.", ["Dan Aharon"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3049.html", 1], ["Speech Synthesis in the Wild.", ["Ganesh Sivaraman", "Parav Nagarsheth", "Elie Khoury"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3050.html", 2], ["Deep Noise Tracking Network: A Hybrid Signal Processing/Deep Learning Approach to Speech Enhancement.", ["Shuai Nie", "Shan Liang", "Bin Liu", "Yaping Zhang", "Wenju Liu", "Jianhua Tao"], "https://doi.org/10.21437/Interspeech.2018-1020", 5], ["A Deep Neural Network Based Harmonic Noise Model for Speech Enhancement.", ["Zhiheng Ouyang", "Hongjiang Yu", "Wei-Ping Zhu", "Benoit Champagne"], "https://doi.org/10.21437/Interspeech.2018-1114", 5], ["A Convolutional Recurrent Neural Network for Real-Time Speech Enhancement.", ["Ke Tan", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2018-1405", 5], ["All-Neural Multi-Channel Speech Enhancement.", ["Zhong-Qiu Wang", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2018-1664", 5], ["Deep Learning for Acoustic Echo Cancellation in Noisy and Double-Talk Scenarios.", ["Hao Zhang", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2018-1484", 5], ["The Conversation: Deep Audio-Visual Speech Enhancement.", ["Triantafyllos Afouras", "Joon Son Chung", "Andrew Zisserman"], "https://doi.org/10.21437/Interspeech.2018-1400", 5], ["Student-Teacher Learning for BLSTM Mask-based Speech Enhancement.", ["Aswin Shanmugam Subramanian", "Szu-Jui Chen", "Shinji Watanabe"], "https://doi.org/10.21437/Interspeech.2018-2440", 5], ["Speech Enhancement Using Deep Mixture of Experts Based on Hard Expectation Maximization.", ["Pavan Karjol", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1730", 5], ["Adversarial Feature-Mapping for Speech Enhancement.", ["Zhong Meng", "Jinyu Li", "Yifan Gong", "Biing-Hwang Fred Juang"], "https://doi.org/10.21437/Interspeech.2018-2461", 5], ["Biophysically-inspired Features Improve the Generalizability of Neural Network-based Speech Enhancement Systems.", ["Deepak Baby", "Sarah Verhulst"], "https://doi.org/10.21437/Interspeech.2018-1237", 5], ["Error Modeling via Asymmetric Laplace Distribution for Deep Neural Network Based Single-Channel Speech Enhancement.", ["Li Chai", "Jun Du", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2018-1439", 5], ["A Priori SNR Estimation Based on a Recurrent Neural Network for Robust Speech Enhancement.", ["Yangyang Xia", "Richard Stern"], "https://doi.org/10.21437/Interspeech.2018-2423", 5], ["Multiple Instance Deep Learning for Weakly Supervised Small-Footprint Audio Event Detection.", ["Shao-Yen Tseng", "Juncheng Li", "Yun Wang", "Florian Metze", "Joseph Szurley", "Samarjit Das"], "https://doi.org/10.21437/Interspeech.2018-1120", 5], ["Unsupervised Temporal Feature Learning Based on Sparse Coding Embedded BoAW for Acoustic Event Recognition.", ["Liwen Zhang", "Jiqing Han", "Shiwen Deng"], "https://doi.org/10.21437/Interspeech.2018-1243", 5], ["Data Independent Sequence Augmentation Method for Acoustic Scene Classification.", ["Teng Zhang", "Kailai Zhang", "Ji Wu"], "https://doi.org/10.21437/Interspeech.2018-1250", 5], ["A Compact and Discriminative Feature Based on Auditory Summary Statistics for Acoustic Scene Classification.", ["Hongwei Song", "Jiqing Han", "Shiwen Deng"], "https://doi.org/10.21437/Interspeech.2018-1299", 5], ["ASe: Acoustic Scene Embedding Using Deep Archetypal Analysis and GMM.", ["Pulkit Sharma", "Vinayak Abrol", "Anshul Thakur"], "https://doi.org/10.21437/Interspeech.2018-1481", 5], ["Deep Convolutional Neural Network with Scalogram for Audio Scene Modeling.", ["Hangting Chen", "Pengyuan Zhang", "Haichuan Bai", "Qingsheng Yuan", "Xiuguo Bao", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1524", 5], ["Time Aggregation Operators for Multi-label Audio Event Detection.", ["Pankaj Joshi", "Digvijaysingh Gautam", "Ganesh Ramakrishnan", "Preethi Jyothi"], "https://doi.org/10.21437/Interspeech.2018-1637", 5], ["Early Detection of Continuous and Partial Audio Events Using CNN.", ["Ian Vince McLoughlin", "Yan Song", "Lam Dang Pham", "Ramaswamy Palaniappan", "Huy Phan", "Yue Lang"], "https://doi.org/10.21437/Interspeech.2018-1821", 5], ["Robust Acoustic Event Classification Using Bag-of-Visual-Words.", ["Manjunath Mulimani", "Shashidhar G. Koolagudi"], "https://doi.org/10.21437/Interspeech.2018-1905", 4], ["Wavelet Transform Based Mel-scaled Features for Acoustic Scene Classification.", ["Shefali Waldekar", "Goutam Saha"], "https://doi.org/10.21437/Interspeech.2018-2083", 5], ["Multi-modal Attention Mechanisms in LSTM and Its Application to Acoustic Scene Classification.", ["Teng Zhang", "Kailai Zhang", "Ji Wu"], "https://doi.org/10.21437/Interspeech.2018-1138", 5], ["Contextual Language Model Adaptation for Conversational Agents.", ["Anirudh Raju", "Behnam Hedayatnia", "Linda Liu", "Ankur Gandhe", "Chandra Khatri", "Angeliki Metallinou", "Anu Venkatesh", "Ariya Rastrow"], "https://doi.org/10.21437/Interspeech.2018-1122", 5], ["Active Memory Networks for Language Modeling.", ["Oscar Chen", "Anton Ragni", "Mark J. F. Gales", "Xie Chen"], "https://doi.org/10.21437/Interspeech.2018-78", 5], ["Unsupervised and Efficient Vocabulary Expansion for Recurrent Neural Network Language Models in ASR.", ["Yerbolat Khassanov", "Eng Siong Chng"], "https://doi.org/10.21437/Interspeech.2018-1021", 5], ["Improving Language Modeling with an Adversarial Critic for Automatic Speech Recognition.", ["Yike Zhang", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1111", 5], ["Training Recurrent Neural Network through Moment Matching for NLP Applications.", ["Yue Deng", "Yilin Shen", "KaWai Chen", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2018-1369", 5], ["Investigation on LSTM Recurrent N-gram Language Models for Speech Recognition.", ["Zoltan Tuske", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2018-2476", 5], ["Online Incremental Learning for Speaker-Adaptive Language Models.", ["Chih Chi Hu", "Bing Liu", "John Shen", "Ian Lane"], "https://doi.org/10.21437/Interspeech.2018-2259", 5], ["Efficient Language Model Adaptation with Noise Contrastive Estimation and Kullback-Leibler Regularization.", ["Jesus Andres-Ferrer", "Nathan Bodenstab", "Paul Vozila"], "https://doi.org/10.21437/Interspeech.2018-1345", 5], ["Recurrent Neural Network Language Model Adaptation for Conversational Speech Recognition.", ["Ke Li", "Hainan Xu", "Yiming Wang", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1413", 5], ["What to Expect from Expected Kneser-Ney Smoothing.", ["Michael Levit", "Sarangarajan Parthasarathy", "Shuangyu Chang"], "https://doi.org/10.21437/Interspeech.2018-84", 5], ["i-Vectors in Language Modeling: An Efficient Way of Domain Adaptation for Feed-Forward Models.", ["Karel Benes", "Santosh Kesiraju", "Lukas Burget"], "https://doi.org/10.21437/Interspeech.2018-1070", 5], ["How Did You like 2017? Detection of Language Markers of Depression and Narcissism in Personal Narratives.", ["Eva-Maria Rathner", "Julia Djamali", "Yannik Terhorst", "Bjorn W. Schuller", "Nicholas Cummins", "Gudrun Salamon", "Christina Hunger-Schoppe", "Harald Baumeister"], "https://doi.org/10.21437/Interspeech.2018-2040", 5], ["Depression Detection from Short Utterances via Diverse Smartphones in Natural Environmental Conditions.", ["Zhaocheng Huang", "Julien Epps", "Dale Joachim", "Michael Chen"], "https://doi.org/10.21437/Interspeech.2018-1743", 5], ["Multi-Lingual Depression-Level Assessment from Conversational Speech Using Acoustic and Text Features.", ["Yasin Ozkanca", "Cenk Demiroglu", "Asli Besirli", "Selime Celik"], "https://doi.org/10.21437/Interspeech.2018-2169", 5], ["Dysarthric Speech Classification Using Glottal Features Computed from Non-words, Words and Sentences.", ["N. P. Narendra", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2018-1059", 5], ["Identifying Schizophrenia Based on Temporal Parameters in Spontaneous Speech.", ["Gabor Gosztolya", "Anita Bagi", "Szilvia Szaloki", "Istvan Szendi", "Ildiko Hoffmann"], "https://doi.org/10.21437/Interspeech.2018-1079", 5], ["Using Prosodic and Lexical Information for Learning Utterance-level Behaviors in Psychotherapy.", ["Karan Singla", "Zhuohao Chen", "Nikolaos Flemotomos", "James Gibson", "Dogan Can", "David C. Atkins", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-2551", 5], ["Automatic Speech Assessment for People with Aphasia Using TDNN-BLSTM with Multi-Task Learning.", ["Ying Qin", "Tan Lee", "Siyuan Feng", "Anthony Pak-Hin Kong"], "https://doi.org/10.21437/Interspeech.2018-1630", 5], ["Towards an Unsupervised Entrainment Distance in Conversational Speech Using Deep Neural Networks.", ["Md. Nasir", "Brian R. Baucom", "Shrikanth Narayanan", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2018-1395", 5], ["Patient Privacy in Paralinguistic Tasks.", ["Francisco Teixeira", "Alberto Abad", "Isabel Trancoso"], "https://doi.org/10.21437/Interspeech.2018-2186", 5], ["A Lightly Supervised Approach to Detect Stuttering in Children's Speech.", ["Sadeen Alharbi", "Madina Hasan", "Anthony J. H. Simons", "Shelagh Brumfitt", "Phil D. Green"], "https://doi.org/10.21437/Interspeech.2018-2155", 5], ["Learning Conditional Acoustic Latent Representation with Gender and Age Attributes for Automatic Pain Level Recognition.", ["Jeng-Lin Li", "Yi-Ming Weng", "Chip-Jin Ng", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2018-1298", 5], ["Speaker and Language Recognition - From Laboratory Technologies to the Wild.", ["Sriram Ganapathy"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/4008.html", 1], ["A Deep Reinforcement Learning Based Multimodal Coaching Model (DCM) for Slot Filling in Spoken Language Understanding(SLU).", ["Yu Wang", "Abhishek Patel", "Yilin Shen", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2018-1379", 5], ["Is ATIS Too Shallow to Go Deeper for Benchmarking Spoken Language Understanding Models?", ["Frederic Bechet", "Christian Raymond"], "https://doi.org/10.21437/Interspeech.2018-2256", 5], ["Robust Spoken Language Understanding via Paraphrasing.", ["Avik Ray", "Yilin Shen", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2018-2358", 5], ["Spoken SQuAD: A Study of Mitigating the Impact of Speech Recognition Errors on Listening Comprehension.", ["Chia-Hsuan Lee", "Szu-Lin Wu", "Chi-Liang Liu", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2018-1714", 5], ["User Information Augmented Semantic Frame Parsing Using Progressive Neural Networks.", ["Yilin Shen", "Xiangyu Zeng", "Yu Wang", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2018-1149", 5], ["An Efficient Approach to Encoding Context for Spoken Language Understanding.", ["Raghav Gupta", "Abhinav Rastogi", "Dilek Hakkani-Tur"], "https://doi.org/10.21437/Interspeech.2018-2403", 5], ["Deep Speech Denoising with Vector Space Projections.", ["Jeffrey Hetherly", "Paul Gamble", "Maria Alejandra Barrios", "Cory Stephenson", "Karl Ni"], "https://doi.org/10.21437/Interspeech.2018-83", 5], ["A Shifted Delta Coefficient Objective for Monaural Speech Separation Using Multi-task Learning.", ["Chenglin Xu", "Wei Rao", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2018-1150", 5], ["A Two-Stage Approach to Noisy Cochannel Speech Separation with Gated Residual Networks.", ["Ke Tan", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2018-1406", 5], ["Monoaural Audio Source Separation Using Variational Autoencoders.", ["Laxmi Pandey", "Anurendra Kumar", "Vinay Namboodiri"], "https://doi.org/10.21437/Interspeech.2018-1140", 5], ["Towards Automated Single Channel Source Separation Using Neural Networks.", ["Arpita Gang", "Pravesh Biyani", "Akshay Soni"], "https://doi.org/10.21437/Interspeech.2018-2065", 5], ["Investigations on Data Augmentation and Loss Functions for Deep Learning Based Speech-Background Separation.", ["Hakan Erdogan", "Takuya Yoshioka"], "https://doi.org/10.21437/Interspeech.2018-2441", 5], ["Annotator Trustability-based Cooperative Learning Solutions for Intelligent Audio Analysis.", ["Simone Hantke", "Christoph Stemp", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1019", 5], ["Semi-supervised Cross-domain Visual Feature Learning for Audio-Visual Broadcast Speech Transcription.", ["Rongfeng Su", "Xunying Liu", "Lan Wang"], "https://doi.org/10.21437/Interspeech.2018-1063", 5], ["Deep Lip Reading: A Comparison of Models and an Online Application.", ["Triantafyllos Afouras", "Joon Son Chung", "Andrew Zisserman"], "https://doi.org/10.21437/Interspeech.2018-1943", 5], ["Iterative Learning of Speech Recognition Models for Air Traffic Control.", ["Ajay Srinivasamurthy", "Petr Motlicek", "Mittul Singh", "Youssef Oualil", "Matthias Kleinert", "Heiko Ehr", "Hartmut Helmke"], "https://doi.org/10.21437/Interspeech.2018-1447", 5], ["Speaker Adaptive Audio-Visual Fusion for the Open-Vocabulary Section of AVICAR.", ["Leda Sari", "Mark Hasegawa-Johnson", "Kumaran S", "Georg Stemmer", "Krishnakumar N. Nair"], "https://doi.org/10.21437/Interspeech.2018-2359", 5], ["Multimodal Name Recognition in Live TV Subtitling.", ["Marek Hruz", "Ales Prazak", "Michal Busta"], "https://doi.org/10.21437/Interspeech.2018-1748", 4], ["Dithered Quantization for Frequency-Domain Speech and Audio Coding.", ["Tom Backstrom", "Johannes Fischer", "Sneha Das"], "https://doi.org/10.21437/Interspeech.2018-46", 5], ["Postfiltering with Complex Spectral Correlations for Speech and Audio Coding.", ["Sneha Das", "Tom Backstrom"], "https://doi.org/10.21437/Interspeech.2018-1026", 5], ["Postfiltering Using Log-Magnitude Spectrum for Speech and Audio Coding.", ["Sneha Das", "Tom Backstrom"], "https://doi.org/10.21437/Interspeech.2018-1027", 5], ["Temporal Noise Shaping with Companding.", ["Arijit Biswas", "Per Hedelin", "Lars F. Villemoes", "Vinay Melkote"], "https://doi.org/10.21437/Interspeech.2018-2096", 5], ["Multi-frame Quantization of LSF Parameters Using a Deep Autoencoder and Pyramid Vector Quantizer.", ["Yaxing Li", "Eshete Derb Emiru", "Shengwu Xiong", "Anna Zhu", "Pengfei Duan", "Yichang Li"], "https://doi.org/10.21437/Interspeech.2018-2577", 5], ["Multi-frame Coding of LSF Parameters Using Block-Constrained Trellis Coded Vector Quantization.", ["Yaxing Li", "Shan Xu", "Shengwu Xiong", "Anna Zhu", "Pengfei Duan", "Yueming Ding"], "https://doi.org/10.21437/Interspeech.2018-2578", 5], ["Training Utterance-level Embedding Networks for Speaker Identification and Verification.", ["Heewoong Park", "Sukhyun Cho", "Kyubyong Park", "Namju Kim", "Jonghun Park"], "https://doi.org/10.21437/Interspeech.2018-1044", 5], ["Analysis of Complementary Information Sources in the Speaker Embeddings Framework.", ["Mahesh Kumar Nandwana", "Mitchell McLaren", "Diego Castan", "Julien van Hout", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2018-1102", 5], ["Self-Attentive Speaker Embeddings for Text-Independent Speaker Verification.", ["Yingke Zhu", "Tom Ko", "David Snyder", "Brian Mak", "Daniel Povey"], "https://doi.org/10.21437/Interspeech.2018-1158", 5], ["An Improved Deep Embedding Learning Method for Short Duration Speaker Verification.", ["Zhifu Gao", "Yan Song", "Ian Vince McLoughlin", "Wu Guo", "Lirong Dai"], "https://doi.org/10.21437/Interspeech.2018-1515", 5], ["Avoiding Speaker Overfitting in End-to-End DNNs Using Raw Waveform for Text-Independent Speaker Verification.", ["Jee-weon Jung", "Hee-Soo Heo", "Il-Ho Yang", "Hye-jin Shim", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2018-1608", 5], ["Deeply Fused Speaker Embeddings for Text-Independent Speaker Verification.", ["Gautam Bhattacharya", "Md. Jahangir Alam", "Vishwa Gupta", "Patrick Kenny"], "https://doi.org/10.21437/Interspeech.2018-1688", 5], ["Employing Phonetic Information in DNN Speaker Embeddings to Improve Speaker Recognition Performance.", ["Md. Hafizur Rahman", "Ivan Himawan", "Mitchell McLaren", "Clinton Fookes", "Sridha Sridharan"], "https://doi.org/10.21437/Interspeech.2018-1804", 5], ["End-to-end Text-dependent Speaker Verification Using Novel Distance Measures.", ["Subhadeep Dey", "Srikanth R. Madikeri", "Petr Motlicek"], "https://doi.org/10.21437/Interspeech.2018-2300", 5], ["Robust Speaker Clustering using Mixtures of von Mises-Fisher Distributions for Naturalistic Audio Streams.", ["Harishchandra Dubey", "Abhijeet Sangwan", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-50", 5], ["Triplet Network with Attention for Speaker Diarization.", ["Huan Song", "Megan M. Willi", "Jayaraman J. Thiagarajan", "Visar Berisha", "Andreas Spanias"], "https://doi.org/10.21437/Interspeech.2018-2305", 5], ["I-vector Transformation Using Conditional Generative Adversarial Networks for Short Utterance Speaker Verification.", ["Jiacen Zhang", "Nakamasa Inoue", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2018-1680", 5], ["Analysis of Length Normalization in End-to-End Speaker Verification System.", ["Weicheng Cai", "Jinkun Chen", "Ming Li"], "https://doi.org/10.21437/Interspeech.2018-92", 5], ["Angular Softmax for Short-Duration Text-independent Speaker Verification.", ["Zili Huang", "Shuai Wang", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2018-1545", 5], ["An End-to-End Text-Independent Speaker Identification System on Short Utterances.", ["Ruifang Ji", "Xinyuan Cai", "Xu Bo"], "https://doi.org/10.21437/Interspeech.2018-1058", 5], ["MTGAN: Speaker Verification through Multitasking Triplet Generative Adversarial Networks.", ["Wenhao Ding", "Liang He"], "https://doi.org/10.21437/Interspeech.2018-1023", 5], ["Categorical vs Dimensional Perception of Italian Emotional Speech.", ["Emilia Parada-Cabaleiro", "Giovanni Costantini", "Anton Batliner", "Alice Baird", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-47", 5], ["A Three-Layer Emotion Perception Model for Valence and Arousal-Based Detection from Multilingual Speech.", ["Xingfeng Li", "Masato Akagi"], "https://doi.org/10.21437/Interspeech.2018-1820", 5], ["Cross-lingual Speech Emotion Recognition through Factor Analysis.", ["Brecht Desplanques", "Kris Demuynck"], "https://doi.org/10.21437/Interspeech.2018-1778", 5], ["Modeling Self-Reported and Observed Affect from Speech.", ["Jian Cheng", "Jared Bernstein", "Elizabeth Rosenfeld", "Peter W. Foltz", "Alex S. Cohen", "Terje B. Holmlund", "Brita Elvevag"], "https://doi.org/10.21437/Interspeech.2018-2222", 5], ["Stochastic Shake-Shake Regularization for Affective Learning from Speech.", ["Che-Wei Huang", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1327", 5], ["Investigating Speech Enhancement and Perceptual Quality for Speech Emotion Recognition.", ["Anderson R. Avila", "Md. Jahangir Alam", "Douglas D. OShaughnessy", "Tiago H. Falk"], "https://doi.org/10.21437/Interspeech.2018-2350", 5], ["Demonstrating and Modelling Systematic Time-varying Annotator Disagreement in Continuous Emotion Annotation.", ["Mia Atcheson", "Vidhyasaharan Sethu", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2018-1933", 5], ["Speech Emotion Recognition from Variable-Length Inputs with Triplet Loss Function.", ["Jian Huang", "Ya Li", "Jianhua Tao", "Zhen Lian"], "https://doi.org/10.21437/Interspeech.2018-1432", 5], ["Imbalance Learning-based Framework for Fear Recognition in the MediaEval Emotional Impact of Movies Task.", ["Xiaotong Zhang", "Xingliang Cheng", "Mingxing Xu", "Thomas Fang Zheng"], "https://doi.org/10.21437/Interspeech.2018-1744", 5], ["Emotion Recognition from Variable-Length Speech Segments Using Deep Learning on Spectrograms.", ["Xi Ma", "Zhiyong Wu", "Jia Jia", "Mingxing Xu", "Helen Meng", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2018-2228", 5], ["Speech Emotion Recognition Using Spectrogram & Phoneme Embedding.", ["Promod Yenigalla", "Abhay Kumar", "Suraj Tripathi", "Chirag Singh", "Sibsambhu Kar", "Jithendra Vepa"], "https://doi.org/10.21437/Interspeech.2018-1811", 5], ["On Enhancing Speech Emotion Recognition Using Generative Adversarial Networks.", ["Saurabh Sahu", "Rahul Gupta", "Carol Y. Espy-Wilson"], "https://doi.org/10.21437/Interspeech.2018-1883", 5], ["Ladder Networks for Emotion Recognition: Using Unsupervised Auxiliary Tasks to Improve Predictions of Emotional Attributes.", ["Srinivas Parthasarathy", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2018-1391", 5], ["Knowledge Distillation for Sequence Model.", ["Mingkun Huang", "Yongbin You", "Zhehuai Chen", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2018-1589", 5], ["Improving CTC-based Acoustic Model with Very Deep Residual Time-delay Neural Networks.", ["Sheng Li", "Xugang Lu", "Ryoichi Takashima", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2018-1475", 5], ["Filter Sampling and Combination CNN (FSC-CNN): A Compact CNN Model for Small-footprint ASR Acoustic Modeling Using Raw Waveforms.", ["Jinxi Guo", "Ning Xu", "Xin Chen", "Yang Shi", "Kaiyuan Xu", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2018-1370", 5], ["Twin Regularization for Online Speech Recognition.", ["Mirco Ravanelli", "Dmitriy Serdyuk", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2018-1407", 5], ["Self-Attentional Acoustic Models.", ["Matthias Sperber", "Jan Niehues", "Graham Neubig", "Sebastian Stuker", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2018-1910", 5], ["Hierarchical Recurrent Neural Networks for Acoustic Modeling.", ["Jinhwan Park", "Iksoo Choi", "Yoonho Boo", "Wonyong Sung"], "https://doi.org/10.21437/Interspeech.2018-1797", 5], ["Dictionary Augmented Sequence-to-Sequence Neural Network for Grapheme to Phoneme Prediction.", ["Antoine Bruguier", "Anton Bakhtin", "Dravyansh Sharma"], "https://doi.org/10.21437/Interspeech.2018-2061", 5], ["Leveraging Second-Order Log-Linear Model for Improved Deep Learning Based ASR Performance.", ["Ankit Raj", "Shakti P. Rath", "Jithendra Vepa"], "https://doi.org/10.21437/Interspeech.2018-1156", 5], ["Semi-Orthogonal Low-Rank Matrix Factorization for Deep Neural Networks.", ["Daniel Povey", "Gaofeng Cheng", "Yiming Wang", "Ke Li", "Hainan Xu", "Mahsa Yarmohammadi", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1417", 5], ["Completely Unsupervised Phoneme Recognition by Adversarially Learning Mapping Relationships from Audio Embeddings.", ["Da-Rong Liu", "Kuan-Yu Chen", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2018-1800", 5], ["Phone Recognition Using a Non-Linear Manifold with Broad Phone Class Dependent DNNs.", ["Mengjie Qian", "Linxue Bai", "Peter Jancovic", "Martin J. Russell"], "https://doi.org/10.21437/Interspeech.2018-1376", 5], ["A Multi-Discriminator CycleGAN for Unsupervised Non-Parallel Speech Domain Adaptation.", ["Ehsan Hosseini-Asl", "Yingbo Zhou", "Caiming Xiong", "Richard Socher"], "https://doi.org/10.21437/Interspeech.2018-1535", 5], ["Interactions between Vowels and Nasal Codas in Mandarin Speakers' Perception of Nasal Finals.", ["Chong Cao", "Wei Wei", "Wei Wang", "Yanlu Xie", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2018-2025", 5], ["Weighting Pitch Contour and Loudness Contour in Mandarin Tone Perception in Cochlear Implant Listeners.", ["Qinglin Meng", "Nengheng Zheng", "Ambika Prasad Mishra", "Jacinta Dan Luo", "Jan W. H. Schnupp"], "https://doi.org/10.21437/Interspeech.2018-1245", 4], ["Implementing DIANA to Model Isolated Auditory Word Recognition in English.", ["Filip Nenadic", "Louis ten Bosch", "Benjamin V. Tucker"], "https://doi.org/10.21437/Interspeech.2018-2081", 5], ["Effects of Homophone Density on Spoken Word Recognition in Mandarin Chinese.", ["Bhamini Sharma"], "https://doi.org/10.21437/Interspeech.2018-2114", 4], ["Visual Timing Information in Audiovisual Speech Perception: Evidence from Lexical Tone Contour.", ["Hui Xie", "Biao Zeng", "Rui Wang"], "https://doi.org/10.21437/Interspeech.2018-1285", 5], ["COSMO SylPhon: A Bayesian Perceptuo-motor Model to Assess Phonological Learning.", ["Marie-Lou Barnaud", "Julien Diard", "Pierre Bessiere", "Jean-Luc Schwartz"], "https://doi.org/10.21437/Interspeech.2018-73", 5], ["Experience-dependent Influence of Music and Language on Lexical Pitch Learning Is Not Additive.", ["Akshay Raj Maggu", "Patrick C. M. Wong", "Hanjun Liu", "Francis C. K. Wong"], "https://doi.org/10.21437/Interspeech.2018-2104", 4], ["Influences of Fundamental Oscillation on Speaker Identification in Vocalic Utterances by Humans and Computers.", ["Volker Dellwo", "Thayabaran Kathiresan", "Elisa Pellegrino", "Lei He", "Sandra Schwab", "Dieter Maurer"], "https://doi.org/10.21437/Interspeech.2018-2331", 5]]