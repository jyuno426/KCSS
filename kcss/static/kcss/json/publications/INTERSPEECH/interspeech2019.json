[["Statistical Approach to Speech Synthesis: Past, Present and Future.", ["Keiichi Tokuda"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs1.html", 0], ["Advances in Automatic Speech Recognition for Child Speech Using Factored Time Delay Neural Network.", ["Fei Wu", "Leibny Paola Garcia-Perera", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2980", 5], ["A Frequency Normalization Technique for Kindergarten Speech Recognition Inspired by the Role of fo in Vowel Perception.", ["Gary Yeung", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2019-1847", 5], ["Improving ASR Systems for Children with Autism and Language Impairment Using Domain-Focused DNN Transfer Techniques.", ["Robert Gale", "Liu Chen", "Jill Dolata", "Jan P. H. van Santen", "Meysam Asgari"], "https://doi.org/10.21437/Interspeech.2019-3161", 5], ["Ultrasound Tongue Imaging for Diarization and Alignment of Child Speech Therapy Sessions.", ["Manuel Sam Ribeiro", "Aciel Eshky", "Korin Richmond", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2019-2612", 5], ["Automated Estimation of Oral Reading Fluency During Summer Camp e-Book Reading with MyTurnToRead.", ["Anastassia Loukina", "Beata Beigman Klebanov", "Patrick L. Lange", "Yao Qian", "Binod Gyawali", "Nitin Madnani", "Abhinav Misra", "Klaus Zechner", "Zuowei Wang", "John Sabatini"], "https://doi.org/10.21437/Interspeech.2019-2889", 5], ["Sustained Vowel Game: A Computer Therapy Game for Children with Dysphonia.", ["Vanessa Lopes", "Joao Magalhaes", "Sofia Cavaco"], "https://doi.org/10.21437/Interspeech.2019-3017", 5], ["The Dependability of Voice on Elders' Acceptance of Humanoid Agents.", ["Anna Esposito", "Terry Amorese", "Marialucia Cuciniello", "Maria Teresa Riviello", "Antonietta Maria Esposito", "Alda Troncone", "Gennaro Cordasco"], "https://doi.org/10.21437/Interspeech.2019-1734", 5], ["God as Interlocutor - Real or Imaginary? Prosodic Markers of Dialogue Speech and Expected Efficacy in Spoken Prayer.", ["Oliver Niebuhr", "Uffe Schjoedt"], "https://doi.org/10.21437/Interspeech.2019-1193", 5], ["Expressiveness Influences Human Vocal Alignment Toward voice-AI.", ["Michelle Cohn", "Georgia Zellou"], "https://doi.org/10.21437/Interspeech.2019-1368", 5], ["Detecting Topic-Oriented Speaker Stance in Conversational Speech.", ["Catherine Lai", "Beatrice Alex", "Johanna D. Moore", "Leimin Tian", "Tatsuro Hori", "Gianpiero Francesca"], "https://doi.org/10.21437/Interspeech.2019-2632", 5], ["Fusion Techniques for Utterance-Level Emotion Recognition Combining Speech and Transcripts.", ["Jilt Sebastian", "Piero Pierucci"], "https://doi.org/10.21437/Interspeech.2019-3201", 5], ["Explaining Sentiment Classification.", ["Marvin Rajwadi", "Cornelius Glackin", "Julie A. Wall", "Gerard Chollet", "Nigel Cannings"], "https://doi.org/10.21437/Interspeech.2019-2743", 5], ["Predicting Group-Level Skin Attention to Short Movies from Audio-Based LSTM-Mixture of Experts Models.", ["Ricardo Kleinlein", "Cristina Luna Jimenez", "Juan Manuel Montero", "Zoraida Callejas", "Fernando Fernandez-Martinez"], "https://doi.org/10.21437/Interspeech.2019-2799", 5], ["Survey Talk: Modeling in Automatic Speech Recognition: Beyond Hidden Markov Models.", ["Ralf Schluter"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs4.html", 0], ["Very Deep Self-Attention Networks for End-to-End Speech Recognition.", ["Ngoc-Quan Pham", "Thai-Son Nguyen", "Jan Niehues", "Markus Muller", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2019-2702", 5], ["Jasper: An End-to-End Convolutional Neural Acoustic Model.", ["Jason Li", "Vitaly Lavrukhin", "Boris Ginsburg", "Ryan Leary", "Oleksii Kuchaiev", "Jonathan M. Cohen", "Huyen Nguyen", "Ravi Teja Gadde"], "https://doi.org/10.21437/Interspeech.2019-1819", 5], ["Unidirectional Neural Network Architectures for End-to-End Automatic Speech Recognition.", ["Niko Moritz", "Takaaki Hori", "Jonathan Le Roux"], "https://doi.org/10.21437/Interspeech.2019-2837", 5], ["Analyzing Phonetic and Graphemic Representations in End-to-End Automatic Speech Recognition.", ["Yonatan Belinkov", "Ahmed Ali", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-2599", 5], ["Multi-Channel Speech Enhancement Using Time-Domain Convolutional Denoising Autoencoder.", ["Naohiro Tawara", "Tetsunori Kobayashi", "Tetsuji Ogawa"], "https://doi.org/10.21437/Interspeech.2019-3197", 5], ["On Nonlinear Spatial Filtering in Multichannel Speech Enhancement.", ["Kristina Tesch", "Robert Rehr", "Timo Gerkmann"], "https://doi.org/10.21437/Interspeech.2019-2751", 5], ["Multi-Channel Block-Online Source Extraction Based on Utterance Adaptation.", ["Juan M. Martin-Donas", "Jens Heitkaemper", "Reinhold Haeb-Umbach", "Angel M. Gomez", "Antonio M. Peinado"], "https://doi.org/10.21437/Interspeech.2019-2244", 5], ["Exploiting Multi-Channel Speech Presence Probability in Parametric Multi-Channel Wiener Filter.", ["Saeed Bagheri", "Daniele Giacobello"], "https://doi.org/10.21437/Interspeech.2019-2665", 5], ["Variational Bayesian Multi-Channel Speech Dereverberation Under Noisy Environments with Probabilistic Convolutive Transfer Function.", ["Masahito Togami", "Tatsuya Komatsu"], "https://doi.org/10.21437/Interspeech.2019-1220", 5], ["Simultaneous Denoising and Dereverberation for Low-Latency Applications Using Frame-by-Frame Online Unified Convolutional Beamformer.", ["Tomohiro Nakatani", "Keisuke Kinoshita"], "https://doi.org/10.21437/Interspeech.2019-1286", 5], ["Individual Variation in Cognitive Processing Style Predicts Differences in Phonetic Imitation of Device and Human Voices.", ["Cathryn Snyder", "Michelle Cohn", "Georgia Zellou"], "https://doi.org/10.21437/Interspeech.2019-2669", 5], ["An Investigation on Speaker Specific Articulatory Synthesis with Speaker Independent Articulatory Inversion.", ["Aravind Illa", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2664", 5], ["Individual Difference of Relative Tongue Size and its Acoustic Effects.", ["Xiaohan Zhang", "Chongke Bi", "Kiyoshi Honda", "Wenhuan Lu", "Jianguo Wei"], "https://doi.org/10.21437/Interspeech.2019-2452", 5], ["Individual Differences of Airflow and Sound Generation in the Vocal Tract of Sibilant /s/.", ["Tsukasa Yoshinaga", "Kazunori Nozaki", "Shigeo Wada"], "https://doi.org/10.21437/Interspeech.2019-1376", 5], ["Hush-Hush Speak: Speech Reconstruction Using Silent Videos.", ["Shashwat Uttam", "Yaman Kumar", "Dhruva Sahrawat", "Mansi Aggarwal", "Rajiv Ratn Shah", "Debanjan Mahata", "Amanda Stent"], "https://doi.org/10.21437/Interspeech.2019-3269", 5], ["SPEAK YOUR MIND! Towards Imagined Speech Recognition with Hierarchical Deep Learning.", ["Pramit Saha", "Muhammad Abdul-Mageed", "Sidney S. Fels"], "https://doi.org/10.21437/Interspeech.2019-3041", 5], ["An Unsupervised Autoregressive Model for Speech Representation Learning.", ["Yu-An Chung", "Wei-Ning Hsu", "Hao Tang", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1473", 5], ["Harmonic-Aligned Frame Mask Based on Non-Stationary Gabor Transform with Application to Content-Dependent Speaker Comparison.", ["Feng Huang", "Peter Balazs"], "https://doi.org/10.21437/Interspeech.2019-1327", 5], ["Glottal Closure Instants Detection from Speech Signal by Deep Features Extracted from Raw Speech and Linear Prediction Residual.", ["Gurunath Reddy M.", "K. Sreenivasa Rao", "Partha Pratim Das"], "https://doi.org/10.21437/Interspeech.2019-1981", 5], ["Learning Problem-Agnostic Speech Representations from Multiple Self-Supervised Tasks.", ["Santiago Pascual", "Mirco Ravanelli", "Joan Serra", "Antonio Bonafonte", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2019-2605", 5], ["Excitation Source and Vocal Tract System Based Acoustic Features for Detection of Nasals in Continuous Speech.", ["Bhanu Teja Nellore", "Sri Harsha Dumpala", "Karan Nathwani", "Suryakanth V. Gangashetty"], "https://doi.org/10.21437/Interspeech.2019-2785", 5], ["Data Augmentation Using GANs for Speech Emotion Recognition.", ["Aggelina Chatziagapi", "Georgios Paraskevopoulos", "Dimitris Sgouropoulos", "Georgios Pantazopoulos", "Malvina Nikandrou", "Theodoros Giannakopoulos", "Athanasios Katsamanis", "Alexandros Potamianos", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-2561", 5], ["High Quality, Lightweight and Adaptable TTS Using LPCNet.", ["Zvi Kons", "Slava Shechtman", "Alexander Sorin", "Carmel Rabinovitz", "Ron Hoory"], "https://doi.org/10.21437/Interspeech.2019-1705", 5], ["Towards Achieving Robust Universal Neural Vocoding.", ["Jaime Lorenzo-Trueba", "Thomas Drugman", "Javier Latorre", "Thomas Merritt", "Bartosz Putrycz", "Roberto Barra-Chicote", "Alexis Moinet", "Vatsal Aggarwal"], "https://doi.org/10.21437/Interspeech.2019-1424", 5], ["Expediting TTS Synthesis with Adversarial Vocoding.", ["Paarth Neekhara", "Chris Donahue", "Miller S. Puckette", "Shlomo Dubnov", "Julian J. McAuley"], "https://doi.org/10.21437/Interspeech.2019-3099", 5], ["Analysis by Adversarial Synthesis - A Novel Approach for Speech Vocoding.", ["Ahmed Mustafa", "Arijit Biswas", "Christian Bergler", "Julia Schottenhamml", "Andreas K. Maier"], "https://doi.org/10.21437/Interspeech.2019-1195", 5], ["Quasi-Periodic WaveNet Vocoder: A Pitch Dependent Dilated Convolution Model for Parametric Speech Generation.", ["Yi-Chiao Wu", "Tomoki Hayashi", "Patrick Lumban Tobing", "Kazuhiro Kobayashi", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2019-1232", 5], ["A Speaker-Dependent WaveNet for Voice Conversion with Non-Parallel Data.", ["Xiaohai Tian", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1514", 5], ["Survey Talk: When Attention Meets Speech Applications: Speech & Speaker Recognition Perspective.", ["Kyu J. Han", "Ramon Prieto", "Tao Ma"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs5.html", 0], ["Attention-Enhanced Connectionist Temporal Classification for Discrete Speech Emotion Recognition.", ["Ziping Zhao", "Zhongtian Bao", "Zixing Zhang", "Nicholas Cummins", "Haishuai Wang", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1649", 5], ["Attentive to Individual: A Multimodal Emotion Recognition Network with Personalized Attention Profile.", ["Jeng-Lin Li", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2044", 5], ["A Saliency-Based Attention LSTM Model for Cognitive Load Classification from Speech.", ["Ascension Gallardo-Antolin", "Juan Manuel Montero"], "https://doi.org/10.21437/Interspeech.2019-1603", 5], ["A Hierarchical Attention Network-Based Approach for Depression Detection from Transcribed Clinical Interviews.", ["Adria Mallol-Ragolta", "Ziping Zhao", "Lukas Stappen", "Nicholas Cummins", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-2036", 5], ["Untranscribed Web Audio for Low Resource Speech Recognition.", ["Andrea Carmantini", "Peter Bell", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2019-2623", 5], ["RWTH ASR Systems for LibriSpeech: Hybrid vs Attention.", ["Christoph Luscher", "Eugen Beck", "Kazuki Irie", "Markus Kitza", "Wilfried Michel", "Albert Zeyer", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-1780", 5], ["Auxiliary Interference Speaker Loss for Target-Speaker Speech Recognition.", ["Naoyuki Kanda", "Shota Horiguchi", "Ryoichi Takashima", "Yusuke Fujita", "Kenji Nagamatsu", "Shinji Watanabe"], "https://doi.org/10.21437/Interspeech.2019-1126", 5], ["Speaker Adaptation for Attention-Based End-to-End Speech Recognition.", ["Zhong Meng", "Yashesh Gaur", "Jinyu Li", "Yifan Gong"], "https://doi.org/10.21437/Interspeech.2019-3135", 5], ["Large Margin Training for Attention Based End-to-End Speech Recognition.", ["Peidong Wang", "Jia Cui", "Chao Weng", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-1680", 5], ["Large-Scale Mixed-Bandwidth Deep Neural Network Acoustic Modeling for Automatic Speech Recognition.", ["Khoi-Nguyen C. Mac", "Xiaodong Cui", "Wei Zhang", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2641", 5], ["SparseSpeech: Unsupervised Acoustic Unit Discovery with Memory-Augmented Sequence Autoencoders.", ["Benjamin Milde", "Chris Biemann"], "https://doi.org/10.21437/Interspeech.2019-2938", 5], ["Bayesian Subspace Hidden Markov Model for Acoustic Unit Discovery.", ["Lucas Ondel", "Hari Krishna Vydana", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-2224", 5], ["Speaker Adversarial Training of DPGMM-Based Feature Extractor for Zero-Resource Languages.", ["Yosuke Higuchi", "Naohiro Tawara", "Tetsunori Kobayashi", "Tetsuji Ogawa"], "https://doi.org/10.21437/Interspeech.2019-2052", 5], ["Building Large-Vocabulary ASR Systems for Languages Without Any Audio Training Data.", ["Manasa Prasad", "Daan van Esch", "Sandy Ritchie", "Jonas Fromseier Mortensen"], "https://doi.org/10.21437/Interspeech.2019-1775", 5], ["Towards Bilingual Lexicon Discovery From Visually Grounded Speech Audio.", ["Emmanuel Azuh", "David Harwath", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1718", 5], ["Improving Unsupervised Subword Modeling via Disentangled Speech Representation Learning and Transformation.", ["Siyuan Feng", "Tan Lee"], "https://doi.org/10.21437/Interspeech.2019-1338", 5], ["Listeners' Ability to Identify the Gender of Preadolescent Children in Different Linguistic Contexts.", ["Shawn L. Nissen", "Sharalee Blunck", "Anita Dromey", "Christopher Dromey"], "https://doi.org/10.21437/Interspeech.2019-1865", 5], ["Sibilant Variation in New Englishes: A Comparative Sociophonetic Study of Trinidadian and American English /s(tr)/-Retraction.", ["Wiebke Ahlers", "Philipp Meer"], "https://doi.org/10.21437/Interspeech.2019-1821", 5], ["Tracking the New Zealand English NEAR/SQUARE Merger Using Functional Principal Components Analysis.", ["Michele Gubian", "Jonathan Harrington", "Mary Stevens", "Florian Schiel", "Paul Warren"], "https://doi.org/10.21437/Interspeech.2019-2115", 5], ["Phonetic Accommodation in a Wizard-of-Oz Experiment: Intonation and Segments.", ["Iona Gessinger", "Bernd Mobius", "Bistra Andreeva", "Eran Raveh", "Ingmar Steiner"], "https://doi.org/10.21437/Interspeech.2019-2445", 5], ["PASCAL and DPA: A Pilot Study on Using Prosodic Competence Scores to Predict Communicative Skills for Team Working and Public Speaking.", ["Oliver Niebuhr", "Jan Michalsky"], "https://doi.org/10.21437/Interspeech.2019-3034", 5], ["Towards the Prosody of Persuasion in Competitive Negotiation. The Relationship Between f0 and Negotiation Success in Same Sex Sales Tasks.", ["Jan Michalsky", "Heike Schoormann", "Thomas Schultze"], "https://doi.org/10.21437/Interspeech.2019-3031", 5], ["VESUS: A Crowd-Annotated Database to Study Emotion Production and Perception in Spoken English.", ["Jacob Sager", "Ravi Shankar", "Jacob Reinhold", "Archana Venkataraman"], "https://doi.org/10.21437/Interspeech.2019-1413", 5], ["Building the Singapore English National Speech Corpus.", ["Jia Xin Koh", "Aqilah Mislan", "Kevin Khoo", "Brian Ang", "Wilson Ang", "Charmaine Ng", "Ying-Ying Tan"], "https://doi.org/10.21437/Interspeech.2019-1525", 5], ["Challenging the Boundaries of Speech Recognition: The MALACH Corpus.", ["Michael Picheny", "Zoltan Tuske", "Brian Kingsbury", "Kartik Audhkhasi", "Xiaodong Cui", "George Saon"], "https://doi.org/10.21437/Interspeech.2019-1907", 5], ["NITK Kids' Speech Corpus.", ["Pravin Bhaskar Ramteke", "Sujata Supanekar", "Pradyoth Hegde", "Hanna Nelson", "Venkataraja Aithal", "Shashidhar G. Koolagudi"], "https://doi.org/10.21437/Interspeech.2019-2061", 5], ["Towards Variability Resistant Dialectal Speech Evaluation.", ["Ahmed Ali", "Salam Khalifa", "Nizar Habash"], "https://doi.org/10.21437/Interspeech.2019-2692", 5], ["How to Annotate 100 Hours in 45 Minutes.", ["Per Fallgren", "Zofia Malisz", "Jens Edlund"], "https://doi.org/10.21437/Interspeech.2019-1648", 5], ["Bayesian HMM Based x-Vector Clustering for Speaker Diarization.", ["Mireia Diez", "Lukas Burget", "Shuai Wang", "Johan Rohdin", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-2813", 5], ["Unleashing the Unused Potential of i-Vectors Enabled by GPU Acceleration.", ["Ville Vestman", "Kong Aik Lee", "Tomi H. Kinnunen", "Takafumi Koshinaka"], "https://doi.org/10.21437/Interspeech.2019-1955", 5], ["MCE 2018: The 1st Multi-Target Speaker Detection and Identification Challenge Evaluation.", ["Suwon Shon", "Najim Dehak", "Douglas A. Reynolds", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1572", 5], ["Improving Aggregation and Loss Function for Better Embedding Learning in End-to-End Speaker Verification System.", ["Zhifu Gao", "Yan Song", "Ian McLoughlin", "Pengcheng Li", "Yiheng Jiang", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2019-1489", 5], ["LSTM Based Similarity Measurement with Spectral Clustering for Speaker Diarization.", ["Qingjian Lin", "Ruiqing Yin", "Ming Li", "Herve Bredin", "Claude Barras"], "https://doi.org/10.21437/Interspeech.2019-1388", 5], ["Who Said That?: Audio-Visual Speaker Diarisation of Real-World Meetings.", ["Joon Son Chung", "Bong-Jin Lee", "Icksang Han"], "https://doi.org/10.21437/Interspeech.2019-3116", 5], ["Multi-PLDA Diarization on Children's Speech.", ["Jiamin Xie", "Leibny Paola Garcia-Perera", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2961", 5], ["Speaker Diarization Using Leave-One-Out Gaussian PLDA Clustering of DNN Embeddings.", ["Alan McCree", "Gregory Sell", "Daniel Garcia-Romero"], "https://doi.org/10.21437/Interspeech.2019-2912", 5], ["Speaker-Corrupted Embeddings for Online Speaker Diarization.", ["Omid Ghahabi", "Volker Fischer"], "https://doi.org/10.21437/Interspeech.2019-2756", 5], ["Speaker Diarization with Lexical Information.", ["Tae Jin Park", "Kyu J. Han", "Jing Huang", "Xiaodong He", "Bowen Zhou", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-1947", 5], ["Joint Speech Recognition and Speaker Diarization via Sequence Transduction.", ["Laurent El Shafey", "Hagen Soltau", "Izhak Shafran"], "https://doi.org/10.21437/Interspeech.2019-1943", 5], ["Normal Variance-Mean Mixtures for Unsupervised Score Calibration.", ["Sandro Cumani"], "https://doi.org/10.21437/Interspeech.2019-1609", 5], ["Speaker Augmentation and Bandwidth Extension for Deep Speaker Embedding.", ["Hitoshi Yamamoto", "Kong Aik Lee", "Koji Okabe", "Takafumi Koshinaka"], "https://doi.org/10.21437/Interspeech.2019-1508", 5], ["Large-Scale Speaker Diarization of Radio Broadcast Archives.", ["Emre Yilmaz", "Adem Derinel", "Kun Zhou", "Henk van den Heuvel", "Niko Brummer", "Haizhou Li", "David A. van Leeuwen"], "https://doi.org/10.21437/Interspeech.2019-1399", 5], ["Toeplitz Inverse Covariance Based Robust Speaker Clustering for Naturalistic Audio Streams.", ["Harishchandra Dubey", "Abhijeet Sangwan", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-1102", 5], ["Examining the Combination of Multi-Band Processing and Channel Dropout for Robust Speech Recognition.", ["Gyorgy Kovacs", "Laszlo Toth", "Dirk Van Compernolle", "Marcus Liwicki"], "https://doi.org/10.21437/Interspeech.2019-3215", 5], ["Label Driven Time-Frequency Masking for Robust Continuous Speech Recognition.", ["Meet H. Soni", "Ashish Panda"], "https://doi.org/10.21437/Interspeech.2019-2172", 5], ["Speaker-Invariant Feature-Mapping for Distant Speech Recognition via Adversarial Teacher-Student Learning.", ["Long Wu", "Hangting Chen", "Li Wang", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-2136", 5], ["Full-Sentence Correlation: A Method to Handle Unpredictable Noise for Robust Speech Recognition.", ["Ji Ming", "Danny Crookes"], "https://doi.org/10.21437/Interspeech.2019-2127", 5], ["Generative Noise Modeling and Channel Simulation for Robust Speech Recognition in Unseen Conditions.", ["Meet H. Soni", "Sonal Joshi", "Ashish Panda"], "https://doi.org/10.21437/Interspeech.2019-2090", 5], ["Far-Field Speech Enhancement Using Heteroscedastic Autoencoder for Improved Speech Recognition.", ["Shashi Kumar", "Shakti P. Rath"], "https://doi.org/10.21437/Interspeech.2019-2032", 5], ["End-to-End SpeakerBeam for Single Channel Target Speech Recognition.", ["Marc Delcroix", "Shinji Watanabe", "Tsubasa Ochiai", "Keisuke Kinoshita", "Shigeki Karita", "Atsunori Ogawa", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2019-1856", 5], ["NIESR: Nuisance Invariant End-to-End Speech Recognition.", ["I-Hung Hsu", "Ayush Jaiswal", "Premkumar Natarajan"], "https://doi.org/10.21437/Interspeech.2019-1836", 5], ["Knowledge Distillation for Throat Microphone Speech Recognition.", ["Takahito Suzuki", "Jun Ogata", "Takashi Tsunakawa", "Masafumi Nishida", "Masafumi Nishimura"], "https://doi.org/10.21437/Interspeech.2019-1597", 5], ["Improved Speaker-Dependent Separation for CHiME-5 Challenge.", ["Jian Wu", "Yong Xu", "Shi-Xiong Zhang", "Lianwu Chen", "Meng Yu", "Lei Xie", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-1569", 5], ["Bridging the Gap Between Monaural Speech Enhancement and Recognition with Distortion-Independent Acoustic Modeling.", ["Peidong Wang", "Ke Tan", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2019-1495", 5], ["Enhanced Spectral Features for Distortion-Independent Acoustic Modeling.", ["Peidong Wang", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2019-1493", 5], ["Universal Adversarial Perturbations for Speech Recognition Systems.", ["Paarth Neekhara", "Shehzeen Hussain", "Prakhar Pandey", "Shlomo Dubnov", "Julian J. McAuley", "Farinaz Koushanfar"], "https://doi.org/10.21437/Interspeech.2019-1353", 5], ["One-Pass Single-Channel Noisy Speech Recognition Using a Combination of Noisy and Enhanced Features.", ["Masakiyo Fujimoto", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-1270", 5], ["Jointly Adversarial Enhancement Training for Robust End-to-End Speech Recognition.", ["Bin Liu", "Shuai Nie", "Shan Liang", "Wenju Liu", "Meng Yu", "Lianwu Chen", "Shouye Peng", "Changliang Li"], "https://doi.org/10.21437/Interspeech.2019-1242", 5], ["Predicting Humor by Learning from Time-Aligned Comments.", ["Zixiaofan Yang", "Bingyan Hu", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2019-3113", 5], ["Predicting the Leading Political Ideology of YouTube Channels Using Acoustic, Textual, and Metadata Information.", ["Yoan Dinkov", "Ahmed Ali", "Ivan Koychev", "Preslav Nakov"], "https://doi.org/10.21437/Interspeech.2019-2965", 5], ["Mitigating Gender and L1 Differences to Improve State and Trait Recognition.", ["Guozhen An", "Rivka Levitan"], "https://doi.org/10.21437/Interspeech.2019-2868", 4], ["Deep Learning Based Mandarin Accent Identification for Accent Robust ASR.", ["Felix Weninger", "Yang Sun", "Junho Park", "Daniel Willett", "Puming Zhan"], "https://doi.org/10.21437/Interspeech.2019-2737", 5], ["Calibrating DNN Posterior Probability Estimates of HMM/DNN Models to Improve Social Signal Detection from Audio Data.", ["Gabor Gosztolya", "Laszlo Toth"], "https://doi.org/10.21437/Interspeech.2019-2552", 5], ["Conversational and Social Laughter Synthesis with WaveNet.", ["Hiroki Mori", "Tomohiro Nagata", "Yoshiko Arimoto"], "https://doi.org/10.21437/Interspeech.2019-2131", 4], ["Laughter Dynamics in Dyadic Conversations.", ["Bogdan Ludusan", "Petra Wagner"], "https://doi.org/10.21437/Interspeech.2019-1733", 5], ["Towards an Annotation Scheme for Complex Laughter in Speech Corpora.", ["Khiet P. Truong", "Jurgen Trouvain", "Michel-Pierre Jansen"], "https://doi.org/10.21437/Interspeech.2019-1557", 5], ["Using Speech to Predict Sequentially Measured Cortisol Levels During a Trier Social Stress Test.", ["Alice Baird", "Shahin Amiriparian", "Nicholas Cummins", "Sarah Sturmbauer", "Johanna Janson", "Eva-Maria Messner", "Harald Baumeister", "Nicolas Rohleder", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1352", 5], ["Sincerity in Acted Speech: Presenting the Sincere Apology Corpus and Results.", ["Alice Baird", "Eduardo Coutinho", "Julia Hirschberg", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1349", 5], ["Do not Hesitate! - Unless You Do it Shortly or Nasally: How the Phonetics of Filled Pauses Determine Their Subjective Frequency and Perceived Speaker Performance.", ["Oliver Niebuhr", "Kerstin Fischer"], "https://doi.org/10.21437/Interspeech.2019-1194", 5], ["Phonet: A Tool Based on Gated Recurrent Neural Networks to Extract Phonological Posteriors from Speech.", ["Juan Camilo Vasquez-Correa", "Philipp Klumpp", "Juan Rafael Orozco-Arroyave", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-1405", 5], ["Code-Switching Sentence Generation by Generative Adversarial Networks and its Application to Data Augmentation.", ["Ching-Ting Chang", "Shun-Po Chuang", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2019-3214", 5], ["Comparative Analysis of Think-Aloud Methods for Everyday Activities in the Context of Cognitive Robotics.", ["Moritz Meier", "Celeste Mason", "Felix Putze", "Tanja Schultz"], "https://doi.org/10.21437/Interspeech.2019-3072", 5], ["RadioTalk: A Large-Scale Corpus of Talk Radio Transcripts.", ["Doug Beeferman", "William Brannon", "Deb Roy"], "https://doi.org/10.21437/Interspeech.2019-2714", 5], ["Qualitative Evaluation of ASR Adaptation in a Lecture Context: Application to the PASTEL Corpus.", ["Salima Mdhaffar", "Yannick Esteve", "Nicolas Hernandez", "Antoine Laurent", "Richard Dufour", "Solen Quiniou"], "https://doi.org/10.21437/Interspeech.2019-2661", 5], ["Active Annotation: Bootstrapping Annotation Lexicon and Guidelines for Supervised NLU Learning.", ["Federico Marinelli", "Alessandra Cervone", "Giuliano Tortoreto", "Evgeny A. Stepanov", "Giuseppe Di Fabbrizio", "Giuseppe Riccardi"], "https://doi.org/10.21437/Interspeech.2019-2537", 5], ["Automatic Lyric Transcription from Karaoke Vocal Tracks: Resources and a Baseline System.", ["Gerardo Roa Dabike", "Jon Barker"], "https://doi.org/10.21437/Interspeech.2019-2378", 5], ["Detecting Mismatch Between Speech and Transcription Using Cross-Modal Attention.", ["Qiang Huang", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2019-2125", 5], ["EpaDB: A Database for Development of Pronunciation Assessment Systems.", ["Jazmin Vidal", "Luciana Ferrer", "Leonardo Brambilla"], "https://doi.org/10.21437/Interspeech.2019-1839", 5], ["Automatic Compression of Subtitles with Neural Networks and its Effect on User Experience.", ["Katrin Angerbauer", "Heike Adel", "Ngoc Thang Vu"], "https://doi.org/10.21437/Interspeech.2019-1750", 5], ["Integrating Video Retrieval and Moment Detection in a Unified Corpus for Video Question Answering.", ["Hongyin Luo", "Mitra Mohtarami", "James R. Glass", "Karthik Krishnamurthy", "Brigitte Richardson"], "https://doi.org/10.21437/Interspeech.2019-1736", 5], ["Early Identification of Speech Changes Due to Amyotrophic Lateral Sclerosis Using Machine Classification.", ["Sarah E. Gutz", "Jun Wang", "Yana Yunusova", "Jordan R. Green"], "https://doi.org/10.21437/Interspeech.2019-2967", 5], ["Automatic Detection of Breath Using Voice Activity Detection and SVM Classifier with Application on News Reports.", ["Mohamed Ismail Yasar Arafath K", "Aurobinda Routray"], "https://doi.org/10.21437/Interspeech.2019-2434", 5], ["Acoustic Scene Classification Using Teacher-Student Learning with Soft-Labels.", ["Hee-Soo Heo", "Jee-weon Jung", "Hye-jin Shim", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1989", 5], ["Rare Sound Event Detection Using Deep Learning and Data Augmentation.", ["Yanping Chen", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2019-1985", 5], ["A Combination of Model-Based and Feature-Based Strategy for Speech-to-Singing Alignment.", ["Bidisha Sharma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1942", 5], ["Dr.VOT: Measuring Positive and Negative Voice Onset Time in the Wild.", ["Yosi Shrem", "Matthew Goldrick", "Joseph Keshet"], "https://doi.org/10.21437/Interspeech.2019-1735", 5], ["Effects of Base-Frequency and Spectral Envelope on Deep-Learning Speech Separation and Recognition Models.", ["J. Hui", "Y. Wei", "S. T. Chen", "R. H. Y. So"], "https://doi.org/10.21437/Interspeech.2019-1715", 5], ["Phone Aware Nearest Neighbor Technique Using Spectral Transition Measure for Non-Parallel Voice Conversion.", ["Nirmesh J. Shah", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2019-1504", 5], ["Weakly Supervised Syllable Segmentation by Vowel-Consonant Peak Classification.", ["Ravi Shankar", "Archana Venkataraman"], "https://doi.org/10.21437/Interspeech.2019-1450", 5], ["An Approach to Online Speaker Change Point Detection Using DNNs and WFSTs.", ["Lukas Mateju", "Petr Cerva", "Jindrich Zdansky"], "https://doi.org/10.21437/Interspeech.2019-1407", 5], ["Regression and Classification for Direction-of-Arrival Estimation with Convolutional Recurrent Neural Networks.", ["Zhenyu Tang", "John D. Kanu", "Kevin Hogan", "Dinesh Manocha"], "https://doi.org/10.21437/Interspeech.2019-1111", 5], ["Non-Parallel Voice Conversion Using Weighted Generative Adversarial Networks.", ["Dipjyoti Paul", "Yannis Pantazis", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2019-2869", 5], ["One-Shot Voice Conversion by Separating Speaker and Content Representations with Instance Normalization.", ["Ju-Chieh Chou", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2019-2663", 5], ["One-Shot Voice Conversion with Global Speaker Embeddings.", ["Hui Lu", "Zhiyong Wu", "Dongyang Dai", "Runnan Li", "Shiyin Kang", "Jia Jia", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2365", 5], ["Non-Parallel Voice Conversion with Cyclic Variational Autoencoder.", ["Patrick Lumban Tobing", "Yi-Chiao Wu", "Tomoki Hayashi", "Kazuhiro Kobayashi", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2019-2307", 5], ["StarGAN-VC2: Rethinking Conditional Methods for StarGAN-Based Voice Conversion.", ["Takuhiro Kaneko", "Hirokazu Kameoka", "Kou Tanaka", "Nobukatsu Hojo"], "https://doi.org/10.21437/Interspeech.2019-2236", 5], ["Robustness of Statistical Voice Conversion Based on Direct Waveform Modification Against Background Sounds.", ["Yusuke Kurita", "Kazuhiro Kobayashi", "Kazuya Takeda", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2019-2206", 5], ["Fast Learning for Non-Parallel Many-to-Many Voice Conversion with Residual Star Generative Adversarial Networks.", ["Shengkui Zhao", "Trung Hieu Nguyen", "Hao Wang", "Bin Ma"], "https://doi.org/10.21437/Interspeech.2019-2067", 5], ["GELP: GAN-Excited Linear Prediction for Speech Synthesis from Mel-Spectrogram.", ["Lauri Juvela", "Bajibabu Bollepalli", "Junichi Yamagishi", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2019-2008", 5], ["Probability Density Distillation with Generative Adversarial Networks for High-Quality Parallel Waveform Generation.", ["Ryuichi Yamamoto", "Eunwoo Song", "Jae-Min Kim"], "https://doi.org/10.21437/Interspeech.2019-1965", 5], ["One-Shot Voice Conversion with Disentangled Representations by Leveraging Phonetic Posteriorgrams.", ["Seyed Hamidreza Mohammadi", "Taehwan Kim"], "https://doi.org/10.21437/Interspeech.2019-1798", 5], ["Investigation of F0 Conditioning and Fully Convolutional Networks in Variational Autoencoder Based Voice Conversion.", ["Wen-Chin Huang", "Yi-Chiao Wu", "Chen-Chou Lo", "Patrick Lumban Tobing", "Tomoki Hayashi", "Kazuhiro Kobayashi", "Tomoki Toda", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-1774", 5], ["Jointly Trained Conversion Model and WaveNet Vocoder for Non-Parallel Voice Conversion Using Mel-Spectrograms and Phonetic Posteriorgrams.", ["Songxiang Liu", "Yuewen Cao", "Xixin Wu", "Lifa Sun", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1316", 5], ["Generative Adversarial Networks for Unpaired Voice Transformation on Impaired Speech.", ["Li-Wei Chen", "Hung-yi Lee", "Yu Tsao"], "https://doi.org/10.21437/Interspeech.2019-1265", 5], ["Group Latent Embedding for Vector Quantized Variational Autoencoder in Non-Parallel Voice Conversion.", ["Shaojin Ding", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2019-1198", 5], ["Semi-Supervised Voice Conversion with Amortized Variational Inference.", ["Cory Stephenson", "Gokce Keskin", "Anil Thomas", "Oguz H. Elibol"], "https://doi.org/10.21437/Interspeech.2019-1840", 5], ["Exploiting Semi-Supervised Training Through a Dropout Regularization in End-to-End Speech Recognition.", ["Subhadeep Dey", "Petr Motlicek", "Trung Bui", "Franck Dernoncourt"], "https://doi.org/10.21437/Interspeech.2019-3246", 5], ["Improved Vocal Tract Length Perturbation for a State-of-the-Art End-to-End Speech Recognition System.", ["Chanwoo Kim", "Minkyu Shin", "Abhinav Garg", "Dhananjaya Gowda"], "https://doi.org/10.21437/Interspeech.2019-3227", 5], ["Multi-Accent Adaptation Based on Gate Mechanism.", ["Han Zhu", "Li Wang", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-3155", 5], ["Unsupervised Adaptation with Adversarial Dropout Regularization for Robust Speech Recognition.", ["Pengcheng Guo", "Sining Sun", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2019-2544", 5], ["Cumulative Adaptation for BLSTM Acoustic Models.", ["Markus Kitza", "Pavel Golik", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-2162", 5], ["Fast DNN Acoustic Model Speaker Adaptation by Learning Hidden Unit Contribution Features.", ["Xurong Xie", "Xunying Liu", "Tan Lee", "Lan Wang"], "https://doi.org/10.21437/Interspeech.2019-2050", 5], ["End-to-End Adaptation with Backpropagation Through WFST for On-Device Speech Recognition System.", ["Emiru Tsunoo", "Yosuke Kashiwagi", "Satoshi Asakawa", "Toshiyuki Kumakura"], "https://doi.org/10.21437/Interspeech.2019-1880", 5], ["Learning Speaker Aware Offsets for Speaker Adaptation of Neural Networks.", ["Leda Sari", "Samuel Thomas", "Mark A. Hasegawa-Johnson"], "https://doi.org/10.21437/Interspeech.2019-1788", 5], ["An Investigation into On-Device Personalization of End-to-End Automatic Speech Recognition Models.", ["Khe Chai Sim", "Petr Zadrazil", "Francoise Beaufays"], "https://doi.org/10.21437/Interspeech.2019-1752", 5], ["A Multi-Accent Acoustic Model Using Mixture of Experts for Speech Recognition.", ["Abhinav Jain", "Vishwanath P. Singh", "Shakti P. Rath"], "https://doi.org/10.21437/Interspeech.2019-1667", 5], ["Personalizing ASR for Dysarthric and Accented Speech with Limited Data.", ["Joel Shor", "Dotan Emanuel", "Oran Lang", "Omry Tuval", "Michael Brenner", "Julie Cattiau", "Fernando Vieira", "Maeve McNally", "Taylor Charbonneau", "Melissa Nollstadt", "Avinatan Hassidim", "Yossi Matias"], "https://doi.org/10.21437/Interspeech.2019-1427", 5], ["Mitigating Noisy Inputs for Question Answering.", ["Denis Peskov", "Joe Barrow", "Pedro Rodriguez", "Graham Neubig", "Jordan L. Boyd-Graber"], "https://doi.org/10.21437/Interspeech.2019-3154", 5], ["One-vs-All Models for Asynchronous Training: An Empirical Analysis.", ["Rahul Gupta", "Aman Alok", "Shankar Ananthakrishnan"], "https://doi.org/10.21437/Interspeech.2019-2760", 5], ["Adapting a FrameNet Semantic Parser for Spoken Language Understanding Using Adversarial Learning.", ["Gabriel Marzinotto", "Geraldine Damnati", "Frederic Bechet"], "https://doi.org/10.21437/Interspeech.2019-2732", 5], ["M2H-GAN: A GAN-Based Mapping from Machine to Human Transcripts for Speech Understanding.", ["Titouan Parcollet", "Mohamed Morchid", "Xavier Bost", "Georges Linares"], "https://doi.org/10.21437/Interspeech.2019-2662", 5], ["Ultra-Compact NLU: Neuronal Network Binarization as Regularization.", ["Munir Georges", "Krzysztof Czarnowski", "Tobias Bocklet"], "https://doi.org/10.21437/Interspeech.2019-2591", 5], ["Speech Model Pre-Training for End-to-End Spoken Language Understanding.", ["Loren Lugosch", "Mirco Ravanelli", "Patrick Ignoto", "Vikrant Singh Tomar", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2019-2396", 5], ["Spoken Language Intent Detection Using Confusion2Vec.", ["Prashanth Gurunath Shivakumar", "Mu Yang", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2019-2226", 5], ["Investigating Adaptation and Transfer Learning for End-to-End Spoken Language Understanding from Speech.", ["Natalia Tomashenko", "Antoine Caubriere", "Yannick Esteve"], "https://doi.org/10.21437/Interspeech.2019-2158", 5], ["Topic-Aware Dialogue Speech Recognition with Transfer Learning.", ["Yuanfeng Song", "Di Jiang", "Xueyang Wu", "Qian Xu", "Raymond Chi-Wing Wong", "Qiang Yang"], "https://doi.org/10.21437/Interspeech.2019-1694", 5], ["Improving Conversation-Context Language Models with Multiple Spoken Language Understanding Models.", ["Ryo Masumura", "Tomohiro Tanaka", "Atsushi Ando", "Hosana Kamiyama", "Takanobu Oba", "Satoshi Kobashikawa", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-1534", 5], ["Meta Learning for Hyperparameter Optimization in Dialogue System.", ["Jen-Tzung Chien", "Wei Xiang Lieow"], "https://doi.org/10.21437/Interspeech.2019-1383", 5], ["Zero Shot Intent Classification Using Long-Short Term Memory Networks.", ["Kyle Williams"], "https://doi.org/10.21437/Interspeech.2019-1274", 5], ["A Comparison of Deep Learning Methods for Language Understanding.", ["Mandy Korpusik", "Zoe Liu", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1262", 5], ["Slot Filling with Weighted Multi-Encoders for Out-of-Domain Values.", ["Yuka Kobayashi", "Takami Yoshida", "Kenji Iwata", "Hiroshi Fujimura"], "https://doi.org/10.21437/Interspeech.2019-1226", 5], ["Multi-Corpus Acoustic-to-Articulatory Speech Inversion.", ["Nadee Seneviratne", "Ganesh Sivaraman", "Carol Y. Espy-Wilson"], "https://doi.org/10.21437/Interspeech.2019-3168", 5], ["Towards a Speaker Independent Speech-BCI Using Speaker Adaptation.", ["Debadatta Dash", "Alan Wisler", "Paul Ferrari", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2019-3109", 5], ["Identifying Input Features for Development of Real-Time Translation of Neural Signals to Text.", ["Janaki Sheth", "Ariel Tankus", "Michelle Tran", "Lindy Comstock", "Itzhak Fried", "William Speier"], "https://doi.org/10.21437/Interspeech.2019-3092", 5], ["Exploring Critical Articulator Identification from 50Hz RT-MRI Data of the Vocal Tract.", ["Samuel S. Silva", "Antonio J. S. Teixeira", "Conceicao Cunha", "Nuno Almeida", "Arun A. Joseph", "Jens Frahm"], "https://doi.org/10.21437/Interspeech.2019-2897", 5], ["Towards a Method of Dynamic Vocal Tract Shapes Generation by Combining Static 3D and Dynamic 2D MRI Speech Data.", ["Ioannis K. Douros", "Anastasiia Tsukanova", "Karyna Isaieva", "Pierre-Andre Vuissoz", "Yves Laprie"], "https://doi.org/10.21437/Interspeech.2019-2880", 5], ["Temporal Coordination of Articulatory and Respiratory Events Prior to Speech Initiation.", ["Oksana Rasskazova", "Christine Mooshammer", "Susanne Fuchs"], "https://doi.org/10.21437/Interspeech.2019-2876", 5], ["Zooming in on Spatiotemporal V-to-C Coarticulation with Functional PCA.", ["Michele Gubian", "Manfred Pastatter", "Marianne Pouplier"], "https://doi.org/10.21437/Interspeech.2019-2143", 5], ["Ultrasound-Based Silent Speech Interface Built on a Continuous Vocoder.", ["Tamas Gabor Csapo", "Mohammed Salah Al-Radhi", "Geza Nemeth", "Gabor Gosztolya", "Tamas Grosz", "Laszlo Toth", "Alexandra Marko"], "https://doi.org/10.21437/Interspeech.2019-2046", 5], ["Assessing Acoustic and Articulatory Dimensions of Speech Motor Adaptation with Random Forests.", ["Eugen Klein", "Jana Brunner", "Phil Hoole"], "https://doi.org/10.21437/Interspeech.2019-1812", 5], ["Speech Organ Contour Extraction Using Real-Time MRI and Machine Learning Method.", ["Hironori Takemoto", "Tsubasa Goto", "Yuya Hagihara", "Sayaka Hamanaka", "Tatsuya Kitamura", "Yukiko Nota", "Kikuo Maekawa"], "https://doi.org/10.21437/Interspeech.2019-1593", 5], ["CNN-Based Phoneme Classifier from Vocal Tract MRI Learns Embedding Consistent with Articulatory Topology.", ["K. G. van Leeuwen", "P. Bos", "Stefano Trebeschi", "Maarten J. A. van Alphen", "Luuk Voskuilen", "Ludi E. Smeele", "Ferdi van der Heijden", "R. J. J. H. van Son"], "https://doi.org/10.21437/Interspeech.2019-1173", 5], ["Strength and Structure: Coupling Tones with Oral Constriction Gestures.", ["Doris Mucke", "Anne Hermes", "Sam Tilsen"], "https://doi.org/10.21437/Interspeech.2019-2650", 5], ["Salient Speech Representations Based on Cloned Networks.", ["W. Bastiaan Kleijn", "Felicia S. C. Lim", "Michael Chinen", "Jan Skoglund"], "https://doi.org/10.21437/Interspeech.2019-1861", 5], ["ASR Inspired Syllable Stress Detection for Pronunciation Evaluation Without Using a Supervised Classifier and Syllable Level Features.", ["Manoj Kumar Ramanathi", "Chiranjeevi Yarra", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2091", 5], ["Acoustic and Articulatory Feature Based Speech Rate Estimation Using a Convolutional Dense Neural Network.", ["Renuka Mannem", "Jhansi Mallela", "Aravind Illa", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2295", 5], ["Predictive Auxiliary Variational Autoencoder for Representation Learning of Global Speech Characteristics.", ["Sebastian Springenberg", "Egor Lakomkin", "Cornelius Weber", "Stefan Wermter"], "https://doi.org/10.21437/Interspeech.2019-2845", 5], ["Unsupervised Low-Rank Representations for Speech Emotion Recognition.", ["Georgios Paraskevopoulos", "Efthymios Tzinis", "Nikolaos Ellinas", "Theodoros Giannakopoulos", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2019-2769", 5], ["On the Suitability of the Riesz Spectro-Temporal Envelope for WaveNet Based Speech Synthesis.", ["Jitendra Kumar Dhiman", "Nagaraj Adiga", "Chandra Sekhar Seelamantula"], "https://doi.org/10.21437/Interspeech.2019-2626", 5], ["Autonomous Emotion Learning in Speech: A View of Zero-Shot Speech Emotion Recognition.", ["Xinzhou Xu", "Jun Deng", "Nicholas Cummins", "Zixing Zhang", "Li Zhao", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-2406", 5], ["An Improved Goodness of Pronunciation (GoP) Measure for Pronunciation Evaluation with DNN-HMM System Considering HMM Transition Probabilities.", ["Sweekar Sudhakara", "Manoj Kumar Ramanathi", "Chiranjeevi Yarra", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2363", 5], ["Low Resource Automatic Intonation Classification Using Gated Recurrent Unit (GRU) Networks Pre-Trained with Synthesized Pitch Patterns.", ["Atreyee Saha", "Chiranjeevi Yarra", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2351", 5], ["Apkinson: A Mobile Solution for Multimodal Assessment of Patients with Parkinson's Disease.", ["Juan Camilo Vasquez-Correa", "Tomas Arias-Vergara", "Philipp Klumpp", "M. Strauss", "Arne Kuderle", "Nils Roth", "S. Bayerl", "Nicanor Garcia-Ospina", "Paula Andrea Perez-Toro", "L. Felipe Parra-Gallego", "Cristian David Rios-Urrego", "D. Escobar-Grisales", "Juan Rafael Orozco-Arroyave", "Bjorn Eskofier", "Elmar Noth"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8003.html", 2], ["Depression State Assessment: Application for Detection of Depression by Speech.", ["Gabor Kiss", "David Sztaho", "Klara Vicsi"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8004.html", 2], ["SPIRE-fluent: A Self-Learning App for Tutoring Oral Fluency to Second Language English Learners.", ["Chiranjeevi Yarra", "Aparna Srinivasan", "Sravani Gottimukkala", "Prasanta Kumar Ghosh"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8008.html", 2], ["Using Real-Time Visual Biofeedback for Second Language Instruction.", ["Shawn L. Nissen", "Rebecca Nissen"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8016.html", 2], ["Splash: Speech and Language Assessment in Schools and Homes.", ["A. Miwardelli", "I. Gallagher", "J. Gibson", "Napoleon Katsos", "Kate M. Knill", "H. Wood"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8027.html", 2], ["Using Ultrasound Imaging to Create Augmented Visual Biofeedback for Articulatory Practice.", ["Colin T. Annand", "Maurice Lamb", "Sarah Dugan", "Sarah R. Li", "Hannah M. Woeste", "T. Douglas Mast", "Michael A. Riley", "Jack A. Masterson", "Neeraja Mahalingam", "Kathryn J. Eary", "Caroline Spencer", "Suzanne Boyce", "Stephanie Jackson", "Anoosha Baxi", "Renee Seward"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8036.html", 2], ["Speech-Based Web Navigation for Limited Mobility Users.", ["Vasiliy Radostev", "Serge Berger", "Justin Tabrizi", "Pasha Kamyshev", "Hisami Suzuki"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8042.html", 2], ["Biosignal Processing for Human-Machine Interaction.", ["Tanja Schultz"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs6.html", 0], ["The Second DIHARD Diarization Challenge: Dataset, Task, and Baselines.", ["Neville Ryant", "Kenneth Church", "Christopher Cieri", "Alejandrina Cristia", "Jun Du", "Sriram Ganapathy", "Mark Liberman"], "https://doi.org/10.21437/Interspeech.2019-1268", 5], ["LEAP Diarization System for the Second DIHARD Challenge.", ["Prachi Singh", "Harsha Vardhan", "Sriram Ganapathy", "A. Kanagasundaram"], "https://doi.org/10.21437/Interspeech.2019-2716", 5], ["ViVoLAB Speaker Diarization System for the DIHARD 2019 Challenge.", ["Ignacio Vinals", "Pablo Gimeno", "Alfonso Ortega Gimenez", "Antonio Miguel", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-2462", 5], ["UWB-NTIS Speaker Diarization System for the DIHARD II 2019 Challenge.", ["Zbynek Zajic", "Marie Kunesova", "Marek Hruz", "Jan Vanek"], "https://doi.org/10.21437/Interspeech.2019-1385", 5], ["The Second DIHARD Challenge: System Description for USC-SAIL Team.", ["Tae Jin Park", "Manoj Kumar", "Nikolaos Flemotomos", "Monisankha Pal", "Raghuveer Peri", "Rimita Lahiri", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-1903", 5], ["Speaker Diarization with Deep Speaker Embeddings for DIHARD Challenge II.", ["Sergey Novoselov", "Aleksei Gusev", "Artem Ivanov", "Timur Pekhovsky", "Andrey Shulipa", "Anastasia Avdeeva", "Artem Gorlanov", "Alexandr Kozlov"], "https://doi.org/10.21437/Interspeech.2019-2757", 5], ["ASVspoof 2019: Future Horizons in Spoofed and Fake Audio Detection.", ["Massimiliano Todisco", "Xin Wang", "Ville Vestman", "Md. Sahidullah", "Hector Delgado", "Andreas Nautsch", "Junichi Yamagishi", "Nicholas W. D. Evans", "Tomi H. Kinnunen", "Kong Aik Lee"], "https://doi.org/10.21437/Interspeech.2019-2249", 5], ["ASSERT: Anti-Spoofing with Squeeze-Excitation and Residual Networks.", ["Cheng-I Lai", "Nanxin Chen", "Jesus Villalba", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-1794", 5], ["Ensemble Models for Spoofing Detection in Automatic Speaker Verification.", ["Bhusan Chettri", "Daniel Stoller", "Veronica Morfi", "Marco A. Martinez Ramirez", "Emmanouil Benetos", "Bob L. Sturm"], "https://doi.org/10.21437/Interspeech.2019-2505", 5], ["The DKU Replay Detection System for the ASVspoof 2019 Challenge: On Data Augmentation, Feature Representation, Classification, and Fusion.", ["Weicheng Cai", "Haiwei Wu", "Danwei Cai", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1230", 5], ["Robust Bayesian and Light Neural Networks for Voice Spoofing Detection.", ["Radoslaw Bialobrzeski", "Michal Kosmider", "Mateusz Matuszewski", "Marcin Plata", "Alexander Rakowski"], "https://doi.org/10.21437/Interspeech.2019-2676", 5], ["STC Antispoofing Systems for the ASVspoof2019 Challenge.", ["Galina Lavrentyeva", "Sergey Novoselov", "Andzhukaev Tseren", "Marina Volkova", "Artem Gorlanov", "Alexandr Kozlov"], "https://doi.org/10.21437/Interspeech.2019-1768", 5], ["The SJTU Robust Anti-Spoofing System for the ASVspoof 2019 Challenge.", ["Yexin Yang", "Hongji Wang", "Heinrich Dinkel", "Zhengyang Chen", "Shuai Wang", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2019-2170", 5], ["IIIT-H Spoofing Countermeasures for Automatic Speaker Verification Spoofing and Countermeasures Challenge 2019.", ["K. N. R. K. Raju Alluri", "Anil Kumar Vuppala"], "https://doi.org/10.21437/Interspeech.2019-1623", 5], ["Anti-Spoofing Speaker Verification System with Multi-Feature Integration and Multi-Task Learning.", ["Rongjin Li", "Miao Zhao", "Zheng Li", "Lin Li", "Qingyang Hong"], "https://doi.org/10.21437/Interspeech.2019-1698", 5], ["Speech Replay Detection with x-Vector Attack Embeddings and Spectral Features.", ["Jennifer Williams", "Joanna Rownicka"], "https://doi.org/10.21437/Interspeech.2019-1760", 5], ["Long Range Acoustic Features for Spoofed Speech Detection.", ["Rohan Kumar Das", "Jichen Yang", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1887", 5], ["Transfer-Representation Learning for Detecting Spoofing Attacks with Converted and Synthesized Speech in Automatic Speaker Verification System.", ["Su-Yu Chang", "Kai-Cheng Wu", "Chia-Ping Chen"], "https://doi.org/10.21437/Interspeech.2019-2014", 5], ["A Light Convolutional GRU-RNN Deep Feature Extractor for ASV Spoofing Detection.", ["Alejandro Gomez Alanis", "Antonio M. Peinado", "Jose A. Gonzalez", "Angel M. Gomez"], "https://doi.org/10.21437/Interspeech.2019-2212", 5], ["Detecting Spoofing Attacks Using VGG and SincNet: BUT-Omilia Submission to ASVspoof 2019 Challenge.", ["Hossein Zeinali", "Themos Stafylakis", "Georgia Athanasopoulou", "Johan Rohdin", "Ioannis Gkinis", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-2892", 5], ["Deep Residual Neural Networks for Audio Spoofing Detection.", ["Moustafa Alzantot", "Ziqi Wang", "Mani B. Srivastava"], "https://doi.org/10.21437/Interspeech.2019-3174", 5], ["Replay Attack Detection with Complementary High-Resolution Information Using End-to-End DNN for the ASVspoof 2019 Challenge.", ["Jee-weon Jung", "Hye-jin Shim", "Hee-Soo Heo", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1991", 5], ["The Zero Resource Speech Challenge 2019: TTS Without T.", ["Ewan Dunbar", "Robin Algayres", "Julien Karadayi", "Mathieu Bernard", "Juan Benjumea", "Xuan-Nga Cao", "Lucie Miskic", "Charlotte Dugrain", "Lucas Ondel", "Alan W. Black", "Laurent Besacier", "Sakriani Sakti", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2019-2904", 5], ["Combining Adversarial Training and Disentangled Speech Representation for Robust Zero-Resource Subword Modeling.", ["Siyuan Feng", "Tan Lee", "Zhiyuan Peng"], "https://doi.org/10.21437/Interspeech.2019-1337", 5], ["Temporally-Aware Acoustic Unit Discovery for Zerospeech 2019 Challenge.", ["Bolaji Yusuf", "Alican Gok", "Batuhan Gundogdu", "Oyku Deniz Kose", "Murat Saraclar"], "https://doi.org/10.21437/Interspeech.2019-1430", 5], ["Unsupervised Acoustic Unit Discovery for Speech Synthesis Using Discrete Latent-Variable Neural Networks.", ["Ryan Eloff", "Andre Nortje", "Benjamin van Niekerk", "Avashna Govender", "Leanne Nortje", "Arnu Pretorius", "Elan Van Biljon", "Ewald van der Westhuizen", "Lisa van Staden", "Herman Kamper"], "https://doi.org/10.21437/Interspeech.2019-1518", 5], ["Unsupervised End-to-End Learning of Discrete Linguistic Units for Voice Conversion.", ["Andy T. Liu", "Po-chun Hsu", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2019-2048", 5], ["Zero Resource Speech Synthesis Using Transcripts Derived from Perceptual Acoustic Units.", ["Karthik Pandia D. S", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2019-2336", 5], ["VQVAE Unsupervised Unit Discovery and Multi-Scale Code2Spec Inverter for Zerospeech Challenge 2019.", ["Andros Tjandra", "Berrak Sisman", "Mingyang Zhang", "Sakriani Sakti", "Haizhou Li", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2019-3232", 5], ["Survey Talk: A Survey on Speech Translation.", ["Jan Niehues"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs9.html", 0], ["Direct Speech-to-Speech Translation with a Sequence-to-Sequence Model.", ["Ye Jia", "Ron J. Weiss", "Fadi Biadsy", "Wolfgang Macherey", "Melvin Johnson", "Zhifeng Chen", "Yonghui Wu"], "https://doi.org/10.21437/Interspeech.2019-1951", 5], ["End-to-End Speech Translation with Knowledge Distillation.", ["Yuchen Liu", "Hao Xiong", "Jiajun Zhang", "Zhongjun He", "Hua Wu", "Haifeng Wang", "Chengqing Zong"], "https://doi.org/10.21437/Interspeech.2019-2582", 5], ["Adapting Transformer to End-to-End Spoken Language Translation.", ["Mattia Antonino Di Gangi", "Matteo Negri", "Marco Turchi"], "https://doi.org/10.21437/Interspeech.2019-3045", 5], ["Unsupervised Phonetic and Word Level Discovery for Speech to Speech Translation for Unwritten Languages.", ["Steven Hillis", "Anushree Prasanna Kumar", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2019-3026", 5], ["Deep Speaker Recognition: Modular or Monolithic?", ["Gautam Bhattacharya", "Md. Jahangir Alam", "Patrick Kenny"], "https://doi.org/10.21437/Interspeech.2019-3146", 5], ["On the Usage of Phonetic Information for Text-Independent Speaker Embedding Extraction.", ["Shuai Wang", "Johan Rohdin", "Lukas Burget", "Oldrich Plchot", "Yanmin Qian", "Kai Yu", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-3036", 5], ["Learning Speaker Representations with Mutual Information.", ["Mirco Ravanelli", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2019-2380", 5], ["Multi-Task Learning with High-Order Statistics for x-Vector Based Text-Independent Speaker Verification.", ["Lanhua You", "Wu Guo", "Li-Rong Dai", "Jun Du"], "https://doi.org/10.21437/Interspeech.2019-2264", 5], ["Data Augmentation Using Variational Autoencoder for Embedding Based Speaker Verification.", ["Zhanghao Wu", "Shuai Wang", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2019-2248", 5], ["Deep Neural Network Embeddings with Gating Mechanisms for Text-Independent Speaker Verification.", ["Lanhua You", "Wu Guo", "Li-Rong Dai", "Jun Du"], "https://doi.org/10.21437/Interspeech.2019-1746", 5], ["Neural Transition Systems for Modeling Hierarchical Semantic Representations.", ["Riyaz Ahmad Bhat", "John Chen", "Rashmi Prasad", "Srinivas Bangalore"], "https://doi.org/10.21437/Interspeech.2019-3075", 5], ["Mining Polysemous Triplets with Recurrent Neural Networks for Spoken Language Understanding.", ["Vedran Vukotic", "Christian Raymond"], "https://doi.org/10.21437/Interspeech.2019-2977", 5], ["Iterative Delexicalization for Improved Spoken Language Understanding.", ["Avik Ray", "Yilin Shen", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2019-2955", 5], ["End-to-End Spoken Language Understanding: Bootstrapping in Low Resource Scenarios.", ["Swapnil Bhosale", "Imran Sheikh", "Sri Harsha Dumpala", "Sunil Kumar Kopparapu"], "https://doi.org/10.21437/Interspeech.2019-2366", 5], ["Recognition of Intentions of Users' Short Responses for Conversational News Delivery System.", ["Hiroaki Takatsu", "Katsuya Yokoyama", "Yoichi Matsuyama", "Hiroshi Honda", "Shinya Fujie", "Tetsunori Kobayashi"], "https://doi.org/10.21437/Interspeech.2019-2121", 5], ["Curriculum-Based Transfer Learning for an Effective End-to-End Spoken Language Understanding and Domain Portability.", ["Antoine Caubriere", "Natalia A. Tomashenko", "Antoine Laurent", "Emmanuel Morin", "Nathalie Camelin", "Yannick Esteve"], "https://doi.org/10.21437/Interspeech.2019-1832", 5], ["Spatial and Spectral Fingerprint in the Brain: Speaker Identification from Single Trial MEG Signals.", ["Debadatta Dash", "Paul Ferrari", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2019-3105", 5], ["ERP Signal Analysis with Temporal Resolution Using a Time Window Bank.", ["Annika Nijveld", "Louis ten Bosch", "Mirjam Ernestus"], "https://doi.org/10.21437/Interspeech.2019-2729", 5], ["Phase Synchronization Between EEG Signals as a Function of Differences Between Stimuli Characteristics.", ["Louis ten Bosch", "Kimberley Mulder", "Louis Boves"], "https://doi.org/10.21437/Interspeech.2019-2443", 5], ["The Processing of Prosodic Cues to Rhetorical Question Interpretation: Psycholinguistic and Neurolinguistics Evidence.", ["Mariya Kharaman", "Manluolan Xu", "Carsten Eulitz", "Bettina Braun"], "https://doi.org/10.21437/Interspeech.2019-2528", 5], ["The Neural Correlates Underlying Lexically-Guided Perceptual Learning.", ["Odette Scharenborg", "Jiska Koemans", "Cybelle Smith", "Mark A. Hasegawa-Johnson", "Kara D. Federmeier"], "https://doi.org/10.21437/Interspeech.2019-2328", 5], ["Speech Quality Evaluation of Synthesized Japanese Speech Using EEG.", ["Ivan Halim Parmonangan", "Hiroki Tanaka", "Sakriani Sakti", "Shinnosuke Takamichi", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2019-2059", 5], ["Multi-Microphone Adaptive Noise Cancellation for Robust Hotword Detection.", ["Yiteng Huang", "Turaj Zakizadeh Shabestary", "Alexander Gruenstein", "Li Wan"], "https://doi.org/10.21437/Interspeech.2019-3006", 5], ["Multi-Task Multi-Network Joint-Learning of Deep Residual Networks and Cycle-Consistency Generative Adversarial Networks for Robust Speech Recognition.", ["Shengkui Zhao", "Chongjia Ni", "Rong Tong", "Bin Ma"], "https://doi.org/10.21437/Interspeech.2019-2078", 5], ["R-Vectors: New Technique for Adaptation to Room Acoustics.", ["Yuri Y. Khokhlov", "Alexander Zatvornitskiy", "Ivan Medennikov", "Ivan Sorokin", "Tatiana Prisyach", "Aleksei Romanenko", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Mariya Korenevskaya", "Oleg Petrov"], "https://doi.org/10.21437/Interspeech.2019-2645", 5], ["Guided Source Separation Meets a Strong ASR Backend: Hitachi/Paderborn University Joint Investigation for Dinner Party ASR.", ["Naoyuki Kanda", "Christoph Boddeker", "Jens Heitkaemper", "Yusuke Fujita", "Shota Horiguchi", "Kenji Nagamatsu", "Reinhold Haeb-Umbach"], "https://doi.org/10.21437/Interspeech.2019-1167", 5], ["Unsupervised Training of Neural Mask-Based Beamforming.", ["Lukas Drude", "Jahn Heymann", "Reinhold Haeb-Umbach"], "https://doi.org/10.21437/Interspeech.2019-2549", 5], ["Acoustic Model Ensembling Using Effective Data Augmentation for CHiME-5 Challenge.", ["Feng Ma", "Li Chai", "Jun Du", "Diyuan Liu", "Zhongfu Ye", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2019-2601", 5], ["Survey Talk: End-to-End Deep Neural Network Based Speaker and Language Recognition.", ["Ming Li", "Weicheng Cai", "Danwei Cai"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs10.html", 0], ["Attention Based Hybrid i-Vector BLSTM Model for Language Recognition.", ["Bharat Padi", "Anand Mohan", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2019-2371", 5], ["RawNet: Advanced End-to-End Deep Neural Network Using Raw Waveforms for Text-Independent Speaker Verification.", ["Jee-weon Jung", "Hee-Soo Heo", "Ju-ho Kim", "Hye-jin Shim", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1982", 5], ["Target Speaker Extraction for Multi-Talker Speaker Verification.", ["Wei Rao", "Chenglin Xu", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1410", 5], ["Improving Keyword Spotting and Language Identification via Neural Architecture Search at Scale.", ["Hanna Mazzawi", "Xavi Gonzalvo", "Aleks Kracun", "Prashant Sridhar", "Niranjan Subrahmanya", "Ignacio Lopez-Moreno", "Hyun-Jin Park", "Patrick Violette"], "https://doi.org/10.21437/Interspeech.2019-1916", 5], ["Forward-Backward Decoding for Regularizing End-to-End TTS.", ["Yibin Zheng", "Xi Wang", "Lei He", "Shifeng Pan", "Frank K. Soong", "Zhengqi Wen", "Jianhua Tao"], "https://doi.org/10.21437/Interspeech.2019-2325", 5], ["A New GAN-Based End-to-End TTS Training Algorithm.", ["Haohan Guo", "Frank K. Soong", "Lei He", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2019-2176", 5], ["Robust Sequence-to-Sequence Acoustic Modeling with Stepwise Monotonic Attention for Neural TTS.", ["Mutian He", "Yan Deng", "Lei He"], "https://doi.org/10.21437/Interspeech.2019-1972", 5], ["Joint Training Framework for Text-to-Speech and Voice Conversion Using Multi-Source Tacotron and WaveNet.", ["Mingyang Zhang", "Xin Wang", "Fuming Fang", "Haizhou Li", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2019-1357", 5], ["Training Multi-Speaker Neural Text-to-Speech Systems Using Speaker-Imbalanced Speech Corpora.", ["Hieu-Thi Luong", "Xin Wang", "Junichi Yamagishi", "Nobuyuki Nishizawa"], "https://doi.org/10.21437/Interspeech.2019-1311", 5], ["Real-Time Neural Text-to-Speech with Sequence-to-Sequence Acoustic Model and WaveGlow or Single Gaussian WaveRNN Vocoders.", ["Takuma Okamoto", "Tomoki Toda", "Yoshinori Shiga", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-1288", 5], ["Fusion Strategy for Prosodic and Lexical Representations of Word Importance.", ["Sushant Kafle", "Cecilia Ovesdotter Alm", "Matt Huenerfauth"], "https://doi.org/10.21437/Interspeech.2019-1898", 5], ["Self Attention in Variational Sequential Learning for Summarization.", ["Jen-Tzung Chien", "Chun-Wei Wang"], "https://doi.org/10.21437/Interspeech.2019-1548", 5], ["Multi-Modal Sentiment Analysis Using Deep Canonical Correlation Analysis.", ["Zhongkai Sun", "Prathusha Kameswara Sarma", "William A. Sethares", "Erik P. Bucy"], "https://doi.org/10.21437/Interspeech.2019-2482", 5], ["Interpreting and Improving Deep Neural SLU Models via Vocabulary Importance.", ["Yilin Shen", "Wenhu Chen", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2019-3184", 5], ["Assessing the Semantic Space Bias Caused by ASR Error Propagation and its Effect on Spoken Document Summarization.", ["Mate Akos Tundik", "Valer Kaszas", "Gyorgy Szaszak"], "https://doi.org/10.21437/Interspeech.2019-2154", 5], ["Latent Topic Attention for Domain Classification.", ["Peisong Huang", "Peijie Huang", "Wencheng Ai", "Jiande Ding", "Jinchuan Zhang"], "https://doi.org/10.21437/Interspeech.2019-2228", 5], ["A Unified Bayesian Source Modelling for Determined Blind Source Separation.", ["Chaitanya Narisetty"], "https://doi.org/10.21437/Interspeech.2019-1272", 5], ["Recursive Speech Separation for Unknown Number of Speakers.", ["Naoya Takahashi", "Sudarsanam Parthasaarathy", "Nabarun Goswami", "Yuki Mitsufuji"], "https://doi.org/10.21437/Interspeech.2019-1550", 5], ["Practical Applicability of Deep Neural Networks for Overlapping Speaker Separation.", ["Pieter Appeltans", "Jeroen Zegers", "Hugo Van hamme"], "https://doi.org/10.21437/Interspeech.2019-1807", 5], ["Speech Separation Using Independent Vector Analysis with an Amplitude Variable Gaussian Mixture Model.", ["Zhaoyi Gu", "Jing Lu", "Kai Chen"], "https://doi.org/10.21437/Interspeech.2019-2076", 5], ["Improved Speech Separation with Time-and-Frequency Cross-Domain Joint Embedding and Clustering.", ["Gene-Ping Yang", "Chao-I Tuan", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2019-2181", 5], ["WHAM!: Extending Speech Separation to Noisy Environments.", ["Gordon Wichern", "Joe Antognini", "Michael Flynn", "Licheng Richard Zhu", "Emmett McQuinn", "Dwight Crow", "Ethan Manilow", "Jonathan Le Roux"], "https://doi.org/10.21437/Interspeech.2019-2821", 5], ["Survey Talk: Preserving Privacy in Speaker and Speech Characterisation.", ["Andreas Nautsch"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs11.html", 0], ["Evaluating Near End Listening Enhancement Algorithms in Realistic Environments.", ["Carol Chermaz", "Cassia Valentini-Botinhao", "Henning F. Schepker", "Simon King"], "https://doi.org/10.21437/Interspeech.2019-1800", 5], ["Improvement and Assessment of Spectro-Temporal Modulation Analysis for Speech Intelligibility Estimation.", ["Amin Edraki", "Wai-Yip Chan", "Jesper Jensen", "Daniel Fogerty"], "https://doi.org/10.21437/Interspeech.2019-2898", 5], ["Listener Preference on the Local Criterion for Ideal Binary-Masked Speech.", ["Zhuohuang Zhang", "Yi Shen"], "https://doi.org/10.21437/Interspeech.2019-1369", 5], ["Using a Manifold Vocoder for Spectral Voice and Style Conversion.", ["Tuan Dinh", "Alexander Kain", "Kris Tjaden"], "https://doi.org/10.21437/Interspeech.2019-1176", 5], ["Multi-Span Acoustic Modelling Using Raw Waveform Signals.", ["Patrick von Platen", "Chao Zhang", "Philip C. Woodland"], "https://doi.org/10.21437/Interspeech.2019-2454", 5], ["An Analysis of Local Monotonic Attention Variants.", ["Andre Merboldt", "Albert Zeyer", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-2879", 5], ["Layer Trajectory BLSTM.", ["Eric Sun", "Jinyu Li", "Yifan Gong"], "https://doi.org/10.21437/Interspeech.2019-2971", 5], ["Improving Transformer-Based End-to-End Speech Recognition with Connectionist Temporal Classification and Language Model Integration.", ["Shigeki Karita", "Nelson Enrique Yalta Soplin", "Shinji Watanabe", "Marc Delcroix", "Atsunori Ogawa", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2019-1938", 5], ["Trainable Dynamic Subsampling for End-to-End Speech Recognition.", ["Shucong Zhang", "Erfan Loweimi", "Yumo Xu", "Peter Bell", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2019-2778", 5], ["Shallow-Fusion End-to-End Contextual Biasing.", ["Ding Zhao", "Tara N. Sainath", "David Rybach", "Pat Rondon", "Deepti Bhatia", "Bo Li", "Ruoming Pang"], "https://doi.org/10.21437/Interspeech.2019-1209", 5], ["Modeling Interpersonal Linguistic Coordination in Conversations Using Word Mover's Distance.", ["Md. Nasir", "Sandeep Nallan Chakravarthula", "Brian R. W. Baucom", "David C. Atkins", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-1900", 5], ["Bag-of-Acoustic-Words for Mental Health Assessment: A Deep Autoencoding Approach.", ["Wenchao Du", "Louis-Philippe Morency", "Jeffrey F. Cohn", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2019-3059", 5], ["Objective Assessment of Social Skills Using Automated Language Analysis for Identification of Schizophrenia and Bipolar Disorder.", ["Rohit Voleti", "Stephanie Woolridge", "Julie M. Liss", "Melissa Milanovic", "Christopher R. Bowie", "Visar Berisha"], "https://doi.org/10.21437/Interspeech.2019-2960", 5], ["Into the Wild: Transitioning from Recognizing Mood in Clinical Interactions to Personal Conversations for Individuals with Bipolar Disorder.", ["Katie Matton", "Melvin G. McInnis", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2019-2698", 5], ["Detecting Depression with Word-Level Multimodal Fusion.", ["Morteza Rohanian", "Julian Hough", "Matthew Purver"], "https://doi.org/10.21437/Interspeech.2019-2283", 5], ["Assessing Neuromotor Coordination in Depression Using Inverted Vocal Tract Variables.", ["Carol Y. Espy-Wilson", "Adam C. Lammert", "Nadee Seneviratne", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2019-1815", 5], ["Towards Universal Dialogue Act Tagging for Task-Oriented Dialogues.", ["Shachi Paul", "Rahul Goel", "Dilek Hakkani-Tur"], "https://doi.org/10.21437/Interspeech.2019-1866", 5], ["HyST: A Hybrid Approach for Flexible and Accurate Dialogue State Tracking.", ["Rahul Goel", "Shachi Paul", "Dilek Hakkani-Tur"], "https://doi.org/10.21437/Interspeech.2019-1863", 5], ["Multi-Lingual Dialogue Act Recognition with Deep Learning Methods.", ["Jiri Martinek", "Pavel Kral", "Ladislav Lenc", "Christophe Cerisara"], "https://doi.org/10.21437/Interspeech.2019-1691", 5], ["BERT-DST: Scalable End-to-End Dialogue State Tracking with Bidirectional Encoder Representations from Transformer.", ["Guan-Lin Chao", "Ian Lane"], "https://doi.org/10.21437/Interspeech.2019-1355", 5], ["Discovering Dialog Rules by Means of an Evolutionary Approach.", ["David Griol", "Zoraida Callejas"], "https://doi.org/10.21437/Interspeech.2019-2230", 5], ["Active Learning for Domain Classification in a Commercial Spoken Personal Assistant.", ["Xi C. Chen", "Adithya Sagar", "Justine T. Kao", "Tony Y. Li", "Christopher Klein", "Stephen Pulman", "Ashish Garg", "Jason D. Williams"], "https://doi.org/10.21437/Interspeech.2019-1315", 5], ["The 2018 NIST Speaker Recognition Evaluation.", ["Seyed Omid Sadjadi", "Craig S. Greenberg", "Elliot Singer", "Douglas A. Reynolds", "Lisa P. Mason", "Jaime Hernandez-Cordero"], "https://doi.org/10.21437/Interspeech.2019-1351", 5], ["State-of-the-Art Speaker Recognition for Telephone and Video Speech: The JHU-MIT Submission for NIST SRE18.", ["Jesus Villalba", "Nanxin Chen", "David Snyder", "Daniel Garcia-Romero", "Alan McCree", "Gregory Sell", "Jonas Borgstrom", "Fred Richardson", "Suwon Shon", "Francois Grondin", "Reda Dehak", "Leibny Paola Garcia-Perera", "Daniel Povey", "Pedro A. Torres-Carrasquillo", "Sanjeev Khudanpur", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2713", 5], ["x-Vector DNN Refinement with Full-Length Recordings for Speaker Recognition.", ["Daniel Garcia-Romero", "David Snyder", "Gregory Sell", "Alan McCree", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2205", 4], ["I4U Submission to NIST SRE 2018: Leveraging from a Decade of Shared Experiences.", ["Kong Aik Lee", "Ville Hautamaki", "Tomi H. Kinnunen", "Hitoshi Yamamoto", "Koji Okabe", "Ville Vestman", "Jing Huang", "Guohong Ding", "Hanwu Sun", "Anthony Larcher", "Rohan Kumar Das", "Haizhou Li", "Mickael Rouvier", "Pierre-Michel Bousquet", "Wei Rao", "Qing Wang", "Chunlei Zhang", "Fahimeh Bahmaninezhad", "Hector Delgado", "Massimiliano Todisco"], "https://doi.org/10.21437/Interspeech.2019-1533", 5], ["Pindrop Labs' Submission to the First Multi-Target Speaker Detection and Identification Challenge.", ["Elie Khoury", "Khaled Lakhdhar", "Andrew Vaughan", "Ganesh Sivaraman", "Parav Nagarsheth"], "https://doi.org/10.21437/Interspeech.2019-3179", 4], ["Speaker Recognition Benchmark Using the CHiME-5 Corpus.", ["Daniel Garcia-Romero", "David Snyder", "Shinji Watanabe", "Gregory Sell", "Alan McCree", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2174", 5], ["Investigating the Effects of Noisy and Reverberant Speech in Text-to-Speech Systems.", ["David Ayllon", "Hector A. Sanchez-Hevia", "Carol Figueroa", "Pierre Lanchantin"], "https://doi.org/10.21437/Interspeech.2019-3104", 5], ["Selection and Training Schemes for Improving TTS Voice Built on Found Data.", ["Fang-Yu Kuo", "Iris Chuoying Ouyang", "Sandesh Aryal", "Pierre Lanchantin"], "https://doi.org/10.21437/Interspeech.2019-2816", 5], ["All Together Now: The Living Audio Dataset.", ["David A. Braude", "Matthew P. Aylett", "Caoimhin Laoide-Kemp", "Simone Ashby", "Kristen M. Scott", "Brian O Raghallaigh", "Anna Braudo", "Alex Brouwer", "Adriana Stan"], "https://doi.org/10.21437/Interspeech.2019-2448", 5], ["LibriTTS: A Corpus Derived from LibriSpeech for Text-to-Speech.", ["Heiga Zen", "Viet Dang", "Rob Clark", "Yu Zhang", "Ron J. Weiss", "Ye Jia", "Zhifeng Chen", "Yonghui Wu"], "https://doi.org/10.21437/Interspeech.2019-2441", 5], ["Corpus Design Using Convolutional Auto-Encoder Embeddings for Audio-Book Synthesis.", ["Meysam Shamsi", "Damien Lolive", "Nelly Barbot", "Jonathan Chevelu"], "https://doi.org/10.21437/Interspeech.2019-2190", 5], ["Evaluating Intention Communication by TTS Using Explicit Definitions of Illocutionary Act Performance.", ["Nobukatsu Hojo", "Noboru Miyazaki"], "https://doi.org/10.21437/Interspeech.2019-2188", 5], ["MOSNet: Deep Learning-Based Objective Assessment for Voice Conversion.", ["Chen-Chou Lo", "Szu-Wei Fu", "Wen-Chin Huang", "Xin Wang", "Junichi Yamagishi", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-2003", 5], ["Investigating the Robustness of Sequence-to-Sequence Text-to-Speech Models to Imperfectly-Transcribed Training Data.", ["Jason Fong", "Pilar Oplustil Gallegos", "Zack Hodari", "Simon King"], "https://doi.org/10.21437/Interspeech.2019-1824", 5], ["Using Pupil Dilation to Measure Cognitive Load When Listening to Text-to-Speech in Quiet and in Noise.", ["Avashna Govender", "Anita E. Wagner", "Simon King"], "https://doi.org/10.21437/Interspeech.2019-1783", 5], ["A Multimodal Real-Time MRI Articulatory Corpus of French for Speech Research.", ["Ioannis K. Douros", "Jacques Felblinger", "Jens Frahm", "Karyna Isaieva", "Arun A. Joseph", "Yves Laprie", "Freddy Odille", "Anastasiia Tsukanova", "Dirk Voit", "Pierre-Andre Vuissoz"], "https://doi.org/10.21437/Interspeech.2019-1700", 5], ["A Chinese Dataset for Identifying Speakers in Novels.", ["Jia-Xiang Chen", "Zhen-Hua Ling", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2019-1614", 5], ["CSS10: A Collection of Single Speaker Speech Datasets for 10 Languages.", ["Kyubyong Park", "Thomas Mulc"], "https://doi.org/10.21437/Interspeech.2019-1500", 5], ["Attention Model for Articulatory Features Detection.", ["Ievgen Karaulov", "Dmytro Tkanov"], "https://doi.org/10.21437/Interspeech.2019-3020", 5], ["Unbiased Semi-Supervised LF-MMI Training Using Dropout.", ["Sibo Tong", "Apoorv Vyas", "Philip N. Garner", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2019-2678", 5], ["Acoustic Model Optimization Based on Evolutionary Stochastic Gradient Descent with Anchors for Automatic Speech Recognition.", ["Xiaodong Cui", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2620", 5], ["Whether to Pretrain DNN or not?: An Empirical Analysis for Voice Conversion.", ["Nirmesh J. Shah", "Hardik B. Sailor", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2019-2608", 5], ["Detection of Glottal Closure Instants from Raw Speech Using Convolutional Neural Networks.", ["Mohit Goyal", "Varun Srivastava", "Prathosh A. P."], "https://doi.org/10.21437/Interspeech.2019-2587", 5], ["Lattice-Based Lightly-Supervised Acoustic Model Training.", ["Joachim Fainberg", "Ondrej Klejch", "Steve Renals", "Peter Bell"], "https://doi.org/10.21437/Interspeech.2019-2533", 5], ["Comparison of Lattice-Free and Lattice-Based Sequence Discriminative Training Criteria for LVCSR.", ["Wilfried Michel", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-2254", 5], ["End-to-End Automatic Speech Recognition with a Reconstruction Criterion Using Speech-to-Text and Text-to-Speech Encoder-Decoders.", ["Ryo Masumura", "Hiroshi Sato", "Tomohiro Tanaka", "Takafumi Moriya", "Yusuke Ijima", "Takanobu Oba"], "https://doi.org/10.21437/Interspeech.2019-2111", 5], ["Char+CV-CTC: Combining Graphemes and Consonant/Vowel Units for CTC-Based ASR Using Multitask Learning.", ["Abdelwahab Heba", "Thomas Pellegrini", "Jean-Pierre Lorre", "Regine Andre-Obrecht"], "https://doi.org/10.21437/Interspeech.2019-1975", 5], ["Guiding CTC Posterior Spike Timings for Improved Posterior Fusion and Knowledge Distillation.", ["Gakuto Kurata", "Kartik Audhkhasi"], "https://doi.org/10.21437/Interspeech.2019-1952", 5], ["Direct Neuron-Wise Fusion of Cognate Neural Networks.", ["Takashi Fukuda", "Masayuki Suzuki", "Gakuto Kurata"], "https://doi.org/10.21437/Interspeech.2019-1930", 5], ["Two Tiered Distributed Training Algorithm for Acoustic Modeling.", ["Pranav Ladkat", "Oleg Rybakov", "Radhika Arava", "Sree Hari Krishnan Parthasarathi", "I-Fan Chen", "Nikko Strom"], "https://doi.org/10.21437/Interspeech.2019-1859", 5], ["Exploring the Encoder Layers of Discriminative Autoencoders for LVCSR.", ["Pin-Tuan Huang", "Hung-Shin Lee", "Syu-Siang Wang", "Kuan-Yu Chen", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-1717", 5], ["Multi-Task CTC Training with Auxiliary Feature Reconstruction for End-to-End Speech Recognition.", ["Gakuto Kurata", "Kartik Audhkhasi"], "https://doi.org/10.21437/Interspeech.2019-1710", 5], ["Framewise Supervised Training Towards End-to-End Speech Recognition Models: First Results.", ["Mohan Li", "Yuanjiang Cao", "Weicong Zhou", "Min Liu"], "https://doi.org/10.21437/Interspeech.2019-1117", 5], ["Deep Hierarchical Fusion with Application in Sentiment Analysis.", ["Efthymios Georgiou", "Charilaos Papaioannou", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2019-3243", 5], ["Leveraging Acoustic Cues and Paralinguistic Embeddings to Detect Expression from Voice.", ["Vikramjit Mitra", "Sue Booker", "Erik Marchi", "David Scott Farrar", "Ute Dorothea Peitz", "Bridget Cheng", "Ermine Teves", "Anuj Mehta", "Devang Naik"], "https://doi.org/10.21437/Interspeech.2019-2998", 5], ["Analysis of Deep Learning Architectures for Cross-Corpus Speech Emotion Recognition.", ["Jack Parry", "Dimitri Palaz", "Georgia Clarke", "Pauline Lecomte", "Rebecca Mead", "Michael Berger", "Gregor Hofer"], "https://doi.org/10.21437/Interspeech.2019-2753", 5], ["A Path Signature Approach for Speech Emotion Recognition.", ["Bo Wang", "Maria Liakata", "Hao Ni", "Terry Lyons", "Alejo J. Nevado-Holgado", "Kate Saunders"], "https://doi.org/10.21437/Interspeech.2019-2624", 5], ["Employing Bottleneck and Convolutional Features for Speech-Based Physical Load Detection on Limited Data Amounts.", ["Olga Egorow", "Tarik Mrech", "Norman Weisskirchen", "Andreas Wendemuth"], "https://doi.org/10.21437/Interspeech.2019-2502", 5], ["Speech Emotion Recognition in Dyadic Dialogues with Attentive Interaction Modeling.", ["Jinming Zhao", "Shizhe Chen", "Jingjun Liang", "Qin Jin"], "https://doi.org/10.21437/Interspeech.2019-2103", 5], ["Predicting Group Performances Using a Personality Composite-Network Architecture During Collaborative Task.", ["Shun-Chang Zhong", "Yun-Shao Lin", "Chun-Min Chang", "Yi-Ching Liu", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2087", 5], ["Enforcing Semantic Consistency for Cross Corpus Valence Regression from Speech Using Adversarial Discrepancy Learning.", ["Gao-Yi Chao", "Yun-Shao Lin", "Chun-Min Chang", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2037", 5], ["Deep Learning of Segment-Level Feature Representation with Multiple Instance Learning for Utterance-Level Speech Emotion Recognition.", ["Shuiyang Mao", "P. C. Ching", "Tan Lee"], "https://doi.org/10.21437/Interspeech.2019-1968", 5], ["Towards Robust Speech Emotion Recognition Using Deep Residual Networks for Speech Enhancement.", ["Andreas Triantafyllopoulos", "Gil Keren", "Johannes Wagner", "Ingmar Steiner", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1811", 5], ["Towards Discriminative Representations and Unbiased Predictions: Class-Specific Angular Softmax for Speech Emotion Recognition.", ["Zhixuan Li", "Liang He", "Jingyang Li", "Li Wang", "Wei-Qiang Zhang"], "https://doi.org/10.21437/Interspeech.2019-1683", 5], ["Learning Temporal Clusters Using Capsule Routing for Speech Emotion Recognition.", ["Md Asif Jalal", "Erfan Loweimi", "Roger K. Moore", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2019-3068", 5], ["L2 Pronunciation Accuracy and Context: A Pilot Study on the Realization of Geminates in Italian as L2 by French Learners.", ["Sonia DApolito", "Barbara Gili Fivela"], "https://doi.org/10.21437/Interspeech.2019-2934", 5], ["The Monophthongs of Formal Nigerian English: An Acoustic Analysis.", ["Nisad Jamakovic", "Robert Fuchs"], "https://doi.org/10.21437/Interspeech.2019-2866", 5], ["Quantifying Fundamental Frequency Modulation as a Function of Language, Speaking Style and Speaker.", ["Pablo Arantes", "Anders Eriksson"], "https://doi.org/10.21437/Interspeech.2019-2857", 5], ["The Voicing Contrast in Stops and Affricates in the Western Armenian of Lebanon.", ["Niamh E. Kelly", "Lara Keshishian"], "https://doi.org/10.21437/Interspeech.2019-2529", 5], ["\" Gra[f] e!\" Word-Final Devoicing of Obstruents in Standard French: An Acoustic Study Based on Large Corpora.", ["Adele Jatteau", "Ioana Vasilescu", "Lori Lamel", "Martine Adda-Decker", "Nicolas Audibert"], "https://doi.org/10.21437/Interspeech.2019-2329", 5], ["Acoustic Indicators of Deception in Mandarin Daily Conversations Recorded from an Interactive Game.", ["Chih-Hsiang Huang", "Huang-Cheng Chou", "Yi-Tong Wu", "Chi-Chun Lee", "Yi-Wen Liu"], "https://doi.org/10.21437/Interspeech.2019-2216", 5], ["Prosodic Effects on Plosive Duration in German and Austrian German.", ["Barbara Schuppler", "Margaret Zellers"], "https://doi.org/10.21437/Interspeech.2019-2197", 5], ["Cross-Lingual Consistency of Phonological Features: An Empirical Study.", ["Cibu Johny", "Alexander Gutkin", "Martin Jansche"], "https://doi.org/10.21437/Interspeech.2019-2184", 5], ["Are IP Initial Vowels Acoustically More Distinct? Results from LDA and CNN Classifications.", ["Fanny Guitard-Ivent", "Gabriele Chignoli", "Cecile Fougeron", "Laurianne Georgeton"], "https://doi.org/10.21437/Interspeech.2019-2153", 5], ["Neural Network-Based Modeling of Phonetic Durations.", ["Xizi Wei", "Melvyn Hunt", "Adrian Skilling"], "https://doi.org/10.21437/Interspeech.2019-2102", 5], ["An Acoustic Study of Vowel Undershoot in a System with Several Degrees of Prominence.", ["Janina Molczanow", "Beata Lukaszewicz", "Anna Lukaszewicz"], "https://doi.org/10.21437/Interspeech.2019-1806", 5], ["A Preliminary Study of Charismatic Speech on YouTube: Correlating Prosodic Variation with Counts of Subscribers, Views and Likes.", ["Stephanie Berger", "Oliver Niebuhr", "Margaret Zellers"], "https://doi.org/10.21437/Interspeech.2019-1664", 5], ["Phonetic Detail Encoding in Explaining the Size of Speech Planning Window.", ["Shan Luo"], "https://doi.org/10.21437/Interspeech.2019-1412", 5], ["Acoustic Cues to Topic and Narrow Focus in Egyptian Arabic.", ["Dina El Zarka", "Barbara Schuppler", "Francesco Cangemi"], "https://doi.org/10.21437/Interspeech.2019-1189", 5], ["Acoustic and Articulatory Study of Ewe Vowels: A Comparative Study of Male and Female.", ["Kowovi Comivi Alowonou", "Jianguo Wei", "Wenhuan Lu", "Zhicheng Liu", "Kiyoshi Honda", "Jianwu Dang"], "https://doi.org/10.21437/Interspeech.2019-2196", 5], ["Speech Augmentation via Speaker-Specific Noise in Unseen Environment.", ["Yanan Guo", "Ziping Zhao", "Yide Ma", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-2712", 5], ["UNetGAN: A Robust Speech Enhancement Approach in Time Domain for Extremely Low Signal-to-Noise Ratio Condition.", ["Xiang Hao", "Xiangdong Su", "Zhiyu Wang", "Hui Zhang", "Batushiren"], "https://doi.org/10.21437/Interspeech.2019-1567", 5], ["Towards Generalized Speech Enhancement with Generative Adversarial Networks.", ["Santiago Pascual", "Joan Serra", "Antonio Bonafonte"], "https://doi.org/10.21437/Interspeech.2019-2688", 5], ["A Convolutional Neural Network with Non-Local Module for Speech Enhancement.", ["Xiaoqi Li", "Yaxing Li", "Meng Li", "Shan Xu", "Yuanjie Dong", "Xinrong Sun", "Shengwu Xiong"], "https://doi.org/10.21437/Interspeech.2019-2472", 5], ["IA-NET: Acceleration and Compression of Speech Enhancement Using Integer-Adder Deep Neural Network.", ["Yu-Chen Lin", "Yi-Te Hsu", "Szu-Wei Fu", "Yu Tsao", "Tei-Wei Kuo"], "https://doi.org/10.21437/Interspeech.2019-1207", 5], ["KL-Divergence Regularized Deep Neural Network Adaptation for Low-Resource Speaker-Dependent Speech Enhancement.", ["Li Chai", "Jun Du", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2019-2426", 5], ["Speech Enhancement with Wide Residual Networks in Reverberant Environments.", ["Jorge Llombart", "Dayana Ribas", "Antonio Miguel", "Luis Vicente", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-1745", 5], ["A Scalable Noisy Speech Dataset and Online Subjective Test Framework.", ["Chandan K. A. Reddy", "Ebrahim Beyrami", "Jamie Pool", "Ross Cutler", "Sriram Srinivasan", "Johannes Gehrke"], "https://doi.org/10.21437/Interspeech.2019-3087", 5], ["Speech Enhancement for Noise-Robust Speech Synthesis Using Wasserstein GAN.", ["Nagaraj Adiga", "Yannis Pantazis", "Vassilis Tsiaras", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2019-2648", 5], ["A Non-Causal FFTNet Architecture for Speech Enhancement.", ["P. V. Muhammed Shifas", "Nagaraj Adiga", "Vassilis Tsiaras", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2019-2622", 5], ["Speech Enhancement with Variance Constrained Autoencoders.", ["Daniel T. Braithwaite", "W. Bastiaan Kleijn"], "https://doi.org/10.21437/Interspeech.2019-1809", 5], ["A Deep Learning Approach to Automatic Characterisation of Rhythm in Non-Native English Speech.", ["Konstantinos Kyriakopoulos", "Kate M. Knill", "Mark J. F. Gales"], "https://doi.org/10.21437/Interspeech.2019-3186", 5], ["Language Learning Using Speech to Image Retrieval.", ["Danny Merkx", "Stefan L. Frank", "Mirjam Ernestus"], "https://doi.org/10.21437/Interspeech.2019-3067", 5], ["Using Alexa for Flashcard-Based Learning.", ["Lucy Skidmore", "Roger K. Moore"], "https://doi.org/10.21437/Interspeech.2019-2893", 5], ["The 2019 Inaugural Fearless Steps Challenge: A Giant Leap for Naturalistic Audio.", ["John H. L. Hansen", "Aditya Joglekar", "Meena Chandra Shekhar", "Vinay Kothapally", "Chengzhu Yu", "Lakshmish Kaushik", "Abhijeet Sangwan"], "https://doi.org/10.21437/Interspeech.2019-2301", 5], ["Completely Unsupervised Phoneme Recognition by a Generative Adversarial Network Harmonized with Iteratively Refined Hidden Markov Models.", ["Kuan-Yu Chen", "Che-Ping Tsai", "Da-Rong Liu", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2019-2068", 5], ["Analysis of Native Listeners' Facial Microexpressions While Shadowing Non-Native Speech - Potential of Shadowers' Facial Expressions for Comprehensibility Prediction.", ["Tasavat Trisitichoke", "Shintaro Ando", "Daisuke Saito", "Nobuaki Minematsu"], "https://doi.org/10.21437/Interspeech.2019-1953", 5], ["Transparent Pronunciation Scoring Using Articulatorily Weighted Phoneme Edit Distance.", ["Reima Karhila", "Anna-Riikka Smolander", "Sari Ylinen", "Mikko Kurimo"], "https://doi.org/10.21437/Interspeech.2019-1785", 5], ["Development of Robust Automated Scoring Models Using Adversarial Input for Oral Proficiency Assessment.", ["Su-Youn Yoon", "Chong Min Lee", "Klaus Zechner", "Keelan Evanini"], "https://doi.org/10.21437/Interspeech.2019-1711", 5], ["Impact of ASR Performance on Spoken Grammatical Error Detection.", ["Yiting Lu", "Mark J. F. Gales", "Kate M. Knill", "P. P. Manakul", "Linlin Wang", "Y. Wang"], "https://doi.org/10.21437/Interspeech.2019-1706", 5], ["Self-Imitating Feedback Generation Using GAN for Computer-Assisted Pronunciation Training.", ["Seung Hee Yang", "Minhwa Chung"], "https://doi.org/10.21437/Interspeech.2019-1478", 5], ["Joint Student-Teacher Learning for Audio-Visual Scene-Aware Dialog.", ["Chiori Hori", "Anoop Cherian", "Tim K. Marks", "Takaaki Hori"], "https://doi.org/10.21437/Interspeech.2019-3143", 5], ["Topical-Chat: Towards Knowledge-Grounded Open-Domain Conversations.", ["Karthik Gopalakrishnan", "Behnam Hedayatnia", "Qinglang Chen", "Anna Gottardi", "Sanjeev Kwatra", "Anu Venkatesh", "Raefer Gabriel", "Dilek Hakkani-Tur"], "https://doi.org/10.21437/Interspeech.2019-3079", 5], ["Analyzing Verbal and Nonverbal Features for Predicting Group Performance.", ["Uliyana Kubasova", "Gabriel Murray", "McKenzie Braley"], "https://doi.org/10.21437/Interspeech.2019-3062", 5], ["Identifying Therapist and Client Personae for Therapeutic Alliance Estimation.", ["Victor R. Martinez", "Nikolaos Flemotomos", "Victor Ardulov", "Krishna Somandepalli", "Simon B. Goldberg", "Zac E. Imel", "David C. Atkins", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-2829", 5], ["Do Hesitations Facilitate Processing of Partially Defective System Utterances? An Exploratory Eye Tracking Study.", ["Kristin Haake", "Sarah Schimke", "Simon Betz", "Sina Zarriess"], "https://doi.org/10.21437/Interspeech.2019-2820", 5], ["Influence of Contextuality on Prosodic Realization of Information Structure in Chinese Dialogues.", ["Bin Li", "Yuan Jia"], "https://doi.org/10.21437/Interspeech.2019-2291", 5], ["Cross-Lingual Transfer Learning for Affective Spoken Dialogue Systems.", ["Kristijan Gjoreski", "Aleksandar Gjoreski", "Ivan Kraljevski", "Diane Hirschfeld"], "https://doi.org/10.21437/Interspeech.2019-2163", 5], ["Identifying Personality Traits Using Overlap Dynamics in Multiparty Dialogue.", ["Mingzhi Yu", "Emer Gilmartin", "Diane J. Litman"], "https://doi.org/10.21437/Interspeech.2019-1886", 5], ["Identifying Mood Episodes Using Dialogue Features from Clinical Interviews.", ["Zakaria Aldeneh", "Mimansa Jaiswal", "Michael Picheny", "Melvin G. McInnis", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2019-1878", 5], ["Do Conversational Partners Entrain on Articulatory Precision?", ["Nichola Lubold", "Stephanie A. Borrie", "Tyson S. Barrett", "Megan M. Willi", "Visar Berisha"], "https://doi.org/10.21437/Interspeech.2019-1786", 5], ["Conversational Emotion Analysis via Attention Mechanisms.", ["Zheng Lian", "Jianhua Tao", "Bin Liu", "Jian Huang"], "https://doi.org/10.21437/Interspeech.2019-1577", 5], ["The Effect of Phoneme Distribution on Perceptual Similarity in English.", ["Emma ONeill", "Julie Carson-Berndsen"], "https://doi.org/10.21437/Interspeech.2019-3042", 5], ["Prosodic Representations of Prominence Classification Neural Networks and Autoencoders Using Bottleneck Features.", ["Sofoklis Kakouros", "Antti Suni", "Juraj Simko", "Martti Vainio"], "https://doi.org/10.21437/Interspeech.2019-2984", 5], ["Compensation for French Liquid Deletion During Auditory Sentence Processing.", ["Sharon Peperkamp", "Alvaro Martin Iturralde Zurita"], "https://doi.org/10.21437/Interspeech.2019-2950", 5], ["Prosodic Factors Influencing Vowel Reduction in Russian.", ["Daniil Kocharov", "Tatiana Kachkovskaia", "Pavel A. Skrelin"], "https://doi.org/10.21437/Interspeech.2019-2918", 5], ["Time to Frequency Domain Mapping of the Voice Source: The Influence of Open Quotient and Glottal Skew on the Low End of the Source Spectrum.", ["Christer Gobl", "Ailbhe Ni Chasaide"], "https://doi.org/10.21437/Interspeech.2019-2888", 5], ["Testing the Distinctiveness of Intonational Tunes: Evidence from Imitative Productions in American English.", ["Eleanor Chodroff", "Jennifer S. Cole"], "https://doi.org/10.21437/Interspeech.2019-2684", 5], ["A Study of a Cross-Language Perception Based on Cortical Analysis Using Biomimetic STRFs.", ["Sangwook Park", "David K. Han", "Mounya Elhilali"], "https://doi.org/10.21437/Interspeech.2019-2507", 5], ["Perceptual Evaluation of Early versus Late F0 Peaks in the Intonation Structure of Czech Question-Word Questions.", ["Pavel Sturm", "Jan Volin"], "https://doi.org/10.21437/Interspeech.2019-2082", 5], ["Acoustic Correlates of Phonation Type in Chichimec.", ["Anneliese Kelterer", "Barbara Schuppler"], "https://doi.org/10.21437/Interspeech.2019-2066", 5], ["F0 Variability Measures Based on Glottal Closure Instants.", ["Yu-Ren Chien", "Michal Borsky", "Jon Gudnason"], "https://doi.org/10.21437/Interspeech.2019-1326", 4], ["Recognition of Creaky Voice from Emergency Calls.", ["Lauri Tavi", "Tanel Alumae", "Stefan Werner"], "https://doi.org/10.21437/Interspeech.2019-1253", 5], ["Direct F0 Estimation with Neural-Network-Based Regression.", ["Shuzhuang Xu", "Hiroshi Shimodaira"], "https://doi.org/10.21437/Interspeech.2019-3267", 5], ["Real Time Online Visual End Point Detection Using Unidirectional LSTM.", ["Tanay Sharma", "Rohith Chandrashekar Aralikatti", "Dilip Kumar Margam", "Abhinav Thanda", "Sharad Roy", "Pujitha Appan Kandala", "Shankar M. Venkatesan"], "https://doi.org/10.21437/Interspeech.2019-3253", 5], ["Fully-Convolutional Network for Pitch Estimation of Speech Signals.", ["Luc Ardaillon", "Axel Roebel"], "https://doi.org/10.21437/Interspeech.2019-2815", 5], ["Vocal Pitch Extraction in Polyphonic Music Using Convolutional Residual Network.", ["Mingye Dong", "Jie Wu", "Jian Luan"], "https://doi.org/10.21437/Interspeech.2019-2286", 5], ["Multi-Level Adaptive Speech Activity Detector for Speech in Naturalistic Environments.", ["Bidisha Sharma", "Rohan Kumar Das", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1928", 5], ["On the Importance of Audio-Source Separation for Singer Identification in Polyphonic Music.", ["Bidisha Sharma", "Rohan Kumar Das", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1925", 5], ["Investigating the Physiological and Acoustic Contrasts Between Choral and Operatic Singing.", ["Hiroko Terasawa", "Kenta Wakasa", "Hideki Kawahara", "Ken-Ichi Sakakibara"], "https://doi.org/10.21437/Interspeech.2019-1864", 5], ["Optimizing Voice Activity Detection for Noisy Conditions.", ["Ruixi Lin", "Charles Costello", "Charles Jankowski", "Vishwas Mruthyunjaya"], "https://doi.org/10.21437/Interspeech.2019-1776", 5], ["Small-Footprint Magic Word Detection Method Using Convolutional LSTM Neural Network.", ["Taiki Yamamoto", "Ryota Nishimura", "Masayuki Misaki", "Norihide Kitaoka"], "https://doi.org/10.21437/Interspeech.2019-1662", 5], ["Acoustic Modeling for Automatic Lyrics-to-Audio Alignment.", ["Chitralekha Gupta", "Emre Yilmaz", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1520", 5], ["Two-Dimensional Convolutional Recurrent Neural Networks for Speech Activity Detection.", ["Anastasios Vafeiadis", "Eleftherios Fanioudakis", "Ilyas Potamitis", "Konstantinos Votis", "Dimitrios Giakoumis", "Dimitrios Tzovaras", "Liming Chen", "Raouf Hamzaoui"], "https://doi.org/10.21437/Interspeech.2019-1354", 5], ["A Study of Soprano Singing in Light of the Source-Filter Interaction.", ["Tokihiko Kaburagi"], "https://doi.org/10.21437/Interspeech.2019-1153", 5], ["Boosting Character-Based Chinese Speech Synthesis via Multi-Task Learning and Dictionary Tutoring.", ["Yuxiang Zou", "Linhao Dong", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2019-3233", 5], ["Building a Mixed-Lingual Neural TTS System with Only Monolingual Data.", ["Liumeng Xue", "Wei Song", "Guanghui Xu", "Lei Xie", "Zhizheng Wu"], "https://doi.org/10.21437/Interspeech.2019-3191", 5], ["Neural Machine Translation for Multilingual Grapheme-to-Phoneme Conversion.", ["Alex Sokolov", "Tracy Rohlin", "Ariya Rastrow"], "https://doi.org/10.21437/Interspeech.2019-3176", 5], ["Analysis of Pronunciation Learning in End-to-End Speech Synthesis.", ["Jason Taylor", "Korin Richmond"], "https://doi.org/10.21437/Interspeech.2019-2830", 5], ["End-to-End Text-to-Speech for Low-Resource Languages by Cross-Lingual Transfer Learning.", ["Yuan-Jui Chen", "Tao Tu", "Cheng-chieh Yeh", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2019-2730", 5], ["Learning to Speak Fluently in a Foreign Language: Multilingual Speech Synthesis and Cross-Language Voice Cloning.", ["Yu Zhang", "Ron J. Weiss", "Heiga Zen", "Yonghui Wu", "Zhifeng Chen", "R. J. Skerry-Ryan", "Ye Jia", "Andrew Rosenberg", "Bhuvana Ramabhadran"], "https://doi.org/10.21437/Interspeech.2019-2668", 5], ["Unified Language-Independent DNN-Based G2P Converter.", ["Marketa Juzova", "Daniel Tihelka", "Jakub Vit"], "https://doi.org/10.21437/Interspeech.2019-2335", 5], ["Disambiguation of Chinese Polyphones in an End-to-End Framework with Semantic Features Extracted by Pre-Trained BERT.", ["Dongyang Dai", "Zhiyong Wu", "Shiyin Kang", "Xixin Wu", "Jia Jia", "Dan Su", "Dong Yu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2292", 5], ["Transformer Based Grapheme-to-Phoneme Conversion.", ["Sevinj Yolchuyeva", "Geza Nemeth", "Balint Gyires-Toth"], "https://doi.org/10.21437/Interspeech.2019-1954", 5], ["Developing Pronunciation Models in New Languages Faster by Exploiting Common Grapheme-to-Phoneme Correspondences Across Languages.", ["Harry Bleyan", "Sandy Ritchie", "Jonas Fromseier Mortensen", "Daan van Esch"], "https://doi.org/10.21437/Interspeech.2019-1781", 5], ["Cross-Lingual, Multi-Speaker Text-To-Speech Synthesis Using Neural Speaker Embedding.", ["Mengnan Chen", "Minchuan Chen", "Shuang Liang", "Jun Ma", "Lei Chen", "Shaojun Wang", "Jing Xiao"], "https://doi.org/10.21437/Interspeech.2019-1632", 5], ["Polyphone Disambiguation for Mandarin Chinese Using Conditional Neural Network with Multi-Level Embedding Features.", ["Zexin Cai", "Yaogen Yang", "Chuxiong Zhang", "Xiaoyi Qin", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1235", 5], ["Token-Level Ensemble Distillation for Grapheme-to-Phoneme Conversion.", ["Hao Sun", "Xu Tan", "Jun-Wei Gan", "Hongzhi Liu", "Sheng Zhao", "Tao Qin", "Tie-Yan Liu"], "https://doi.org/10.21437/Interspeech.2019-1208", 5], ["Multilingual Speech Recognition with Corpus Relatedness Sampling.", ["Xinjian Li", "Siddharth Dalmia", "Alan W. Black", "Florian Metze"], "https://doi.org/10.21437/Interspeech.2019-3052", 5], ["Multi-Dialect Acoustic Modeling Using Phone Mapping and Online i-Vectors.", ["Harish Arsikere", "Ashtosh Sapru", "Sri Garimella"], "https://doi.org/10.21437/Interspeech.2019-2881", 5], ["Large-Scale Multilingual Speech Recognition with a Streaming End-to-End Model.", ["Anjuli Kannan", "Arindrima Datta", "Tara N. Sainath", "Eugene Weinstein", "Bhuvana Ramabhadran", "Yonghui Wu", "Ankur Bapna", "Zhifeng Chen", "Seungji Lee"], "https://doi.org/10.21437/Interspeech.2019-2858", 5], ["Recognition of Latin American Spanish Using Multi-Task Learning.", ["Carlos Mendes", "Alberto Abad", "Joao Paulo Neto", "Isabel Trancoso"], "https://doi.org/10.21437/Interspeech.2019-2772", 5], ["End-to-End Accented Speech Recognition.", ["Thibault Viglino", "Petr Motlicek", "Milos Cernak"], "https://doi.org/10.21437/Interspeech.2019-2122", 5], ["End-to-End Articulatory Attribute Modeling for Low-Resource Multilingual Speech Recognition.", ["Sheng Li", "Chenchen Ding", "Xugang Lu", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2092", 5], ["Exploiting Monolingual Speech Corpora for Code-Mixed Speech Recognition.", ["Karan Taneja", "Satarupa Guha", "Preethi Jyothi", "Basil Abraham"], "https://doi.org/10.21437/Interspeech.2019-1959", 5], ["Phoneme-Based Contextualization for Cross-Lingual Speech Recognition in End-to-End Models.", ["Ke Hu", "Antoine Bruguier", "Tara N. Sainath", "Rohit Prabhavalkar", "Golan Pundak"], "https://doi.org/10.21437/Interspeech.2019-1868", 5], ["Constrained Output Embeddings for End-to-End Code-Switching Speech Recognition with Only Monolingual Data.", ["Yerbolat Khassanov", "Haihua Xu", "Van Tung Pham", "Zhiping Zeng", "Eng Siong Chng", "Chongjia Ni", "Bin Ma"], "https://doi.org/10.21437/Interspeech.2019-1867", 5], ["On the End-to-End Solution to Mandarin-English Code-Switching Speech Recognition.", ["Zhiping Zeng", "Yerbolat Khassanov", "Van Tung Pham", "Haihua Xu", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1429", 5], ["Towards Language-Universal Mandarin-English Speech Recognition.", ["Shiliang Zhang", "Yuan Liu", "Ming Lei", "Bin Ma", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2019-1365", 5], ["Improving ASR Confidence Scores for Alexa Using Acoustic and Hypothesis Embeddings.", ["Prakhar Swarup", "Roland Maas", "Sri Garimella", "Sri Harish Mallidi", "Bjorn Hoffmeister"], "https://doi.org/10.21437/Interspeech.2019-1241", 5], ["Investigation of Transformer Based Spelling Correction Model for CTC-Based End-to-End Mandarin Speech Recognition.", ["Shiliang Zhang", "Ming Lei", "Zhijie Yan"], "https://doi.org/10.21437/Interspeech.2019-1290", 5], ["Improving Performance of End-to-End ASR on Numeric Sequences.", ["Cal Peyser", "Hao Zhang", "Tara N. Sainath", "Zelin Wu"], "https://doi.org/10.21437/Interspeech.2019-1345", 5], ["A Time Delay Neural Network with Shared Weight Self-Attention for Small-Footprint Keyword Spotting.", ["Ye Bai", "Jiangyan Yi", "Jianhua Tao", "Zhengqi Wen", "Zhengkun Tian", "Chenghao Zhao", "Cunhang Fan"], "https://doi.org/10.21437/Interspeech.2019-1676", 5], ["Sub-Band Convolutional Neural Networks for Small-Footprint Spoken Term Classification.", ["Chieh-Chi Kao", "Ming Sun", "Yixin Gao", "Shiv Vitaladevuni", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2019-1766", 5], ["Investigating Radical-Based End-to-End Speech Recognition Systems for Chinese Dialects and Japanese.", ["Sheng Li", "Xugang Lu", "Chenchen Ding", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2104", 5], ["Joint Decoding of CTC Based Systems for Speech Recognition.", ["Jiaqi Guo", "Yongbin You", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2019-2026", 5], ["A Joint End-to-End and DNN-HMM Hybrid Automatic Speech Recognition System with Transferring Sharable Knowledge.", ["Tomohiro Tanaka", "Ryo Masumura", "Takafumi Moriya", "Takanobu Oba", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-2263", 5], ["Active Learning Methods for Low Resource End-to-End Speech Recognition.", ["Karan Malhotra", "Shubham Bansal", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2019-2316", 5], ["Analysis of Multilingual Sequence-to-Sequence Speech Recognition Systems.", ["Martin Karafiat", "Murali Karthick Baskar", "Shinji Watanabe", "Takaaki Hori", "Matthew Wiesner", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-2355", 5], ["Lattice Generation in Attention-Based Speech Recognition Models.", ["Michal Zapotoczny", "Piotr Pietrzak", "Adrian Lancucki", "Jan Chorowski"], "https://doi.org/10.21437/Interspeech.2019-2667", 5], ["Sampling from Stochastic Finite Automata with Applications to CTC Decoding.", ["Martin Jansche", "Alexander Gutkin"], "https://doi.org/10.21437/Interspeech.2019-2740", 5], ["ShrinkML: End-to-End ASR Model Compression Using Reinforcement Learning.", ["Lukasz Dudziak", "Mohamed S. Abdelfattah", "Ravichander Vipperla", "Stefanos Laskaridis", "Nicholas D. Lane"], "https://doi.org/10.21437/Interspeech.2019-2811", 5], ["Acoustic-to-Phrase Models for Speech Recognition.", ["Yashesh Gaur", "Jinyu Li", "Zhong Meng", "Yifan Gong"], "https://doi.org/10.21437/Interspeech.2019-3056", 5], ["Performance Monitoring for End-to-End Speech Recognition.", ["Ruizhi Li", "Gregory Sell", "Hynek Hermansky"], "https://doi.org/10.21437/Interspeech.2019-3137", 5], ["The Role of Musical Experience in the Perceptual Weighting of Acoustic Cues for the Obstruent Coda Voicing Contrast in American English.", ["Michelle Cohn", "Georgia Zellou", "Santiago Barreda"], "https://doi.org/10.21437/Interspeech.2019-3103", 5], ["Individual Differences in Implicit Attention to Phonetic Detail in Speech Perception.", ["Natalie Lewandowski", "Daniel Duran"], "https://doi.org/10.21437/Interspeech.2019-2989", 5], ["Effects of Natural Variability in Cross-Modal Temporal Correlations on Audiovisual Speech Recognition Benefit.", ["Kaylah Lalonde"], "https://doi.org/10.21437/Interspeech.2019-2931", 5], ["Listening with Great Expectations: An Investigation of Word Form Anticipations in Naturalistic Speech.", ["M. Bentum", "Louis ten Bosch", "Antal van den Bosch", "Mirjam Ernestus"], "https://doi.org/10.21437/Interspeech.2019-2741", 5], ["Quantifying Expectation Modulation in Human Speech Processing.", ["M. Bentum", "Louis ten Bosch", "Antal van den Bosch", "Mirjam Ernestus"], "https://doi.org/10.21437/Interspeech.2019-2685", 5], ["Perception of Pitch Contours in Speech and Nonspeech.", ["Daniel R. Turner", "Ann R. Bradlow", "Jennifer S. Cole"], "https://doi.org/10.21437/Interspeech.2019-2619", 5], ["Analyzing Reaction Time and Error Sequences in Lexical Decision Experiments.", ["Louis ten Bosch", "Lou Boves", "Kimberley Mulder"], "https://doi.org/10.21437/Interspeech.2019-2611", 5], ["Automatic Detection of the Temporal Segmentation of Hand Movements in British English Cued Speech.", ["Li Liu", "Jianze Li", "Gang Feng", "Xiao-Ping Steven Zhang"], "https://doi.org/10.21437/Interspeech.2019-2353", 5], ["Place Shift as an Autonomous Process: Evidence from Japanese Listeners.", ["Yuriko Yokoe"], "https://doi.org/10.21437/Interspeech.2019-2302", 5], ["A Perceptual Study of CV Syllables in Both Spoken and Whistled Speech: A Tashlhiyt Berber Perspective.", ["Julien Meyer", "Laure Dentel", "Silvain Gerber", "Rachid Ridouane"], "https://doi.org/10.21437/Interspeech.2019-2251", 5], ["Consonant Classification in Mandarin Based on the Depth Image Feature: A Pilot Study.", ["Han-Chi Hsieh", "Wei-Zhong Zheng", "Ko-Chiang Chen", "Ying-Hui Lai"], "https://doi.org/10.21437/Interspeech.2019-1893", 5], ["The Different Roles of Expectations in Phonetic and Lexical Processing.", ["Shiri Lev-Ari", "Robin Dodsworth", "Jeff Mielke", "Sharon Peperkamp"], "https://doi.org/10.21437/Interspeech.2019-1795", 5], ["Perceptual Adaptation to Device and Human Voices: Learning and Generalization of a Phonetic Shift Across Real and Voice-AI Talkers.", ["Bruno Ferenc Segedin", "Michelle Cohn", "Georgia Zellou"], "https://doi.org/10.21437/Interspeech.2019-1433", 5], ["End-to-End Convolutional Sequence Learning for ASL Fingerspelling Recognition.", ["Katerina Papadimitriou", "Gerasimos Potamianos"], "https://doi.org/10.21437/Interspeech.2019-2422", 5], ["Multiview Shared Subspace Learning Across Speakers and Speech Commands.", ["Krishna Somandepalli", "Naveen Kumar", "Arindam Jati", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-3130", 5], ["A Machine Learning Based Clustering Protocol for Determining Hearing Aid Initial Configurations from Pure-Tone Audiograms.", ["Chelzy Belitz", "Hussnain Ali", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-3091", 5], ["Acoustic Scene Classification with Mismatched Devices Using CliqueNets and Mixup Data Augmentation.", ["Truc Nguyen", "Franz Pernkopf"], "https://doi.org/10.21437/Interspeech.2019-3002", 5], ["DeepLung: Smartphone Convolutional Neural Network-Based Inference of Lung Anomalies for Pulmonary Patients.", ["Mohsin Y. Ahmed", "Md. Mahbubur Rahman", "Jilong Kuang"], "https://doi.org/10.21437/Interspeech.2019-2953", 5], ["On the Use/Misuse of the Term 'Phoneme'.", ["Roger K. Moore", "Lucy Skidmore"], "https://doi.org/10.21437/Interspeech.2019-2711", 5], ["Understanding and Visualizing Raw Waveform-Based CNNs.", ["Hannah Muckenhirn", "Vinayak Abrol", "Mathew Magimai-Doss", "Sebastien Marcel"], "https://doi.org/10.21437/Interspeech.2019-2341", 5], ["Fr\u00e9chet Audio Distance: A Reference-Free Metric for Evaluating Music Enhancement Algorithms.", ["Kevin Kilgour", "Mauricio Zuluaga", "Dominik Roblek", "Matthew Sharifi"], "https://doi.org/10.21437/Interspeech.2019-2219", 5], ["ReMASC: Realistic Replay Attack Corpus for Voice Controlled Systems.", ["Yuan Gong", "Jian Yang", "Jacob Huber", "Mitchell MacKnight", "Christian Poellabauer"], "https://doi.org/10.21437/Interspeech.2019-1541", 5], ["Analyzing Intra-Speaker and Inter-Speaker Vocal Tract Impedance Characteristics in a Low-Dimensional Feature Space Using t-SNE.", ["Balamurali B. T.", "Jer-Ming Chen"], "https://doi.org/10.21437/Interspeech.2019-1492", 4], ["Directional Audio Rendering Using a Neural Network Based Personalized HRTF.", ["Geon Woo Lee", "Jung Hyuk Lee", "Seong Ju Kim", "Hong Kook Kim"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8005.html", 2], ["Online Speech Processing and Analysis Suite.", ["Wikus Pienaar", "Daan Wissing"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8007.html", 2], ["Formant Pattern and Spectral Shape Ambiguity of Vowel Sounds, and Related Phenomena of Vowel Acoustics - Exemplary Evidence.", ["Dieter Maurer", "Heidy Suter", "Christian dHereuse", "Volker Dellwo"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8017.html", 2], ["Sound Tools eXtended (STx) 5.0 - A Powerful Sound Analysis Tool Optimized for Speech.", ["Anton Noll", "Jonathan Stuefer", "Nicola Klingler", "Hannah Leykum", "Carina Lozo", "Jan Luttenberger", "Michael Pucher", "Carolin Schmid"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8022.html", 2], ["FarSpeech: Arabic Natural Language Processing for Live Arabic Speech.", ["Mohamed Eldesouki", "Naassih Gopee", "Ahmed Ali", "Kareem Darwish"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8030.html", 2], ["A System for Real-Time Privacy Preserving Data Collection for Ambient Assisted Living.", ["Fasih Haider", "Saturnino Luz"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8037.html", 2], ["NUS Speak-to-Sing: A Web Platform for Personalized Speech-to-Singing Conversion.", ["Chitralekha Gupta", "Karthika Vijayan", "Bidisha Sharma", "Xiaoxue Gao", "Haizhou Li"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8041.html", 2], ["Physiology and Physics of Voice Production.", ["Manfred Kaltenbacher"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs12.html", 0], ["The INTERSPEECH 2019 Computational Paralinguistics Challenge: Styrian Dialects, Continuous Sleepiness, Baby Sounds & Orca Activity.", ["Bjorn W. Schuller", "Anton Batliner", "Christian Bergler", "Florian B. Pokorny", "Jarek Krajewski", "Margaret Cychosz", "Ralf Vollmann", "Sonja-Dana Roelen", "Sebastian Schnieder", "Elika Bergelson", "Alejandrina Cristia", "Amanda Seidl", "Anne S. Warlaumont", "Lisa Yankowitz", "Elmar Noth", "Shahin Amiriparian", "Simone Hantke", "Maximilian Schmitt"], "https://doi.org/10.21437/Interspeech.2019-1122", 5], ["Using Speech Production Knowledge for Raw Waveform Modelling Based Styrian Dialect Identification.", ["S. Pavankumar Dubagunta", "Mathew Magimai-Doss"], "https://doi.org/10.21437/Interspeech.2019-2398", 5], ["Deep Neural Baselines for Computational Paralinguistics.", ["Daniel Elsner", "Stefan Langer", "Fabian Ritz", "Robert Muller", "Steffen Illium"], "https://doi.org/10.21437/Interspeech.2019-2478", 5], ["Styrian Dialect Classification: Comparing and Fusing Classifiers Based on a Feature Selection Using a Genetic Algorithm.", ["Thomas Kisler", "Raphael Winkelmann", "Florian Schiel"], "https://doi.org/10.21437/Interspeech.2019-2540", 5], ["Using Attention Networks and Adversarial Augmentation for Styrian Dialect Continuous Sleepiness and Baby Sound Recognition.", ["Sung-Lin Yeh", "Gao-Yi Chao", "Bo-Hao Su", "Yu-Lin Huang", "Meng-Han Lin", "Yin-Chun Tsai", "Yu-Wen Tai", "Zheng-Chi Lu", "Chieh-Yu Chen", "Tsung-Ming Tai", "Chiu-Wang Tseng", "Cheng-Kuang Lee", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2110", 5], ["Ordinal Triplet Loss: Investigating Sleepiness Detection from Speech.", ["Peter Wu", "Sai Krishna Rallabandi", "Alan W. Black", "Eric Nyberg"], "https://doi.org/10.21437/Interspeech.2019-2278", 5], ["Voice Quality and Between-Frame Entropy for Sleepiness Estimation.", ["Vijay Ravi", "Soo Jin Park", "Amber Afshan", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2019-2988", 5], ["Using Fisher Vector and Bag-of-Audio-Words Representations to Identify Styrian Dialects, Sleepiness, Baby & Orca Sounds.", ["Gabor Gosztolya"], "https://doi.org/10.21437/Interspeech.2019-1726", 5], ["Instantaneous Phase and Long-Term Acoustic Cues for Orca Activity Detection.", ["Rohan Kumar Das", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1894", 5], ["Relevance-Based Feature Masking: Improving Neural Network Based Whale Classification Through Explainable Artificial Intelligence.", ["Dominik Schiller", "Tobias Huber", "Florian Lingenfelser", "Michael Dietz", "Andreas Seiderer", "Elisabeth Andre"], "https://doi.org/10.21437/Interspeech.2019-2707", 5], ["Spatial, Temporal and Spectral Multiresolution Analysis for the INTERSPEECH 2019 ComParE Challenge.", ["Marie-Jose Caraty", "Claude Montacie"], "https://doi.org/10.21437/Interspeech.2019-1693", 5], ["The DKU-LENOVO Systems for the INTERSPEECH 2019 Computational Paralinguistic Challenge.", ["Haiwei Wu", "Weiqing Wang", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1386", 5], ["The VOiCES from a Distance Challenge 2019.", ["Mahesh Kumar Nandwana", "Julien van Hout", "Colleen Richey", "Mitchell McLaren", "Maria Auxiliadora Barrios", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2019-1837", 5], ["STC Speaker Recognition Systems for the VOiCES from a Distance Challenge.", ["Sergey Novoselov", "Aleksei Gusev", "Artem Ivanov", "Timur Pekhovsky", "Andrey Shulipa", "Galina Lavrentyeva", "Vladimir Volokhov", "Alexandr Kozlov"], "https://doi.org/10.21437/Interspeech.2019-2783", 5], ["Analysis of BUT Submission in Far-Field Scenarios of VOiCES 2019 Challenge.", ["Pavel Matejka", "Oldrich Plchot", "Hossein Zeinali", "Ladislav Mosner", "Anna Silnova", "Lukas Burget", "Ondrej Novotny", "Ondrej Glembek"], "https://doi.org/10.21437/Interspeech.2019-2471", 5], ["The STC ASR System for the VOiCES from a Distance Challenge 2019.", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Ivan Sorokin", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Tatiana Prisyach", "Mariya Korenevskaya", "Oleg Petrov", "Alexander Zatvornitskiy"], "https://doi.org/10.21437/Interspeech.2019-1574", 5], ["The I2R's ASR System for the VOiCES from a Distance Challenge 2019.", ["Tze Yuang Chong", "Kye Min Tan", "Kah Kuan Teh", "Chang Huai You", "Hanwu Sun", "Tran Huy Dat"], "https://doi.org/10.21437/Interspeech.2019-2130", 5], ["The VOiCES from a Distance Challenge 2019.", ["Mahesh Kumar Nandwana", "Julien van Hout", "Colleen Richey", "Mitchell McLaren", "Maria Alejandra Barrios", "Aaron Lawson"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs14.html", 0], ["STC Speaker Recognition Systems for the VOiCES from a Distance Challenge.", ["Sergey Novoselov", "Aleksei Gusev", "Artem Ivanov", "Timur Pekhovsky", "Andrey Shulipa", "Galina Lavrentyeva", "Vladimir Volokhov", "Alexandr Kozlov"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs15.html", 0], ["Analysis of BUT Submission in Far-Field Scenarios of VOiCES 2019 Challenge.", ["Pavel Matejka", "Oldrich Plchot", "Hossein Zeinali", "Ladislav Mosner", "Anna Silnova", "Lukas Burget", "Ondrej Novotny", "Ondrej Glembek"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs16.html", 0], ["The STC ASR System for the VOiCES from a Distance Challenge 2019.", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Ivan Sorokin", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Tatiana Prisyach", "Mariya Korenevskaya", "Oleg Petrov", "Alexander Zatvornitskiy"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs17.html", 0], ["The I2R's ASR System for the VOiCES from a Distance Challenge 2019.", ["Tze Yuang Chong", "Kye Min Tan", "Kah Kuan Teh", "Chang Huai You", "Hanwu Sun", "Tran Huy Dat"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs18.html", 0], ["Multi-Task Discriminative Training of Hybrid DNN-TVM Model for Speaker Verification with Noisy and Far-Field Speech.", ["Arindam Jati", "Raghuveer Peri", "Monisankha Pal", "Tae Jin Park", "Naveen Kumar", "Ruchir Travadi", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-3010", 5], ["The JHU Speaker Recognition System for the VOiCES 2019 Challenge.", ["David Snyder", "Jesus Villalba", "Nanxin Chen", "Daniel Povey", "Gregory Sell", "Najim Dehak", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2979", 5], ["Intel Far-Field Speaker Recognition System for VOiCES Challenge 2019.", ["Jonathan Huang", "Tobias Bocklet"], "https://doi.org/10.21437/Interspeech.2019-2894", 5], ["The I2R's Submission to VOiCES Distance Speaker Recognition Challenge 2019.", ["Hanwu Sun", "Kah Kuan Teh", "Ivan Kukanov", "Tran Huy Dat"], "https://doi.org/10.21437/Interspeech.2019-1997", 5], ["The LeVoice Far-Field Speech Recognition System for VOiCES from a Distance Challenge 2019.", ["Yulong Liang", "Lin Yang", "Xuyang Wang", "Yingjie Li", "Chen Jia", "Junjie Wang"], "https://doi.org/10.21437/Interspeech.2019-1944", 5], ["The JHU ASR System for VOiCES from a Distance Challenge 2019.", ["Yiming Wang", "David Snyder", "Hainan Xu", "Vimal Manohar", "Phani Sankar Nidadavolu", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-1948", 5], ["The DKU System for the Speaker Recognition Task of the 2019 VOiCES from a Distance Challenge.", ["Danwei Cai", "Xiaoyi Qin", "Weicheng Cai", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1435", 5], ["Identifying Distinctive Acoustic and Spectral Features in Parkinson's Disease.", ["Yermiyahu Hauptman", "Ruth Aloni-Lavi", "Itshak Lapidot", "Tanya Gurevich", "Yael Manor", "Stav Naor", "Noa Diamant", "Irit Opher"], "https://doi.org/10.21437/Interspeech.2019-2465", 5], ["Aerodynamics and Lumped-Masses Combined with Delay Lines for Modeling Vertical and Anterior-Posterior Phase Differences in Pathological Vocal Fold Vibration.", ["Carlo Drioli", "Philipp Aichinger"], "https://doi.org/10.21437/Interspeech.2019-2338", 5], ["Mel-Frequency Cepstral Coefficients of Voice Source Waveforms for Classification of Phonation Types in Speech.", ["Sudarsana Reddy Kadiri", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2019-2863", 5], ["Automatic Detection of Autism Spectrum Disorder in Children Using Acoustic and Text Features from Brief Natural Conversations.", ["Sunghye Cho", "Mark Liberman", "Neville Ryant", "Meredith Cola", "Robert T. Schultz", "Julia Parish-Morris"], "https://doi.org/10.21437/Interspeech.2019-1452", 5], ["Analysis and Synthesis of Vocal Flutter and Vocal Jitter.", ["Jean Schoentgen", "Philipp Aichinger"], "https://doi.org/10.21437/Interspeech.2019-1998", 5], ["Reliability of Clinical Voice Parameters Captured with Smartphones - Measurements of Added Noise and Spectral Tilt.", ["Felix Schaeffler", "Stephen Jannetts", "Janet Beck"], "https://doi.org/10.21437/Interspeech.2019-2910", 5], ["Say What? A Dataset for Exploring the Error Patterns That Two ASR Engines Make.", ["Meredith Moore", "Michael Saxon", "Hemanth Venkateswara", "Visar Berisha", "Sethuraman Panchanathan"], "https://doi.org/10.21437/Interspeech.2019-3096", 5], ["Survey Talk: Prosody Research and Applications: The State of the Art.", ["Nigel G. Ward"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs20.html", 0], ["Dimensions of Prosodic Prominence in an Attractor Model.", ["Simon Roessig", "Doris Mucke", "Lena Pagel"], "https://doi.org/10.21437/Interspeech.2019-2227", 5], ["Comparative Analysis of Prosodic Characteristics Using WaveNet Embeddings.", ["Antti Suni", "Marcin Wlodarczak", "Martti Vainio", "Juraj Simko"], "https://doi.org/10.21437/Interspeech.2019-2373", 5], ["The Role of Voice Quality in the Perception of Prominence in Synthetic Speech.", ["Andy Murphy", "Irena Yanushevskaya", "Ailbhe Ni Chasaide", "Christer Gobl"], "https://doi.org/10.21437/Interspeech.2019-2761", 5], ["Phonological Awareness of French Rising Contours in Japanese Learners.", ["Rachel Albar", "Hiyon Yoo"], "https://doi.org/10.21437/Interspeech.2019-2856", 5], ["Audio Classification of Bit-Representation Waveform.", ["Masaki Okawa", "Takuya Saito", "Naoki Sawada", "Hiromitsu Nishizaki"], "https://doi.org/10.21437/Interspeech.2019-1855", 5], ["Locality-Constrained Linear Coding Based Fused Visual Features for Robust Acoustic Event Classification.", ["Manjunath Mulimani", "Shashidhar G. Koolagudi"], "https://doi.org/10.21437/Interspeech.2019-1421", 5], ["Learning How to Listen: A Temporal-Frequential Attention Model for Sound Event Detection.", ["Yu-Han Shen", "Ke-Xin He", "Wei-Qiang Zhang"], "https://doi.org/10.21437/Interspeech.2019-2045", 5], ["A Deep Residual Network for Large-Scale Acoustic Scene Analysis.", ["Logan Ford", "Hao Tang", "Francois Grondin", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-2731", 5], ["Supervised Classifiers for Audio Impairments with Noisy Labels.", ["Chandan K. A. Reddy", "Ross Cutler", "Johannes Gehrke"], "https://doi.org/10.21437/Interspeech.2019-3074", 5], ["Self-Attention for Speech Emotion Recognition.", ["Lorenzo Tarantino", "Philip N. Garner", "Alexandros Lazaridis"], "https://doi.org/10.21437/Interspeech.2019-2822", 5], ["Unsupervised Singing Voice Conversion.", ["Eliya Nachmani", "Lior Wolf"], "https://doi.org/10.21437/Interspeech.2019-1761", 5], ["Adversarially Trained End-to-End Korean Singing Voice Synthesis System.", ["Juheon Lee", "Hyeong-Seok Choi", "Chang-Bin Jeon", "Junghyun Koo", "Kyogu Lee"], "https://doi.org/10.21437/Interspeech.2019-1722", 5], ["Singing Voice Synthesis Using Deep Autoregressive Neural Networks for Acoustic Modeling.", ["Yuan-Hao Yi", "Yang Ai", "Zhen-Hua Ling", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2019-1563", 5], ["Conditional Variational Auto-Encoder for Text-Driven Expressive AudioVisual Speech Synthesis.", ["Sara Dahmani", "Vincent Colotte", "Valerian Girard", "Slim Ouni"], "https://doi.org/10.21437/Interspeech.2019-2848", 5], ["A Strategy for Improved Phone-Level Lyrics-to-Audio Alignment for Speech-to-Singing Synthesis.", ["David Ayllon", "Fernando Villavicencio", "Pierre Lanchantin"], "https://doi.org/10.21437/Interspeech.2019-3049", 5], ["Modeling Labial Coarticulation with Bidirectional Gated Recurrent Networks and Transfer Learning.", ["Theo Biasutto-Lervat", "Sara Dahmani", "Slim Ouni"], "https://doi.org/10.21437/Interspeech.2019-2097", 5], ["SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition.", ["Daniel S. Park", "William Chan", "Yu Zhang", "Chung-Cheng Chiu", "Barret Zoph", "Ekin D. Cubuk", "Quoc V. Le"], "https://doi.org/10.21437/Interspeech.2019-2680", 5], ["Forget a Bit to Learn Better: Soft Forgetting for CTC-Based Automatic Speech Recognition.", ["Kartik Audhkhasi", "George Saon", "Zoltan Tuske", "Brian Kingsbury", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2841", 5], ["Online Hybrid CTC/Attention Architecture for End-to-End Speech Recognition.", ["Haoran Miao", "Gaofeng Cheng", "Pengyuan Zhang", "Ta Li", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-2018", 5], ["A Highly Efficient Distributed Deep Learning System for Automatic Speech Recognition.", ["Wei Zhang", "Xiaodong Cui", "Ulrich Finkler", "George Saon", "Abdullah Kayi", "Alper Buyuktosunoglu", "Brian Kingsbury", "David S. Kung", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2700", 5], ["Knowledge Distillation for End-to-End Monaural Multi-Talker ASR System.", ["Wangyou Zhang", "Xuankai Chang", "Yanmin Qian"], "https://doi.org/10.21437/Interspeech.2019-3192", 5], ["Analysis of Deep Clustering as Preprocessing for Automatic Speech Recognition of Sparsely Overlapping Speech.", ["Tobias Menne", "Ilya Sklyar", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-1728", 5], ["Survey Talk: Recognition of Foreign-Accented Speech: Challenges and Opportunities for Human and Computer Speech Communication.", ["Ann R. Bradlow"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs21.html", 0], ["The Effects of Time Expansion on English as a Second Language Individuals.", ["John S. Novak III", "Daniel Bunn", "Robert V. Kenyon"], "https://doi.org/10.21437/Interspeech.2019-2763", 5], ["Capturing L1 Influence on L2 Pronunciation by Simulating Perceptual Space Using Acoustic Features.", ["Shuju Shi", "Chilin Shih", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2019-3183", 5], ["Cognitive Factors in Thai-Na\u00efve Mandarin Speakers' Imitation of Thai Lexical Tones.", ["Juqiang Chen", "Catherine T. Best", "Mark Antoniou"], "https://doi.org/10.21437/Interspeech.2019-1403", 5], ["Foreign-Language Knowledge Enhances Artificial-Language Segmentation.", ["Annie Tremblay", "Mirjam Broersma"], "https://doi.org/10.21437/Interspeech.2019-2446", 5], ["Neural Named Entity Recognition from Subword Units.", ["Abdalghani Abujabal", "Judith Gaspers"], "https://doi.org/10.21437/Interspeech.2019-1305", 5], ["Unsupervised Acoustic Segmentation and Clustering Using Siamese Network Embeddings.", ["Saurabhchand Bhati", "Shekhar Nayak", "K. Sri Rama Murty", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2981", 5], ["An Empirical Evaluation of DTW Subsampling Methods for Keyword Search.", ["Bolaji Yusuf", "Murat Saraclar"], "https://doi.org/10.21437/Interspeech.2019-2413", 5], ["Linguistically-Informed Training of Acoustic Word Embeddings for Low-Resource Languages.", ["Zixiaofan Yang", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2019-3119", 5], ["Multimodal Word Discovery and Retrieval with Phone Sequence and Image Concepts.", ["Liming Wang", "Mark A. Hasegawa-Johnson"], "https://doi.org/10.21437/Interspeech.2019-1487", 5], ["Empirical Evaluation of Sequence-to-Sequence Models for Word Discovery in Low-Resource Settings.", ["Marcely Zanon Boito", "Aline Villavicencio", "Laurent Besacier"], "https://doi.org/10.21437/Interspeech.2019-2029", 5], ["Direct-Path Signal Cross-Correlation Estimation for Sound Source Localization in Reverberation.", ["Wei Xue", "Ying Tong", "Guohong Ding", "Chao Zhang", "Tao Ma", "Xiaodong He", "Bowen Zhou"], "https://doi.org/10.21437/Interspeech.2019-1488", 5], ["Multiple Sound Source Localization with SVD-PHAT.", ["Francois Grondin", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-2653", 5], ["Robust DOA Estimation Based on Convolutional Neural Network and Time-Frequency Masking.", ["Wangyou Zhang", "Ying Zhou", "Yanmin Qian"], "https://doi.org/10.21437/Interspeech.2019-3158", 5], ["Multichannel Loss Function for Supervised Speech Source Separation by Mask-Based Beamforming.", ["Yoshiki Masuyama", "Masahito Togami", "Tatsuya Komatsu"], "https://doi.org/10.21437/Interspeech.2019-1289", 5], ["Direction-Aware Speaker Beam for Multi-Channel Speaker Extraction.", ["Guanjun Li", "Shan Liang", "Shuai Nie", "Wenju Liu", "Meng Yu", "Lianwu Chen", "Shouye Peng", "Changliang Li"], "https://doi.org/10.21437/Interspeech.2019-1474", 5], ["Multimodal SpeakerBeam: Single Channel Target Speech Extraction with Audio-Visual Speaker Clues.", ["Tsubasa Ochiai", "Marc Delcroix", "Keisuke Kinoshita", "Atsunori Ogawa", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2019-1513", 5], ["Speech Denoising with Deep Feature Losses.", ["Francois G. Germain", "Qifeng Chen", "Vladlen Koltun"], "https://doi.org/10.21437/Interspeech.2019-1924", 5], ["VoiceFilter: Targeted Voice Separation by Speaker-Conditioned Spectrogram Masking.", ["Quan Wang", "Hannah Muckenhirn", "Kevin W. Wilson", "Prashant Sridhar", "Zelin Wu", "John R. Hershey", "Rif A. Saurous", "Ron J. Weiss", "Ye Jia", "Ignacio Lopez-Moreno"], "https://doi.org/10.21437/Interspeech.2019-1101", 5], ["Incorporating Symbolic Sequential Modeling for Speech Enhancement.", ["Chien-Feng Liao", "Yu Tsao", "Xugang Lu", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-1777", 5], ["Maximum a posteriori Speech Enhancement Based on Double Spectrum.", ["Pejman Mowlaee", "Daniel Scheran", "Johannes Stahl", "Sean U. N. Wood", "W. Bastiaan Kleijn"], "https://doi.org/10.21437/Interspeech.2019-1197", 5], ["Coarse-to-Fine Optimization for Speech Enhancement.", ["Jian Yao", "Ahmad Al-Dahle"], "https://doi.org/10.21437/Interspeech.2019-2792", 5], ["Kernel Machines Beat Deep Neural Networks on Mask-Based Single-Channel Speech Enhancement.", ["Like Hui", "Siyuan Ma", "Mikhail Belkin"], "https://doi.org/10.21437/Interspeech.2019-1344", 5], ["Survey Talk: Multimodal Processing of Speech and Language.", ["Florian Metze"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs22.html", 0], ["MobiVSR : Efficient and Light-Weight Neural Network for Visual Speech Recognition on Mobile Devices.", ["Nilay Shrivastava", "Astitwa Saxena", "Yaman Kumar", "Rajiv Ratn Shah", "Amanda Stent", "Debanjan Mahata", "Preeti Kaur", "Roger Zimmermann"], "https://doi.org/10.21437/Interspeech.2019-3273", 5], ["Speaker Adaptation for Lip-Reading Using Visual Identity Vectors.", ["Pujitha Appan Kandala", "Abhinav Thanda", "Dilip Kumar Margam", "Rohith Chandrashekar Aralikatti", "Tanay Sharma", "Sharad Roy", "Shankar M. Venkatesan"], "https://doi.org/10.21437/Interspeech.2019-3237", 5], ["MobiLipNet: Resource-Efficient Deep Learning Based Lipreading.", ["Alexandros Koumparoulis", "Gerasimos Potamianos"], "https://doi.org/10.21437/Interspeech.2019-2618", 5], ["LipSound: Neural Mel-Spectrogram Reconstruction for Lip Reading.", ["Leyuan Qu", "Cornelius Weber", "Stefan Wermter"], "https://doi.org/10.21437/Interspeech.2019-1393", 5], ["Two-Pass End-to-End Speech Recognition.", ["Tara N. Sainath", "Ruoming Pang", "David Rybach", "Yanzhang He", "Rohit Prabhavalkar", "Wei Li", "Mirko Visontai", "Qiao Liang", "Trevor Strohman", "Yonghui Wu", "Ian McGraw", "Chung-Cheng Chiu"], "https://doi.org/10.21437/Interspeech.2019-1341", 5], ["Extract, Adapt and Recognize: An End-to-End Neural Network for Corrupted Monaural Speech Recognition.", ["Max W. Y. Lam", "Jun Wang", "Xunying Liu", "Helen Meng", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-1626", 5], ["Multi-Task Multi-Resolution Char-to-BPE Cross-Attention Decoder for End-to-End Speech Recognition.", ["Dhananjaya Gowda", "Abhinav Garg", "Kwangyoun Kim", "Mehul Kumar", "Chanwoo Kim"], "https://doi.org/10.21437/Interspeech.2019-3216", 5], ["Multi-Stride Self-Attention for Speech Recognition.", ["Kyu J. Han", "Jing Huang", "Yun Tang", "Xiaodong He", "Bowen Zhou"], "https://doi.org/10.21437/Interspeech.2019-1973", 5], ["LF-MMI Training of Bayesian and Gaussian Process Time Delay Neural Networks for Speech Recognition.", ["Shoukang Hu", "Xurong Xie", "Shansong Liu", "Max W. Y. Lam", "Jianwei Yu", "Xixin Wu", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2379", 5], ["Self-Teaching Networks.", ["Liang Lu", "Eric Sun", "Yifan Gong"], "https://doi.org/10.21437/Interspeech.2019-1467", 5], ["Improved End-to-End Speech Emotion Recognition Using Self Attention Mechanism and Multitask Learning.", ["Yuanchao Li", "Tianyu Zhao", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2019-2594", 5], ["Continuous Emotion Recognition in Speech - Do We Need Recurrence?", ["Maximilian Schmitt", "Nicholas Cummins", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-2710", 5], ["Speech Based Emotion Prediction: Can a Linear Model Work?", ["Anda Ouyang", "Ting Dang", "Vidhyasaharan Sethu", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2019-3149", 5], ["Speech Emotion Recognition Based on Multi-Label Emotion Existence Model.", ["Atsushi Ando", "Ryo Masumura", "Hosana Kamiyama", "Satoshi Kobashikawa", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-2524", 5], ["Gender De-Biasing in Speech Emotion Recognition.", ["Cristina Gorrostieta", "Reza Lotfian", "Kye Taylor", "Richard Brutti", "John Kane"], "https://doi.org/10.21437/Interspeech.2019-1708", 5], ["CycleGAN-Based Emotion Style Transfer as Data Augmentation for Speech Emotion Recognition.", ["Fang Bao", "Michael Neumann", "Ngoc Thang Vu"], "https://doi.org/10.21437/Interspeech.2019-2293", 5], ["Lombard Speech Synthesis Using Transfer Learning in a Tacotron Text-to-Speech System.", ["Bajibabu Bollepalli", "Lauri Juvela", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2019-1333", 5], ["Augmented CycleGANs for Continuous Scale Normal-to-Lombard Speaking Style Conversion.", ["Shreyas Seshadri", "Lauri Juvela", "Paavo Alku", "Okko Rasanen"], "https://doi.org/10.21437/Interspeech.2019-1681", 5], ["Foreign Accent Conversion by Synthesizing Speech from Phonetic Posteriorgrams.", ["Guanlong Zhao", "Shaojin Ding", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2019-1778", 5], ["A Multi-Speaker Emotion Morphing Model Using Highway Networks and Maximum Likelihood Objective.", ["Ravi Shankar", "Jacob Sager", "Archana Venkataraman"], "https://doi.org/10.21437/Interspeech.2019-2512", 5], ["Effects of Waveform PMF on Anti-Spoofing Detection.", ["Itshak Lapidot", "Jean-Francois Bonastre"], "https://doi.org/10.21437/Interspeech.2019-2607", 5], ["Nonparallel Emotional Speech Conversion.", ["Jian Gao", "Deep Chakraborty", "Hamidou Tembine", "Olaitan Olaleye"], "https://doi.org/10.21437/Interspeech.2019-2878", 5], ["Self-Supervised Speaker Embeddings.", ["Themos Stafylakis", "Johan Rohdin", "Oldrich Plchot", "Petr Mizera", "Lukas Burget"], "https://doi.org/10.21437/Interspeech.2019-2842", 5], ["Privacy-Preserving Speaker Recognition with Cohort Score Normalisation.", ["Andreas Nautsch", "Jose Patino", "Amos Treiber", "Themos Stafylakis", "Petr Mizera", "Massimiliano Todisco", "Thomas Schneider", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2019-2638", 5], ["Large Margin Softmax Loss for Speaker Verification.", ["Yi Liu", "Liang He", "Jia Liu"], "https://doi.org/10.21437/Interspeech.2019-2357", 5], ["A Deep Neural Network for Short-Segment Speaker Recognition.", ["Amirhossein Hajavi", "Ali Etemad"], "https://doi.org/10.21437/Interspeech.2019-2240", 5], ["Deep Speaker Embedding Extraction with Channel-Wise Feature Responses and Additive Supervision Softmax Loss Function.", ["Jianfeng Zhou", "Tao Jiang", "Zheng Li", "Lin Li", "Qingyang Hong"], "https://doi.org/10.21437/Interspeech.2019-1704", 5], ["VoiceID Loss: Speech Enhancement for Speaker Verification.", ["Suwon Shon", "Hao Tang", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1496", 5], ["Blind Channel Response Estimation for Replay Attack Detection.", ["Anderson R. Avila", "Md. Jahangir Alam", "Douglas D. OShaughnessy", "Tiago H. Falk"], "https://doi.org/10.21437/Interspeech.2019-2956", 5], ["Energy Separation-Based Instantaneous Frequency Estimation for Cochlear Cepstral Feature for Replay Spoof Detection.", ["Ankur T. Patil", "Rajul Acharya", "Pulikonda Krishna Aditya Sai", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2019-2742", 5], ["Optimization of False Acceptance/Rejection Rates and Decision Threshold for End-to-End Text-Dependent Speaker Verification Systems.", ["Victoria Mingote", "Antonio Miguel", "Dayana Ribas", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-2550", 5], ["Deep Hashing for Speaker Identification and Retrieval.", ["Lei Fan", "Qing-Yuan Jiang", "Ya-Qi Yu", "Wu-Jun Li"], "https://doi.org/10.21437/Interspeech.2019-2457", 5], ["Adversarial Optimization for Dictionary Attacks on Speaker Verification.", ["Mirko Marras", "Pawel Korus", "Nasir D. Memon", "Gianni Fenu"], "https://doi.org/10.21437/Interspeech.2019-2430", 5], ["An Adaptive-Q Cochlear Model for Replay Spoofing Detection.", ["Tharshini Gunendradasan", "Eliathamby Ambikairajah", "Julien Epps", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-2361", 5], ["An End-to-End Text-Independent Speaker Verification Framework with a Keyword Adversarial Network.", ["Sungrack Yun", "Janghoon Cho", "Jungyun Eum", "Wonil Chang", "Kyuwoong Hwang"], "https://doi.org/10.21437/Interspeech.2019-2208", 5], ["Shortcut Connections Based Deep Speaker Embeddings for End-to-End Speaker Verification System.", ["Soonshin Seo", "Daniel Jun Rim", "Minkyu Lim", "Donghyun Lee", "Hosung Park", "Junseok Oh", "Changmin Kim", "Ji-Hwan Kim"], "https://doi.org/10.21437/Interspeech.2019-2195", 5], ["Device Feature Extractor for Replay Spoofing Detection.", ["Chang Huai You", "Jichen Yang", "Huy Dat Tran"], "https://doi.org/10.21437/Interspeech.2019-2137", 5], ["Cross-Domain Replay Spoofing Attack Detection Using Domain Adversarial Training.", ["Hongji Wang", "Heinrich Dinkel", "Shuai Wang", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2019-2120", 5], ["A Study of x-Vector Based Speaker Recognition on Short Utterances.", ["Ahilan Kanagasundaram", "Sridha Sridharan", "Ganapathy Sriram", "S. Prachi", "Clinton Fookes"], "https://doi.org/10.21437/Interspeech.2019-1891", 5], ["Tied Mixture of Factor Analyzers Layer to Combine Frame Level Representations in Neural Speaker Embeddings.", ["Nanxin Chen", "Jesus Villalba", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-1782", 5], ["Biologically Inspired Adaptive-Q Filterbanks for Replay Spoofing Attack Detection.", ["Buddhi Wickramasinghe", "Eliathamby Ambikairajah", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2019-1535", 5], ["On Robustness of Unsupervised Domain Adaptation for Speaker Recognition.", ["Pierre-Michel Bousquet", "Mickael Rouvier"], "https://doi.org/10.21437/Interspeech.2019-1524", 5], ["Large-Scale Speaker Retrieval on Random Speaker Variability Subspace.", ["Suwon Shon", "Younggun Lee", "Taesu Kim"], "https://doi.org/10.21437/Interspeech.2019-1498", 5], ["Meeting Transcription Using Asynchronous Distant Microphones.", ["Takuya Yoshioka", "Dimitrios Dimitriadis", "Andreas Stolcke", "William Hinthorn", "Zhuo Chen", "Michael Zeng", "Xuedong Huang"], "https://doi.org/10.21437/Interspeech.2019-3088", 5], ["Detection and Recovery of OOVs for Improved English Broadcast News Captioning.", ["Samuel Thomas", "Kartik Audhkhasi", "Zoltan Tuske", "Yinghui Huang", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2793", 5], ["Improving Large Vocabulary Urdu Speech Recognition System Using Deep Neural Networks.", ["Muhammad Umar Farooq", "Farah Adeeba", "Sahar Rauf", "Sarmad Hussain"], "https://doi.org/10.21437/Interspeech.2019-2629", 5], ["Hybrid Arbitration Using Raw ASR String and NLU Information - Taking the Best of Both Embedded World and Cloud World.", ["Min Tang"], "https://doi.org/10.21437/Interspeech.2019-2586", 5], ["Leveraging a Character, Word and Prosody Triplet for an ASR Error Robust and Agglutination Friendly Punctuation Approach.", ["Gyorgy Szaszak", "Mate Akos Tundik"], "https://doi.org/10.21437/Interspeech.2019-2132", 5], ["The Airbus Air Traffic Control Speech Recognition 2018 Challenge: Towards ATC Automatic Transcription and Call Sign Detection.", ["Thomas Pellegrini", "Jerome Farinas", "Estelle Delpech", "Francois Lancelot"], "https://doi.org/10.21437/Interspeech.2019-1962", 5], ["Kite: Automatic Speech Recognition for Unmanned Aerial Vehicles.", ["Dan Oneata", "Horia Cucu"], "https://doi.org/10.21437/Interspeech.2019-1390", 5], ["Exploring Methods for the Automatic Detection of Errors in Manual Transcription.", ["Xiaofei Wang", "Jinyi Yang", "Ruizhi Li", "Samik Sadhu", "Hynek Hermansky"], "https://doi.org/10.21437/Interspeech.2019-1343", 5], ["Improved Low-Resource Somali Speech Recognition by Semi-Supervised Acoustic and Language Model Training.", ["Astik Biswas", "Raghav Menon", "Ewald van der Westhuizen", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2019-1328", 5], ["The Althingi ASR System.", ["Inga Run Helgadottir", "Anna Bjork Nikulasdottir", "Michal Borsky", "Judy Y. Fong", "Robert Kjaran", "Jon Gudnason"], "https://doi.org/10.21437/Interspeech.2019-1248", 5], ["CRIM's Speech Transcription and Call Sign Detection System for the ATC Airbus Challenge Task.", ["Vishwa Gupta", "Lise Rebout", "Gilles Boulianne", "Pierre Andre Menard", "Jahangir Alam"], "https://doi.org/10.21437/Interspeech.2019-1131", 5], ["Optimizing Speech-Input Length for Speaker-Independent Depression Classification.", ["Tomasz Rutowski", "Amir Harati", "Yang Lu", "Elizabeth Shriberg"], "https://doi.org/10.21437/Interspeech.2019-3095", 5], ["A New Approach for Automating Analysis of Responses on Verbal Fluency Tests from Subjects At-Risk for Schizophrenia.", ["Mary Pietrowicz", "Carla Agurto", "Raquel Norel", "Elif Eyigoz", "Guillermo A. Cecchi", "Zarina R. Bilgrami", "Cheryl Corcoran"], "https://doi.org/10.21437/Interspeech.2019-2987", 5], ["Comparison of Telephone Recordings and Professional Microphone Recordings for Early Detection of Parkinson's Disease, Using Mel-Frequency Cepstral Coefficients with Gaussian Mixture Models.", ["Laetitia Jeancolas", "Graziella Mangone", "Jean-Christophe Corvol", "Marie Vidailhet", "Stephane Lehericy", "Badr-Eddine Benkelfat", "Habib Benali", "Dijana Petrovska-Delacretaz"], "https://doi.org/10.21437/Interspeech.2019-2825", 5], ["Spectral Subspace Analysis for Automatic Assessment of Pathological Speech Intelligibility.", ["Parvaneh Janbakhshi", "Ina Kodrasi", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2019-2791", 5], ["An Investigation of Therapeutic Rapport Through Prosody in Brief Psychodynamic Psychotherapy.", ["Carolina De Pasquale", "Charlie Cullen", "Brian Vaughan"], "https://doi.org/10.21437/Interspeech.2019-2551", 5], ["Feature Representation of Pathophysiology of Parkinsonian Dysarthria.", ["Alice Rueda", "Juan Camilo Vasquez-Correa", "Cristian David Rios-Urrego", "Juan Rafael Orozco-Arroyave", "Sridhar Krishnan", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-2490", 5], ["Neural Transfer Learning for Cry-Based Diagnosis of Perinatal Asphyxia.", ["Charles C. Onu", "Jonathan Lebensold", "William L. Hamilton", "Doina Precup"], "https://doi.org/10.21437/Interspeech.2019-2340", 5], ["Investigating the Variability of Voice Quality and Pain Levels as a Function of Multiple Clinical Parameters.", ["Hui-Ting Hong", "Jeng-Lin Li", "Yi-Ming Weng", "Chip-Jin Ng", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2247", 5], ["Assessing Parkinson's Disease from Speech Using Fisher Vectors.", ["Jose Vicente Egas Lopez", "Juan Rafael Orozco-Arroyave", "Gabor Gosztolya"], "https://doi.org/10.21437/Interspeech.2019-2217", 5], ["Feature Space Visualization with Spatial Similarity Maps for Pathological Speech Data.", ["Philipp Klumpp", "Juan Camilo Vasquez-Correa", "Tino Haderlein", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-2080", 5], ["Predicting Behavior in Cancer-Afflicted Patient and Spouse Interactions Using Speech and Language.", ["Sandeep Nallan Chakravarthula", "Haoqi Li", "Shao-Yen Tseng", "Maija Reblin", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2019-1888", 5], ["Automatic Assessment of Language Impairment Based on Raw ASR Output.", ["Ying Qin", "Tan Lee", "Anthony Pak-Hin Kong"], "https://doi.org/10.21437/Interspeech.2019-1688", 5], ["Effects of Spectral and Temporal Cues to Mandarin Concurrent-Vowels Identification for Normal-Hearing and Hearing-Impaired Listeners.", ["Zhen Fu", "Xihong Wu", "Jing Chen"], "https://doi.org/10.21437/Interspeech.2019-3209", 5], ["Disfluencies and Human Speech Transcription Errors.", ["Vicky Zayats", "Trang Tran", "Richard A. Wright", "Courtney Mansfield", "Mari Ostendorf"], "https://doi.org/10.21437/Interspeech.2019-3134", 5], ["The Influence of Distraction on Speech Processing: How Selective is Selective Attention?", ["Sandra I. Parhammer", "Miriam Ebersberg", "Jenny Tippmann", "Katja Stark", "Andreas Opitz", "Barbara Hinger", "Sonja Rossi"], "https://doi.org/10.21437/Interspeech.2019-2699", 5], ["Subjective Evaluation of Communicative Effort for Younger and Older Adults in Interactive Tasks with Energetic and Informational Masking.", ["Valerie Hazan", "Outi Tuomainen", "Linda Taschenberger"], "https://doi.org/10.21437/Interspeech.2019-2215", 5], ["Perceiving Older Adults Producing Clear and Lombard Speech.", ["Chris Davis", "Jeesun Kim"], "https://doi.org/10.21437/Interspeech.2019-2210", 5], ["Phone-Attribute Posteriors to Evaluate the Speech of Cochlear Implant Users.", ["Tomas Arias-Vergara", "Juan Rafael Orozco-Arroyave", "Milos Cernak", "Sandra Gollwitzer", "Maria Schuster", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-2144", 5], ["Effects of Urgent Speech and Congruent/Incongruent Text on Speech Intelligibility in Noise and Reverberation.", ["Nao Hodoshima"], "https://doi.org/10.21437/Interspeech.2019-1902", 5], ["Quantifying Cochlear Implant Users' Ability for Speaker Identification Using CI Auditory Stimuli.", ["Nursadul Mamun", "Ria Ghosh", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-1852", 5], ["Lexically Guided Perceptual Learning of a Vowel Shift in an Interactive L2 Listening Context.", ["E. Felker", "Mirjam Ernestus", "Mirjam Broersma"], "https://doi.org/10.21437/Interspeech.2019-1414", 5], ["Talker Intelligibility and Listening Effort with Temporally Modified Speech.", ["Maximillian Paulus", "Valerie Hazan", "Patti Adank"], "https://doi.org/10.21437/Interspeech.2019-1402", 5], ["R2SPIN: Re-Recording the Revised Speech Perception in Noise Test.", ["Lauren Ward", "Catherine Robinson", "Matthew Paradis", "Katherine M. Tucker", "Ben G. Shirley"], "https://doi.org/10.21437/Interspeech.2019-1281", 5], ["Contributions of Consonant-Vowel Transitions to Mandarin Tone Identification in Simulated Electric-Acoustic Hearing.", ["Fei Chen"], "https://doi.org/10.21437/Interspeech.2019-1124", 5], ["Monaural Speech Enhancement with Dilated Convolutions.", ["Shadi Pirhosseinloo", "Jonathan S. Brumberg"], "https://doi.org/10.21437/Interspeech.2019-2782", 5], ["Noise Adaptive Speech Enhancement Using Domain Adversarial Training.", ["Chien-Feng Liao", "Yu Tsao", "Hung-yi Lee", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-1519", 5], ["Environment-Dependent Attention-Driven Recurrent Convolutional Neural Network for Robust Speech Enhancement.", ["Meng Ge", "Longbiao Wang", "Nan Li", "Hao Shi", "Jianwu Dang", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2019-1477", 5], ["A Statistically Principled and Computationally Efficient Approach to Speech Enhancement Using Variational Autoencoders.", ["Manuel Pariente", "Antoine Deleforge", "Emmanuel Vincent"], "https://doi.org/10.21437/Interspeech.2019-1398", 5], ["Speech Enhancement Using Forked Generative Adversarial Networks with Spectral Subtraction.", ["Ju Lin", "Sufeng Niu", "Zice Wei", "Xiang Lan", "Adriaan J. van Wijngaarden", "Melissa C. Smith", "Kuang-Ching Wang"], "https://doi.org/10.21437/Interspeech.2019-2954", 5], ["Specialized Speech Enhancement Model Selection Based on Learned Non-Intrusive Quality Assessment Metric.", ["Ryandhimas E. Zezario", "Szu-Wei Fu", "Xugang Lu", "Hsin-Min Wang", "Yu Tsao"], "https://doi.org/10.21437/Interspeech.2019-2425", 5], ["Speaker-Aware Deep Denoising Autoencoder with Embedded Speaker Identity for Speech Enhancement.", ["Fu-Kai Chuang", "Syu-Siang Wang", "Jeih-weih Hung", "Yu Tsao", "Shih-Hau Fang"], "https://doi.org/10.21437/Interspeech.2019-2108", 5], ["Investigation of Cost Function for Supervised Monaural Speech Separation.", ["Yun Liu", "Hui Zhang", "Xueliang Zhang", "Yuhang Cao"], "https://doi.org/10.21437/Interspeech.2019-1897", 5], ["Deep Attention Gated Dilated Temporal Convolutional Networks with Intra-Parallel Convolutional Modules for End-to-End Monaural Speech Separation.", ["Ziqiang Shi", "Huibin Lin", "Liu Liu", "Rujie Liu", "Jiqing Han", "Anyan Shi"], "https://doi.org/10.21437/Interspeech.2019-1373", 5], ["Masking Estimation with Phase Restoration of Clean Speech for Monaural Speech Enhancement.", ["Xianyun Wang", "Changchun Bao"], "https://doi.org/10.21437/Interspeech.2019-1141", 5], ["Progressive Speech Enhancement with Residual Connections.", ["Jorge Llombart", "Dayana Ribas", "Antonio Miguel", "Luis Vicente", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-1748", 5], ["Acoustic Model Bootstrapping Using Semi-Supervised Learning.", ["Langzhou Chen", "Volker Leutnant"], "https://doi.org/10.21437/Interspeech.2019-2818", 5], ["Bandwidth Embeddings for Mixed-Bandwidth Speech Recognition.", ["Gautam Mantena", "Ozlem Kalinli", "Ossama Abdel-Hamid", "Don McAllaster"], "https://doi.org/10.21437/Interspeech.2019-2589", 5], ["Adversarial Black-Box Attacks on Automatic Speech Recognition Systems Using Multi-Objective Evolutionary Optimization.", ["Shreya Khare", "Rahul Aralikatte", "Senthil Mani"], "https://doi.org/10.21437/Interspeech.2019-2420", 5], ["Towards Debugging Deep Neural Networks by Generating Speech Utterances.", ["Bilal Soomro", "Anssi Kanervisto", "Trung Ngo Trong", "Ville Hautamaki"], "https://doi.org/10.21437/Interspeech.2019-2339", 5], ["Compression of CTC-Trained Acoustic Models by Dynamic Frame-Wise Distillation or Segment-Wise N-Best Hypotheses Imitation.", ["Haisong Ding", "Kai Chen", "Qiang Huo"], "https://doi.org/10.21437/Interspeech.2019-2182", 5], ["Keyword Spotting for Hearing Assistive Devices Robust to External Speakers.", ["Ivan Lopez-Espejo", "Zheng-Hua Tan", "Jesper Jensen"], "https://doi.org/10.21437/Interspeech.2019-2010", 5], ["Latent Dirichlet Allocation Based Acoustic Data Selection for Automatic Speech Recognition.", ["Mortaza Doulaty", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2019-1797", 5], ["Target Speaker Recovery and Recognition Network with Average x-Vector and Global Training.", ["Wenjie Li", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-1692", 5], ["Lyrics Recognition from Singing Voice Focused on Correspondence Between Voice and Notes.", ["Motoyuki Suzuki", "Sho Tomita", "Tomoki Morita"], "https://doi.org/10.21437/Interspeech.2019-1318", 4], ["Transfer Learning from Audio-Visual Grounding to Speech Recognition.", ["Wei-Ning Hsu", "David Harwath", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1227", 5], ["Cross-Corpus Speech Emotion Recognition Using Semi-Supervised Transfer Non-Negative Matrix Factorization with Adaptation Regularization.", ["Hui Luo", "Jiqing Han"], "https://doi.org/10.21437/Interspeech.2019-2041", 5], ["Modeling User Context for Valence Prediction from Narratives.", ["Aniruddha Tammewar", "Alessandra Cervone", "Eva-Maria Messner", "Giuseppe Riccardi"], "https://doi.org/10.21437/Interspeech.2019-2489", 5], ["Front-End Feature Compensation and Denoising for Noise Robust Speech Emotion Recognition.", ["Rupayan Chakraborty", "Ashish Panda", "Meghna Pandharipande", "Sonal Joshi", "Sunil Kumar Kopparapu"], "https://doi.org/10.21437/Interspeech.2019-2243", 5], ["The Contribution of Acoustic Features Analysis to Model Emotion Perceptual Process for Language Diversity.", ["Xingfeng Li", "Masato Akagi"], "https://doi.org/10.21437/Interspeech.2019-2229", 5], ["Design and Development of a Multi-Lingual Speech Corpora (TaMaR-EmoDB) for Emotion Analysis.", ["Rajeev Rajan", "Haritha U. G.", "Sujitha A. C.", "Rejisha T. M."], "https://doi.org/10.21437/Interspeech.2019-2034", 5], ["Speech Emotion Recognition with a Reject Option.", ["Kusha Sridhar", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2019-1842", 5], ["Development of Emotion Rankers Based on Intended and Perceived Emotion Labels.", ["Zhenghao Jin", "Houwei Cao"], "https://doi.org/10.21437/Interspeech.2019-1831", 5], ["Emotion Recognition from Natural Phone Conversations in Individuals with and without Recent Suicidal Ideation.", ["John Gideon", "Heather T. Schatten", "Melvin G. McInnis", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2019-1830", 5], ["An Acoustic and Lexical Analysis of Emotional Valence in Spontaneous Speech: Autobiographical Memory Recall in Older Adults.", ["Deniece S. Nazareth", "Ellen Tournier", "Sarah Leimkotter", "Esther Janse", "Dirk Heylen", "Gerben J. Westerhof", "Khiet P. Truong"], "https://doi.org/10.21437/Interspeech.2019-1823", 5], ["Does the Lombard Effect Improve Emotional Communication in Noise? - Analysis of Emotional Speech Acted in Noise.", ["Yi Zhao", "Atsushi Ando", "Shinji Takaki", "Junichi Yamagishi", "Satoshi Kobashikawa"], "https://doi.org/10.21437/Interspeech.2019-1605", 5], ["Linear Discriminant Differential Evolution for Feature Selection in Emotional Speech Recognition.", ["Soumaya Gharsellaoui", "Sid-Ahmed Selouani", "Mohammed Sidi Yakoub"], "https://doi.org/10.21437/Interspeech.2019-1218", 5], ["Multi-Modal Learning for Speech Emotion Recognition: An Analysis and Comparison of ASR Outputs with Ground Truth Transcription.", ["Saurabh Sahu", "Vikramjit Mitra", "Nadee Seneviratne", "Carol Y. Espy-Wilson"], "https://doi.org/10.21437/Interspeech.2019-1149", 5], ["Articulatory Characteristics of Secondary Palatalization in Romanian Fricatives.", ["Laura Spinu", "Maida Percival", "Alexei Kochetov"], "https://doi.org/10.21437/Interspeech.2019-3039", 5], ["Articulation of Vowel Length Contrasts in Australian English.", ["Louise Ratko", "Michael I. Proctor", "Felicity Cox"], "https://doi.org/10.21437/Interspeech.2019-2995", 5], ["V-to-V Coarticulation Induced Acoustic and Articulatory Variability of Vowels: The Effect of Pitch-Accent.", ["Andrea Deme", "Marton Bartok", "Tekla Etelka Graczi", "Tamas Gabor Csapo", "Alexandra Marko"], "https://doi.org/10.21437/Interspeech.2019-2890", 5], ["The Contribution of Lip Protrusion to Anglo-English /r/: Evidence from Hyper- and Non-Hyperarticulated Speech.", ["Hannah King", "Emmanuel Ferragne"], "https://doi.org/10.21437/Interspeech.2019-2851", 5], ["Articulatory Analysis of Transparent Vowel /i\u02d0/ in Harmonic and Antiharmonic Hungarian Stems: Is There a Difference?", ["Alexandra Marko", "Marton Bartok", "Tamas Gabor Csapo", "Tekla Etelka Graczi", "Andrea Deme"], "https://doi.org/10.21437/Interspeech.2019-2352", 5], ["On the Role of Oral Configurations in European Portuguese Nasal Vowels.", ["Conceicao Cunha", "Samuel S. Silva", "Antonio J. S. Teixeira", "Catarina Oliveira", "Paula Martins", "Arun A. Joseph", "Jens Frahm"], "https://doi.org/10.21437/Interspeech.2019-2232", 5], ["Residual + Capsule Networks (ResCap) for Simultaneous Single-Channel Overlapped Keyword Recognition.", ["Yan Xiong", "Visar Berisha", "Chaitali Chakrabarti"], "https://doi.org/10.21437/Interspeech.2019-2913", 5], ["A Study for Improving Device-Directed Speech Detection Toward Frictionless Human-Machine Interaction.", ["Che-Wei Huang", "Roland Maas", "Sri Harish Mallidi", "Bjorn Hoffmeister"], "https://doi.org/10.21437/Interspeech.2019-2840", 5], ["Unsupervised Methods for Audio Classification from Lecture Discussion Recordings.", ["Hang Su", "Borislav Dzodzo", "Xixin Wu", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2384", 5], ["Neural Whispered Speech Detection with Imbalanced Learning.", ["Takanori Ashihara", "Yusuke Shinohara", "Hiroshi Sato", "Takafumi Moriya", "Kiyoaki Matsui", "Takaaki Fukutomi", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-2161", 5], ["Deep Learning for Orca Call Type Identification - A Fully Unsupervised Approach.", ["Christian Bergler", "Manuel Schmitt", "Rachael Xi Cheng", "Andreas K. Maier", "Volker Barth", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-1857", 5], ["Open-Vocabulary Keyword Spotting with Audio and Text Embeddings.", ["Niccolo Sacchi", "Alexandre Nanchen", "Martin Jaggi", "Milos Cernak"], "https://doi.org/10.21437/Interspeech.2019-1846", 5], ["ToneNet: A CNN Model of Tone Classification of Mandarin Chinese.", ["Qiang Gao", "Shutao Sun", "Yaping Yang"], "https://doi.org/10.21437/Interspeech.2019-1483", 5], ["Temporal Convolution for Real-Time Keyword Spotting on Mobile Devices.", ["Seungwoo Choi", "Seokjun Seo", "Beomjun Shin", "Hyeongmin Byun", "Martin Kersner", "Beomsu Kim", "Dongyoung Kim", "Sungjoo Ha"], "https://doi.org/10.21437/Interspeech.2019-1363", 5], ["Audio Tagging with Compact Feedforward Sequential Memory Network and Audio-to-Audio Ratio Based Data Augmentation.", ["Zhiying Huang", "Shiliang Zhang", "Ming Lei"], "https://doi.org/10.21437/Interspeech.2019-1302", 5], ["Music Genre Classification Using Duplicated Convolutional Layers in Neural Networks.", ["Hansi Yang", "Wei-Qiang Zhang"], "https://doi.org/10.21437/Interspeech.2019-1298", 5], ["A Storyteller's Tale: Literature Audiobooks Genre Classification Using CNN and RNN Architectures.", ["Nehory Carmi", "Azaria Cohen", "Mireille Avigal", "Anat Lerner"], "https://doi.org/10.21437/Interspeech.2019-1154", 4], ["Parameter Enhancement for MELP Speech Codec in Noisy Communication Environment.", ["Min-Jae Hwang", "Hong-Goo Kang"], "https://doi.org/10.21437/Interspeech.2019-3249", 5], ["Cascaded Cross-Module Residual Learning Towards Lightweight End-to-End Speech Coding.", ["Kai Zhen", "Jongmo Sung", "Mi Suk Lee", "Seungkwon Beack", "Minje Kim"], "https://doi.org/10.21437/Interspeech.2019-1816", 5], ["End-to-End Optimization of Source Models for Speech and Audio Coding Using a Machine Learning Framework.", ["Tom Backstrom"], "https://doi.org/10.21437/Interspeech.2019-1284", 5], ["A Real-Time Wideband Neural Vocoder at 1.6kb/s Using LPCNet.", ["Jean-Marc Valin", "Jan Skoglund"], "https://doi.org/10.21437/Interspeech.2019-1255", 5], ["Super-Wideband Spectral Envelope Modeling for Speech Coding.", ["Guillaume Fuchs", "Chamran Ashour", "Tom Backstrom"], "https://doi.org/10.21437/Interspeech.2019-1620", 5], ["Speech Audio Super-Resolution for Speech Recognition.", ["Xinyu Li", "Venkata Chebiyyam", "Katrin Kirchhoff"], "https://doi.org/10.21437/Interspeech.2019-3043", 5], ["Artificial Bandwidth Extension Using H\u221e Optimization.", ["Deepika Gupta", "Hanumant Singh Shekhawat"], "https://doi.org/10.21437/Interspeech.2019-1580", 5], ["Quality Degradation Diagnosis for Voice Networks - Estimating the Perceived Noisiness, Coloration, and Discontinuity of Transmitted Speech.", ["Gabriel Mittag", "Sebastian Moller"], "https://doi.org/10.21437/Interspeech.2019-2636", 5], ["A Cross-Entropy-Guided (CEG) Measure for Speech Enhancement Front-End Assessing Performances of Back-End Automatic Speech Recognition.", ["Li Chai", "Jun Du", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2019-2511", 5], ["Extending the E-Model Towards Super-Wideband and Fullband Speech Communication Scenarios.", ["Sebastian Moller", "Gabriel Mittag", "Thilo Michael", "Vincent Barriac", "Hitoshi Aoki"], "https://doi.org/10.21437/Interspeech.2019-1340", 5], ["Modulation Vectors as Robust Feature Representation for ASR in Domain Mismatched Conditions.", ["Samik Sadhu", "Hynek Hermansky"], "https://doi.org/10.21437/Interspeech.2019-2723", 5], ["Prosody Usage Optimization for Children Speech Recognition with Zero Resource Children Speech.", ["Chenda Li", "Yanmin Qian"], "https://doi.org/10.21437/Interspeech.2019-2659", 5], ["Unsupervised Raw Waveform Representation Learning for ASR.", ["Purvi Agrawal", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2019-2652", 5], ["Low-Dimensional Bottleneck Features for On-Device Continuous Speech Recognition.", ["David B. Ramsay", "Kevin Kilgour", "Dominik Roblek", "Matthew Sharifi"], "https://doi.org/10.21437/Interspeech.2019-2193", 4], ["Binary Speech Features for Keyword Spotting Tasks.", ["Alexandre Riviello", "Jean-Pierre David"], "https://doi.org/10.21437/Interspeech.2019-1877", 5], ["wav2vec: Unsupervised Pre-Training for Speech Recognition.", ["Steffen Schneider", "Alexei Baevski", "Ronan Collobert", "Michael Auli"], "https://doi.org/10.21437/Interspeech.2019-1873", 5], ["Automatic Detection of Prosodic Focus in American English.", ["Sunghye Cho", "Mark Liberman", "Yong-cheol Lee"], "https://doi.org/10.21437/Interspeech.2019-1668", 5], ["Feature Exploration for Almost Zero-Resource ASR-Free Keyword Spotting Using a Multilingual Bottleneck Extractor and Correspondence Autoencoders.", ["Raghav Menon", "Herman Kamper", "Ewald van der Westhuizen", "John Quinn", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2019-1665", 5], ["On Learning Interpretable CNNs with Parametric Modulated Kernel-Based Filters.", ["Erfan Loweimi", "Peter Bell", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2019-1257", 5], ["Reverse Transfer Learning: Can Word Embeddings Trained for Different NLP Tasks Improve Neural Language Models?", ["Lyan Verwimp", "Jerome R. Bellegarda"], "https://doi.org/10.21437/Interspeech.2019-1332", 5], ["Joint Grapheme and Phoneme Embeddings for Contextual End-to-End ASR.", ["Zhehuai Chen", "Mahaveer Jain", "Yongqiang Wang", "Michael L. Seltzer", "Christian Fuegen"], "https://doi.org/10.21437/Interspeech.2019-1434", 5], ["Character-Aware Sub-Word Level Language Modeling for Uyghur and Turkish ASR.", ["Chang Liu", "Zhen Zhang", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-1484", 5], ["Connecting and Comparing Language Model Interpolation Techniques.", ["Ernest Pusateri", "Christophe Van Gysel", "Rami Botros", "Sameer Badaskar", "Mirko Hannemann", "Youssef Oualil", "Ilya Oparin"], "https://doi.org/10.21437/Interspeech.2019-1822", 5], ["Enriching Rare Word Representations in Neural Language Models by Embedding Matrix Augmentation.", ["Yerbolat Khassanov", "Zhiping Zeng", "Van Tung Pham", "Haihua Xu", "Eng Siong Chng"], "https://doi.org/10.21437/Interspeech.2019-1858", 5], ["Comparative Study of Parametric and Representation Uncertainty Modeling for Recurrent Neural Network Language Models.", ["Jianwei Yu", "Max W. Y. Lam", "Shoukang Hu", "Xixin Wu", "Xu Li", "Yuewen Cao", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1927", 5], ["Improving Automatically Induced Lexicons for Highly Agglutinating Languages Using Data-Driven Morphological Segmentation.", ["Wiehan Agenbag", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2019-2164", 5], ["Attention-Based Word Vector Prediction with LSTMs and its Application to the OOV Problem in ASR.", ["Alejandro Coucheiro-Limeres", "Fernando Fernandez-Martinez", "Ruben San Segundo", "Javier Ferreiros Lopez"], "https://doi.org/10.21437/Interspeech.2019-2347", 5], ["Code-Switching Sentence Generation by Bert and Generative Adversarial Networks.", ["Yingying Gao", "Junlan Feng", "Ying Liu", "Leijing Hou", "Xin Pan", "Yong Ma"], "https://doi.org/10.21437/Interspeech.2019-2501", 5], ["Unified Verbalization for Speech Recognition & Synthesis Across Languages.", ["Sandy Ritchie", "Richard Sproat", "Kyle Gorman", "Daan van Esch", "Christian Schallhart", "Nikos Bampounis", "Benoit Brard", "Jonas Fromseier Mortensen", "Millie Holt", "Eoin Mahon"], "https://doi.org/10.21437/Interspeech.2019-2807", 5], ["Better Morphology Prediction for Better Speech Systems.", ["Dravyansh Sharma", "Melissa Wilson", "Antoine Bruguier"], "https://doi.org/10.21437/Interspeech.2019-3207", 5], ["Vietnamese Learners Tackling the German /\u0283t/ in Perception.", ["Anke Sennema", "Silke Hamann"], "https://doi.org/10.21437/Interspeech.2019-2832", 4], ["An Articulatory-Acoustic Investigation into GOOSE-Fronting in German-English Bilinguals Residing in London, UK.", ["Scott Lewis", "Adib Mehrabi", "Esther de Leeuw"], "https://doi.org/10.21437/Interspeech.2019-2637", 5], ["Multimodal Articulation-Based Pronunciation Error Detection with Spectrogram and Acoustic Features.", ["Sabrina Jenne", "Ngoc Thang Vu"], "https://doi.org/10.21437/Interspeech.2019-1677", 5], ["Using Prosody to Discover Word Order Alternations in a Novel Language.", ["Anouschka Foltz", "Sarah Cooper", "Tamsin M. McKelvey"], "https://doi.org/10.21437/Interspeech.2019-1183", 5], ["Speaking Rate, Information Density, and Information Rate in First-Language and Second-Language Speech.", ["Ann R. Bradlow"], "https://doi.org/10.21437/Interspeech.2019-1150", 5], ["Articulation Rate as a Metric in Spoken Language Assessment.", ["Calbert Graham", "Francis Nolan"], "https://doi.org/10.21437/Interspeech.2019-2098", 5], ["Learning Alignment for Multimodal Emotion Recognition from Speech.", ["Haiyang Xu", "Hui Zhang", "Kun Han", "Yun Wang", "Yiping Peng", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2019-3247", 5], ["Liquid Deletion in French Child-Directed Speech.", ["Sharon Peperkamp", "Monica Hegde", "Maria Julia Carbajal"], "https://doi.org/10.21437/Interspeech.2019-2838", 5], ["Towards Detection of Canonical Babbling by Citizen Scientists: Performance as a Function of Clip Length.", ["Amanda Seidl", "Anne S. Warlaumont", "Alejandrina Cristia"], "https://doi.org/10.21437/Interspeech.2019-1773", 5], ["Nasal Consonant Discrimination in Infant- and Adult-Directed Speech.", ["Bogdan Ludusan", "Annett Jorschick", "Reiko Mazuka"], "https://doi.org/10.21437/Interspeech.2019-1737", 5], ["No Distributional Learning in Adults from Attended Listening to Non-Speech.", ["Ellen Marklund", "Johan Sjons", "Lisa Gustavsson", "Elisabet Eir Cortes"], "https://doi.org/10.21437/Interspeech.2019-1674", 5], ["A Computational Model of Early Language Acquisition from Audiovisual Experiences of Young Infants.", ["Okko Rasanen", "Khazar Khorrami"], "https://doi.org/10.21437/Interspeech.2019-1523", 5], ["The Production of Chinese Affricates /ts/ and /tsh/ by Native Urdu Speakers.", ["Dan Du", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2019-1638", 5], ["Multi-Stream Network with Temporal Attention for Environmental Sound Classification.", ["Xinyu Li", "Venkata Chebiyyam", "Katrin Kirchhoff"], "https://doi.org/10.21437/Interspeech.2019-3019", 5], ["Neural Network Distillation on IoT Platforms for Sound Event Detection.", ["Gianmarco Cerutti", "Rahul Prasad", "Alessio Brutti", "Elisabetta Farella"], "https://doi.org/10.21437/Interspeech.2019-2394", 5], ["Class-Wise Centroid Distance Metric Learning for Acoustic Event Detection.", ["Xugang Lu", "Peng Shen", "Sheng Li", "Yu Tsao", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2271", 5], ["A Hybrid Approach to Acoustic Scene Classification Based on Universal Acoustic Models.", ["Xue Bai", "Jun Du", "Zi-Rui Wang", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2019-2171", 5], ["Hierarchical Pooling Structure for Weakly Labeled Sound Event Detection.", ["Ke-Xin He", "Yu-Han Shen", "Wei-Qiang Zhang"], "https://doi.org/10.21437/Interspeech.2019-2049", 5], ["Sound Event Detection in Multichannel Audio Using Convolutional Time-Frequency-Channel Squeeze and Excitation.", ["Wei Xia", "Kazuhito Koishida"], "https://doi.org/10.21437/Interspeech.2019-1860", 5], ["A Robust Framework for Acoustic Scene Classification.", ["Lam Dang Pham", "Ian Vince McLoughlin", "Huy Phan", "Ramaswamy Palaniappan"], "https://doi.org/10.21437/Interspeech.2019-1841", 5], ["Compression of Acoustic Event Detection Models with Quantized Distillation.", ["Bowen Shi", "Ming Sun", "Chieh-Chi Kao", "Viktor Rozgic", "Spyros Matsoukas", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2019-1747", 5], ["An End-to-End Audio Classification System Based on Raw Waveforms and Mix-Training Strategy.", ["Jiaxu Chen", "Jing Hao", "Kai Chen", "Di Xie", "Shicai Yang", "Shiliang Pu"], "https://doi.org/10.21437/Interspeech.2019-1579", 5], ["Few-Shot Audio Classification with Attentional Graph Neural Networks.", ["Shilei Zhang", "Yong Qin", "Kewei Sun", "Yonghua Lin"], "https://doi.org/10.21437/Interspeech.2019-1532", 5], ["Semi-Supervised Audio Classification with Consistency-Based Regularization.", ["Kangkang Lu", "Chuan-Sheng Foo", "Kah Kuan Teh", "Huy Dat Tran", "Vijay Ramaseshan Chandrasekhar"], "https://doi.org/10.21437/Interspeech.2019-1231", 5], ["Avaya Conversational Intelligence: A Real-Time System for Spoken Language Understanding in Human-Human Call Center Conversations.", ["Jan Mizgajski", "Adrian Szymczak", "Robert Glowski", "Piotr Szymanski", "Piotr Zelasko", "Lukasz Augustyniak", "Mikolaj Morzy", "Yishay Carmiel", "Jeff Hodson", "Lukasz Wojciak", "Daniel Smoczyk", "Adam Wrobel", "Bartosz Borowik", "Adam Artajew", "Marcin Baran", "Cezary Kwiatkowski", "Marzena Zyla-Hoppe"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8002.html", 2], ["Robust Keyword Spotting via Recycle-Pooling for Mobile Game.", ["Shounan An", "Youngsoo Kim", "Hu Xu", "Jinwoo Lee", "Myungwoo Lee", "Insoo Oh"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8010.html", 2], ["Multimodal Dialog with the MALACH Audiovisual Archive.", ["Adam Chylek", "Lubos Smidl", "Jan Svec"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8011.html", 2], ["SpeechMarker: A Voice Based Multi-Level Attendance Application.", ["Sarfaraz Jelil", "Abhishek Shrivastava", "Rohan Kumar Das", "S. R. Mahadeva Prasanna", "Rohit Sinha"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8014.html", 2], ["Robust Sound Recognition: A Neuromorphic Approach.", ["Jibin Wu", "Zihan Pan", "Malu Zhang", "Rohan Kumar Das", "Yansong Chua", "Haizhou Li"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8032.html", 2], ["The CUHK Dysarthric Speech Recognition Systems for English and Cantonese.", ["Shoukang Hu", "Shansong Liu", "Heng Fai Chang", "Mengzhe Geng", "Jiani Chen", "Lau Wing Chung", "To Ka Hei", "Jianwei Yu", "Ka Ho Wong", "Xunying Liu", "Helen Meng"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8047.html", 2], ["BAS Web Services for Automatic Subtitle Creation and Anonymization.", ["Florian Schiel", "Thomas Kisler"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8001.html", 2], ["A User-Friendly and Adaptable Re-Implementation of an Acoustic Prominence Detection and Annotation Tool.", ["Jana Vosse", "Petra Wagner"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8015.html", 2], ["PyToBI: A Toolkit for ToBI Labeling Under Python.", ["Monica Dominguez", "Patrick Louis Rohrer", "Juan Soler Company"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8021.html", 2], ["GECKO - A Tool for Effective Annotation of Human Conversations.", ["Golan Levy", "Raquel Sitman", "Ido Amir", "Eduard Golshtein", "Ran Mochary", "Eilon Reshef", "Roi Reichart", "Omri Allouche"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8025.html", 2], ["SLP-AA: Tools for Sign Language Phonetic and Phonological Research.", ["Roger Yu-Hsiang Lo", "Kathleen Currie Hall"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8028.html", 2], ["SANTLR: Speech Annotation Toolkit for Low Resource Languages.", ["Xinjian Li", "Zhong Zhou", "Siddharth Dalmia", "Alan W. Black", "Florian Metze"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8040.html", 2], ["Web-Based Speech Synthesis Editor.", ["Martin Gruber", "Jakub Vit", "Jindrich Matousek"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8013.html", 2], ["GFM-Voc: A Real-Time Voice Quality Modification System.", ["Olivier Perrotin", "Ian Vince McLoughlin"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8018.html", 2], ["Off the Cuff: Exploring Extemporaneous Speech Delivery with TTS.", ["Eva Szekely", "Gustav Eje Henter", "Jonas Beskow", "Joakim Gustafson"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8026.html", 2], ["Synthesized Spoken Names: Biases Impacting Perception.", ["Lucas Kessler", "Cecilia Ovesdotter Alm", "Reynold Bailey"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8031.html", 2], ["Unbabel Talk - Human Verified Translations for Voice Instant Messaging.", ["Luis Bernardo", "Mathieu Giquel", "Sebastiao Quintas", "Paulo Dimas", "Helena Moniz", "Isabel Trancoso"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8034.html", 2], ["Adjusting Pleasure-Arousal-Dominance for Continuous Emotional Text-to-Speech Synthesizer.", ["Azam Rabiee", "Tae-Ho Kim", "Soo-Young Lee"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8045.html", 2], ["Learning Natural Language Interfaces with Neural Models.", ["Mirella Lapata"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs23.html", 0], ["The GDPR & Speech Data: Reflections of Legal and Technology Communities, First Steps Towards a Common Understanding.", ["Andreas Nautsch", "Catherine Jasserand", "Els Kindt", "Massimiliano Todisco", "Isabel Trancoso", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2019-2647", 5], ["Privacy-Preserving Adversarial Representation Learning in ASR: Reality or Illusion?", ["Brij Mohan Lal Srivastava", "Aurelien Bellet", "Marc Tommasi", "Emmanuel Vincent"], "https://doi.org/10.21437/Interspeech.2019-2415", 5], ["Privacy-Preserving Siamese Feature Extraction for Gender Recognition versus Speaker Identification.", ["Alexandru Nelus", "Silas Rech", "Timm Koppelmann", "Henrik Biermann", "Rainer Martin"], "https://doi.org/10.21437/Interspeech.2019-1148", 5], ["Privacy-Preserving Variational Information Feature Extraction for Domestic Activity Monitoring versus Speaker Identification.", ["Alexandru Nelus", "Janek Ebbers", "Reinhold Haeb-Umbach", "Rainer Martin"], "https://doi.org/10.21437/Interspeech.2019-1703", 5], ["Extracting Mel-Frequency and Bark-Frequency Cepstral Coefficients from Encrypted Signals.", ["Patricia Thaine", "Gerald Penn"], "https://doi.org/10.21437/Interspeech.2019-1136", 5], ["Sound Privacy: A Conversational Speech Corpus for Quantifying the Experience of Privacy.", ["Pablo Perez Zarazaga", "Sneha Das", "Tom Backstrom", "Vishnu Vidyadhara Raju Vegesna", "Anil Kumar Vuppala"], "https://doi.org/10.21437/Interspeech.2019-1172", 5], ["Improving Code-Switched Language Modeling Performance Using Cognate Features.", ["Victor Soto", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2019-2681", 5], ["Linguistically Motivated Parallel Data Augmentation for Code-Switch Language Modeling.", ["Grandee Lee", "Xianghu Yue", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1382", 5], ["Variational Attention Using Articulatory Priors for Generating Code Mixed Speech Using Monolingual Corpora.", ["Sai Krishna Rallabandi", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2019-1103", 5], ["Code-Switching Detection Using ASR-Generated Language Posteriors.", ["Qinyi Wang", "Emre Yilmaz", "Adem Derinel", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1161", 5], ["Semi-Supervised Acoustic Model Training for Five-Lingual Code-Switched ASR.", ["Astik Biswas", "Emre Yilmaz", "Febe de Wet", "Ewald van der Westhuizen", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2019-1325", 5], ["Multi-Graph Decoding for Code-Switching ASR.", ["Emre Yilmaz", "Samuel Cohen", "Xianghu Yue", "David A. van Leeuwen", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1125", 5], ["End-to-End Multilingual Multi-Speaker Speech Recognition.", ["Hiroshi Seki", "Takaaki Hori", "Shinji Watanabe", "Jonathan Le Roux", "John R. Hershey"], "https://doi.org/10.21437/Interspeech.2019-3038", 5], ["Survey Talk: Realistic Physics-Based Computational Voice Production.", ["Oriol Guasch"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs24.html", 0], ["An Extended Two-Dimensional Vocal Tract Model for Fast Acoustic Simulation of Single-Axis Symmetric Three-Dimensional Tubes.", ["Debasish Ray Mohapatra", "Victor Zappi", "Sidney S. Fels"], "https://doi.org/10.21437/Interspeech.2019-1764", 5], ["Perceptual Optimization of an Enhanced Geometric Vocal Fold Model for Articulatory Speech Synthesis.", ["Peter Birkholz", "Susanne Drechsel", "Simon Stone"], "https://doi.org/10.21437/Interspeech.2019-2410", 5], ["Articulatory Copy Synthesis Based on a Genetic Algorithm.", ["Yingming Gao", "Simon Stone", "Peter Birkholz"], "https://doi.org/10.21437/Interspeech.2019-1334", 5], ["A Phonetic-Level Analysis of Different Input Features for Articulatory Inversion.", ["Abdolreza Sabzi Shahrebabaki", "Negar Olfati", "Ali Shariq Imran", "Sabato Marco Siniscalchi", "Torbjorn Svendsen"], "https://doi.org/10.21437/Interspeech.2019-2526", 5], ["Advancing Sequence-to-Sequence Based Speech Recognition.", ["Zoltan Tuske", "Kartik Audhkhasi", "George Saon"], "https://doi.org/10.21437/Interspeech.2019-3018", 5], ["Sequence-to-Sequence Speech Recognition with Time-Depth Separable Convolutions.", ["Awni Hannun", "Ann Lee", "Qiantong Xu", "Ronan Collobert"], "https://doi.org/10.21437/Interspeech.2019-2460", 5], ["Semi-Supervised Sequence-to-Sequence ASR Using Unpaired Speech and Text.", ["Murali Karthick Baskar", "Shinji Watanabe", "Ramon Fernandez Astudillo", "Takaaki Hori", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-3167", 5], ["Learn Spelling from Teachers: Transferring Knowledge from Language Models to Sequence-to-Sequence Speech Recognition.", ["Ye Bai", "Jiangyan Yi", "Jianhua Tao", "Zhengkun Tian", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2019-1554", 5], ["On the Choice of Modeling Unit for Sequence-to-Sequence Speech Recognition.", ["Kazuki Irie", "Rohit Prabhavalkar", "Anjuli Kannan", "Antoine Bruguier", "David Rybach", "Patrick Nguyen"], "https://doi.org/10.21437/Interspeech.2019-2277", 5], ["Listen, Attend, Spell and Adapt: Speaker Adapted Sequence-to-Sequence ASR.", ["Felix Weninger", "Jesus Andres-Ferrer", "Xinwei Li", "Puming Zhan"], "https://doi.org/10.21437/Interspeech.2019-2719", 5], ["Lattice Re-Scoring During Manual Editing for Automatic Error Correction of ASR Transcripts.", ["Anna V. Runarsdottir", "Inga Run Helgadottir", "Jon Gudnason"], "https://doi.org/10.21437/Interspeech.2019-1790", 5], ["GPU-Based WFST Decoding with Extra Large Language Model.", ["Daisuke Fukunaga", "Yoshiki Tanaka", "Yuichi Kageyama"], "https://doi.org/10.21437/Interspeech.2019-2101", 5], ["Real-Time One-Pass Decoder for Speech Recognition Using LSTM Language Models.", ["Javier Jorge", "Adria Gimenez", "Javier Iranzo-Sanchez", "Jorge Civera", "Albert Sanchis", "Alfons Juan"], "https://doi.org/10.21437/Interspeech.2019-2798", 5], ["Vectorized Beam Search for CTC-Attention-Based Speech Recognition.", ["Hiroshi Seki", "Takaaki Hori", "Shinji Watanabe", "Niko Moritz", "Jonathan Le Roux"], "https://doi.org/10.21437/Interspeech.2019-2860", 5], ["Contextual Recovery of Out-of-Lattice Named Entities in Automatic Speech Recognition.", ["Jack Serrino", "Leonid Velikovich", "Petar S. Aleksic", "Cyril Allauzen"], "https://doi.org/10.21437/Interspeech.2019-2962", 5], ["Sequence-to-Sequence Learning via Attention Transfer for Incremental Speech Recognition.", ["Sashi Novitasari", "Andros Tjandra", "Sakriani Sakti", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2019-2985", 5], ["Unsupervised Representation Learning with Future Observation Prediction for Speech Emotion Recognition.", ["Zheng Lian", "Jianhua Tao", "Bin Liu", "Jian Huang"], "https://doi.org/10.21437/Interspeech.2019-1582", 5], ["Spatio-Temporal Attention Pooling for Audio Scene Classification.", ["Huy Phan", "Oliver Y. Chen", "Lam Pham", "Philipp Koch", "Maarten De Vos", "Ian Vince McLoughlin", "Alfred Mertins"], "https://doi.org/10.21437/Interspeech.2019-3040", 5], ["Subspace Pooling Based Temporal Features Extraction for Audio Event Recognition.", ["Qiuying Shi", "Hui Luo", "Jiqing Han"], "https://doi.org/10.21437/Interspeech.2019-2047", 5], ["Multi-Scale Time-Frequency Attention for Acoustic Event Detection.", ["Jingyang Zhang", "Wenhao Ding", "Jintao Kang", "Liang He"], "https://doi.org/10.21437/Interspeech.2019-1587", 5], ["Acoustic Scene Classification by Implicitly Identifying Distinct Sound Events.", ["Hongwei Song", "Jiqing Han", "Shiwen Deng", "Zhihao Du"], "https://doi.org/10.21437/Interspeech.2019-2231", 5], ["Parameter-Transfer Learning for Low-Resource Individualization of Head-Related Transfer Functions.", ["Xiaoke Qi", "Lu Wang"], "https://doi.org/10.21437/Interspeech.2019-2558", 5], ["Prosodic Characteristics of Mandarin Declarative and Interrogative Utterances in Parkinson's Disease.", ["Lei Liu", "Meng Jian", "Wentao Gu"], "https://doi.org/10.21437/Interspeech.2019-3276", 5], ["Study of the Performance of Automatic Speech Recognition Systems in Speakers with Parkinson's Disease.", ["Laureano Moro-Velazquez", "Jaejin Cho", "Shinji Watanabe", "Mark A. Hasegawa-Johnson", "Odette Scharenborg", "Heejin Kim", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2993", 5], ["Towards the Speech Features of Mild Cognitive Impairment: Universal Evidence from Structured and Unstructured Connected Speech of Chinese.", ["Tianqi Wang", "Chongyuan Lian", "Jingshen Pan", "Quanlei Yan", "Feiqi Zhu", "Manwa L. Ng", "Lan Wang", "Nan Yan"], "https://doi.org/10.21437/Interspeech.2019-2414", 5], ["Child Speech Disorder Detection with Siamese Recurrent Network Using Speech Attribute Features.", ["Jiarui Wang", "Ying Qin", "Zhiyuan Peng", "Tan Lee"], "https://doi.org/10.21437/Interspeech.2019-2320", 5], ["Interpretable Deep Learning Model for the Detection and Reconstruction of Dysarthric Speech.", ["Daniel Korzekwa", "Roberto Barra-Chicote", "Bozena Kostek", "Thomas Drugman", "Mateusz Lajszczak"], "https://doi.org/10.21437/Interspeech.2019-1206", 5], ["Vocal Biomarker Assessment Following Pediatric Traumatic Brain Injury: A Retrospective Cohort Study.", ["Camille Noufi", "Adam C. Lammert", "Daryush D. Mehta", "James R. Williamson", "Gregory Ciccarelli", "Douglas E. Sturim", "Jordan R. Green", "Thomas F. Campbell", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2019-1200", 5], ["Survey Talk: Reaching Over the Gap: Cross- and Interdisciplinary Research on Human and Automatic Speech Processing.", ["Odette Scharenborg"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs25.html", 0], ["Improved Deep Duel Model for Rescoring N-Best Speech Recognition List Using Backward LSTMLM and Ensemble Encoders.", ["Atsunori Ogawa", "Marc Delcroix", "Shigeki Karita", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2019-1949", 5], ["Language Modeling with Deep Transformers.", ["Kazuki Irie", "Albert Zeyer", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-2225", 5], ["Scalable Multi Corpora Neural Language Models for ASR.", ["Anirudh Raju", "Denis Filimonov", "Gautam Tiwari", "Guitang Lan", "Ariya Rastrow"], "https://doi.org/10.21437/Interspeech.2019-3060", 5], ["Who Needs Words? Lexicon-Free Speech Recognition.", ["Tatiana Likhomanenko", "Gabriel Synnaeve", "Ronan Collobert"], "https://doi.org/10.21437/Interspeech.2019-3107", 5], ["Direct Modelling of Speech Emotion from Raw Speech.", ["Siddique Latif", "Rajib Rana", "Sara Khalifa", "Raja Jurdak", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2019-3252", 5], ["Improving Emotion Identification Using Phone Posteriors in Raw Speech Waveform Based DNN.", ["Mousmita Sarma", "Pegah Ghahremani", "Daniel Povey", "Nagendra Kumar Goel", "Kandarpa Kumar Sarma", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2093", 5], ["Pyramid Memory Block and Timestep Attention for Speech Emotion Recognition.", ["Miao Cao", "Chun Yang", "Fang Zhou", "Xu-Cheng Yin"], "https://doi.org/10.21437/Interspeech.2019-3140", 5], ["Robust Speech Emotion Recognition Under Different Encoding Conditions.", ["Christopher Oates", "Andreas Triantafyllopoulos", "Ingmar Steiner", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1658", 5], ["Using the Bag-of-Audio-Word Feature Representation of ASR DNN Posteriors for Paralinguistic Classification.", ["Gabor Gosztolya"], "https://doi.org/10.21437/Interspeech.2019-1163", 5], ["Disentangling Style Factors from Speaker Representations.", ["Jennifer Williams", "Simon King"], "https://doi.org/10.21437/Interspeech.2019-1769", 5], ["Sentence Prosody and Wh-Indeterminates in Taiwan Mandarin.", ["Yu-Yin Hsu", "Anqi Xu"], "https://doi.org/10.21437/Interspeech.2019-2545", 5], ["Frication as a Vowel Feature? - Evidence from the Rui'an Wu Chinese Dialect.", ["Fang Hu", "Youjue He"], "https://doi.org/10.21437/Interspeech.2019-1134", 5], ["Vowels and Diphthongs in the Xupu Xiang Chinese Dialect.", ["Zhenrui Zhang", "Fang Hu"], "https://doi.org/10.21437/Interspeech.2019-1174", 5], ["Age-Related Changes in European Portuguese Vowel Acoustics.", ["Luciana Albuquerque", "Catarina Oliveira", "Antonio J. S. Teixeira", "Pedro Sa-Couto", "Daniela Figueiredo"], "https://doi.org/10.21437/Interspeech.2019-1818", 5], ["Vowel-Tone Interaction in Two Tibeto-Burman Languages.", ["Wendy Lalhminghlui", "Viyazonuo Terhiija", "Priyankoo Sarmah"], "https://doi.org/10.21437/Interspeech.2019-2808", 5], ["The Vowel System of Korebaju.", ["Jenifer Vega Rodriguez"], "https://doi.org/10.21437/Interspeech.2019-3210", 5], ["Fundamental Frequency Accommodation in Multi-Party Human-Robot Game Interactions: The Effect of Winning or Losing.", ["Omnia Ibrahim", "Gabriel Skantze", "Sabine Stoll", "Volker Dellwo"], "https://doi.org/10.21437/Interspeech.2019-2496", 5], ["Pitch Accent Trajectories Across Different Conditions of Visibility and Information Structure - Evidence from Spontaneous Dyadic Interaction.", ["Petra Wagner", "Nataliya Bryhadyr", "Marin Schroer"], "https://doi.org/10.21437/Interspeech.2019-1619", 5], ["The Greennn Tree - Lengthening Position Influences Uncertainty Perception.", ["Simon Betz", "Sina Zarriess", "Eva Szekely", "Petra Wagner"], "https://doi.org/10.21437/Interspeech.2019-2572", 5], ["CNN-BLSTM Based Question Detection from Dialogs Considering Phase and Context Information.", ["Yuke Si", "Longbiao Wang", "Jianwu Dang", "Mengfei Wu", "Aijun Li"], "https://doi.org/10.21437/Interspeech.2019-1701", 5], ["Mirroring to Build Trust in Digital Assistants.", ["Katherine Metcalf", "Barry-John Theobald", "Garrett Weinberg", "Robert Lee", "Ing-Marie Jonsson", "Russ Webb", "Nicholas Apostoloff"], "https://doi.org/10.21437/Interspeech.2019-1829", 5], ["Three's a Crowd? Effects of a Second Human on Vocal Accommodation with a Voice Assistant.", ["Eran Raveh", "Ingo Siegert", "Ingmar Steiner", "Iona Gessinger", "Bernd Mobius"], "https://doi.org/10.21437/Interspeech.2019-1825", 5], ["Adversarial Regularization for End-to-End Robust Speaker Verification.", ["Qing Wang", "Pengcheng Guo", "Sining Sun", "Lei Xie", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-2983", 5], ["Combining Speaker Recognition and Metric Learning for Speaker-Dependent Representation Learning.", ["Joao Monteiro", "Md. Jahangir Alam", "Tiago H. Falk"], "https://doi.org/10.21437/Interspeech.2019-2974", 5], ["VAE-Based Regularization for Deep Speaker Embedding.", ["Yang Zhang", "Lantian Li", "Dong Wang"], "https://doi.org/10.21437/Interspeech.2019-2486", 5], ["Language Recognition Using Triplet Neural Networks.", ["Victoria Mingote", "Diego Castan", "Mitchell McLaren", "Mahesh Kumar Nandwana", "Alfonso Ortega Gimenez", "Eduardo Lleida", "Antonio Miguel"], "https://doi.org/10.21437/Interspeech.2019-2437", 5], ["Spatial Pyramid Encoding with Convex Length Normalization for Text-Independent Speaker Verification.", ["Youngmoon Jung", "Younggwan Kim", "Hyungjun Lim", "Yeunju Choi", "Hoirin Kim"], "https://doi.org/10.21437/Interspeech.2019-2177", 5], ["End-to-End Losses Based on Speaker Basis Vectors and All-Speaker Hard Negative Mining for Speaker Verification.", ["Hee-Soo Heo", "Jee-weon Jung", "Il-Ho Yang", "Sung-Hyun Yoon", "Hye-jin Shim", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1986", 5], ["An Effective Deep Embedding Learning Architecture for Speaker Verification.", ["Yiheng Jiang", "Yan Song", "Ian McLoughlin", "Zhifu Gao", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2019-1606", 5], ["Far-Field End-to-End Text-Dependent Speaker Verification Based on Mixed Training Data with Transfer Learning and Enrollment Data Augmentation.", ["Xiaoyi Qin", "Danwei Cai", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1542", 5], ["Two-Stage Training for Chinese Dialect Recognition.", ["Zongze Ren", "Guofu Yang", "Shugong Xu"], "https://doi.org/10.21437/Interspeech.2019-1522", 5], ["Investigation on Blind Bandwidth Extension with a Non-Linear Function and its Evaluation of x-Vector-Based Speaker Verification.", ["Ryota Kaminishi", "Haruna Miyamoto", "Sayaka Shiota", "Hitoshi Kiya"], "https://doi.org/10.21437/Interspeech.2019-1510", 5], ["Auto-Encoding Nearest Neighbor i-Vectors for Speaker Verification.", ["Umair Khan", "Miquel India", "Javier Hernando"], "https://doi.org/10.21437/Interspeech.2019-1444", 5], ["Towards a Fault-Tolerant Speaker Verification System: A Regularization Approach to Reduce the Condition Number.", ["Siqi Zheng", "Gang Liu", "Hongbin Suo", "Yun Lei"], "https://doi.org/10.21437/Interspeech.2019-1442", 5], ["Deep Learning Based Multi-Channel Speaker Recognition in Noisy and Reverberant Environments.", ["Hassan Taherian", "Zhong-Qiu Wang", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2019-1428", 5], ["Joint Optimization of Neural Acoustic Beamforming and Dereverberation with x-Vectors for Robust Speaker Verification.", ["Joon-Young Yang", "Joon-Hyuk Chang"], "https://doi.org/10.21437/Interspeech.2019-1356", 5], ["A New Time-Frequency Attention Mechanism for TDNN and CNN-LSTM-TDNN, with Application to Language Identification.", ["Xiaoxiao Miao", "Ian McLoughlin", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-1256", 5], ["An Attention-Based Hybrid Network for Automatic Detection of Alzheimer's Disease from Narrative Speech.", ["Jun Chen", "Ji Zhu", "Jieping Ye"], "https://doi.org/10.21437/Interspeech.2019-2872", 5], ["Investigating the Lombard Effect Influence on End-to-End Audio-Visual Speech Recognition.", ["Pingchuan Ma", "Stavros Petridis", "Maja Pantic"], "https://doi.org/10.21437/Interspeech.2019-2726", 5], ["\"Computer, Test My Hearing\": Accurate Speech Audiometry with Smart Speakers.", ["Jasper Ooster", "Pia Nancy Porysek Moreta", "Jorg-Hendrik Bach", "Inga Holube", "Bernd T. Meyer"], "https://doi.org/10.21437/Interspeech.2019-2118", 5], ["Synchronising Audio and Ultrasound by Learning Cross-Modal Embeddings.", ["Aciel Eshky", "Manuel Sam Ribeiro", "Korin Richmond", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2019-1804", 5], ["Automatic Hierarchical Attention Neural Network for Detecting AD.", ["Yilin Pan", "Bahman Mirheidari", "Markus Reuber", "Annalena Venneri", "Daniel Blackburn", "Heidi Christensen"], "https://doi.org/10.21437/Interspeech.2019-1799", 5], ["Deep Sensing of Breathing Signal During Conversational Speech.", ["Venkata Srikanth Nallanthighal", "Aki Harma", "Helmer Strik"], "https://doi.org/10.21437/Interspeech.2019-1796", 5], ["Parrotron: An End-to-End Speech-to-Speech Conversion Model and its Applications to Hearing-Impaired Speech and Speech Separation.", ["Fadi Biadsy", "Ron J. Weiss", "Pedro J. Moreno", "Dimitri Kanvesky", "Ye Jia"], "https://doi.org/10.21437/Interspeech.2019-1789", 5], ["Exploiting Visual Features Using Bayesian Gated Neural Networks for Disordered Speech Recognition.", ["Shansong Liu", "Shoukang Hu", "Yi Wang", "Jianwei Yu", "Rongfeng Su", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1536", 5], ["Video-Driven Speech Reconstruction Using Generative Adversarial Networks.", ["Konstantinos Vougioukas", "Pingchuan Ma", "Stavros Petridis", "Maja Pantic"], "https://doi.org/10.21437/Interspeech.2019-1445", 5], ["On the Use of Pitch Features for Disordered Speech Recognition.", ["Shansong Liu", "Shoukang Hu", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2609", 5], ["Large-Scale Visual Speech Recognition.", ["Brendan Shillingford", "Yannis M. Assael", "Matthew W. Hoffman", "Thomas Paine", "Cian Hughes", "Utsav Prabhu", "Hank Liao", "Hasim Sak", "Kanishka Rao", "Lorrayne Bennett", "Marie Mulville", "Misha Denil", "Ben Coppin", "Ben Laurie", "Andrew W. Senior", "Nando de Freitas"], "https://doi.org/10.21437/Interspeech.2019-1669", 5], ["Investigating Linguistic and Semantic Features for Turn-Taking Prediction in Open-Domain Human-Computer Conversation.", ["Seyedeh Zahra Razavi", "Benjamin Kane", "Lenhart K. Schubert"], "https://doi.org/10.21437/Interspeech.2019-3152", 5], ["Benchmarking Benchmarks: Introducing New Automatic Indicators for Benchmarking Spoken Language Understanding Corpora.", ["Frederic Bechet", "Christian Raymond"], "https://doi.org/10.21437/Interspeech.2019-3033", 5], ["A Neural Turn-Taking Model without RNN.", ["Chaoran Liu", "Carlos Toshinori Ishi", "Hiroshi Ishiguro"], "https://doi.org/10.21437/Interspeech.2019-2270", 5], ["An Incremental Turn-Taking Model for Task-Oriented Dialog Systems.", ["Andrei C. Coman", "Koichiro Yoshino", "Yukitoshi Murase", "Satoshi Nakamura", "Giuseppe Riccardi"], "https://doi.org/10.21437/Interspeech.2019-1826", 5], ["Personalized Dialogue Response Generation Learned from Monologues.", ["Feng-Guang Su", "Aliyah R. Hsu", "Yi-Lin Tuan", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2019-1696", 5], ["Voice Quality as a Turn-Taking Cue.", ["Mattias Heldner", "Marcin Wlodarczak", "Stefan Benus", "Agustin Gravano"], "https://doi.org/10.21437/Interspeech.2019-1592", 5], ["Turn-Taking Prediction Based on Detection of Transition Relevance Place.", ["Kohei Hara", "Koji Inoue", "Katsuya Takanashi", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2019-1537", 5], ["Analysis of Effect and Timing of Fillers in Natural Turn-Taking.", ["Divesh Lala", "Shizuka Nakamura", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2019-1527", 5], ["Multimodal Response Obligation Detection with Unsupervised Online Domain Adaptation.", ["Shota Horiguchi", "Naoyuki Kanda", "Kenji Nagamatsu"], "https://doi.org/10.21437/Interspeech.2019-1313", 5], ["Follow-Up Question Generation Using Neural Tensor Network-Based Domain Ontology Population in an Interview Coaching System.", ["Ming-Hsiang Su", "Chung-Hsien Wu", "Yi Chang"], "https://doi.org/10.21437/Interspeech.2019-1300", 5], ["On the Role of Style in Parsing Speech with Neural Models.", ["Trang Tran", "Jiahong Yuan", "Yang Liu", "Mari Ostendorf"], "https://doi.org/10.21437/Interspeech.2019-3122", 5], ["On the Contributions of Visual and Textual Supervision in Low-Resource Semantic Speech Retrieval.", ["Ankita Pasad", "Bowen Shi", "Herman Kamper", "Karen Livescu"], "https://doi.org/10.21437/Interspeech.2019-3051", 5], ["Automatic Detection of Off-Topic Spoken Responses Using Very Deep Convolutional Neural Networks.", ["Xinhao Wang", "Su-Youn Yoon", "Keelan Evanini", "Klaus Zechner", "Yao Qian"], "https://doi.org/10.21437/Interspeech.2019-1848", 5], ["Rescoring Keyword Search Confidence Estimates with Graph-Based Re-Ranking Using Acoustic Word Embeddings.", ["Anna Piunova", "Eugen Beck", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-1817", 5], ["SpeechYOLO: Detection and Localization of Speech Objects.", ["Yael Segal", "Tzeviya Sylvia Fuchs", "Joseph Keshet"], "https://doi.org/10.21437/Interspeech.2019-1749", 5], ["Prosodic Phrase Alignment for Machine Dubbing.", ["Alp Oktem", "Mireia Farrus", "Antonio Bonafonte"], "https://doi.org/10.21437/Interspeech.2019-1621", 5], ["Spot the Pleasant People! Navigating the Cocktail Party Buzz.", ["Christina Tannander", "Per Fallgren", "Jens Edlund", "Joakim Gusafsson"], "https://doi.org/10.21437/Interspeech.2019-1553", 5], ["Neural Text Clustering with Document-Level Attention Based on Dynamic Soft Labels.", ["Zhi Chen", "Wu Guo", "Li-Rong Dai", "Zhen-Hua Ling", "Jun Du"], "https://doi.org/10.21437/Interspeech.2019-1417", 5], ["Noisy BiLSTM-Based Models for Disfluency Detection.", ["Nguyen Bach", "Fei Huang"], "https://doi.org/10.21437/Interspeech.2019-1336", 5], ["Subword RNNLM Approximations for Out-Of-Vocabulary Keyword Search.", ["Mittul Singh", "Sami Virpioja", "Peter Smit", "Mikko Kurimo"], "https://doi.org/10.21437/Interspeech.2019-1329", 5], ["Simultaneous Detection and Localization of a Wake-Up Word Using Multi-Task Learning of the Duration and Endpoint.", ["Takashi Maekaku", "Yusuke Kida", "Akihiko Sugiyama"], "https://doi.org/10.21437/Interspeech.2019-1180", 5], ["On Mitigating Acoustic Feedback in Hearing Aids with Frequency Warping by All-Pass Networks.", ["Ching Hua Lee", "Kuan-Lin Chen", "Fredric J. Harris", "Bhaskar D. Rao", "Harinath Garudadri"], "https://doi.org/10.21437/Interspeech.2019-3195", 5], ["Deep Multitask Acoustic Echo Cancellation.", ["Amin Fazel", "Mostafa El-Khamy", "Jungwon Lee"], "https://doi.org/10.21437/Interspeech.2019-2908", 5], ["Deep Learning for Joint Acoustic Echo and Noise Cancellation with Nonlinear Distortions.", ["Hao Zhang", "Ke Tan", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2019-2651", 5], ["Harmonic Beamformers for Non-Intrusive Speech Intelligibility Prediction.", ["Charlotte Sorensen", "Jesper Bunsow Boldt", "Mads Graesboll Christensen"], "https://doi.org/10.21437/Interspeech.2019-2929", 5], ["Convolutional Neural Network-Based Speech Enhancement for Cochlear Implant Recipients.", ["Nursadul Mamun", "Soheil Khorram", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-1850", 5], ["Validation of the Non-Intrusive Codebook-Based Short Time Objective Intelligibility Metric for Processed Speech.", ["Charlotte Sorensen", "Jesper B. Boldt", "Mads G. Christensen"], "https://doi.org/10.21437/Interspeech.2019-1625", 5], ["Predicting Speech Intelligibility of Enhanced Speech Using Phone Accuracy of DNN-Based ASR System.", ["Kenichi Arai", "Shoko Araki", "Atsunori Ogawa", "Keisuke Kinoshita", "Tomohiro Nakatani", "Katsuhiko Yamamoto", "Toshio Irino"], "https://doi.org/10.21437/Interspeech.2019-1381", 5], ["A Novel Method to Correct Steering Vectors in MVDR Beamformer for Noise Robust ASR.", ["Suliang Bu", "Yunxin Zhao", "Mei-Yuh Hwang"], "https://doi.org/10.21437/Interspeech.2019-2944", 5], ["End-to-End Multi-Channel Speech Enhancement Using Inter-Channel Time-Restricted Attention on Raw Waveform.", ["Hyeon Seung Lee", "Hyung Yong Kim", "Woo Hyun Kang", "Jeunghun Kim", "Nam Soo Kim"], "https://doi.org/10.21437/Interspeech.2019-2397", 5], ["Neural Spatial Filter: Target Speaker Speech Separation Assisted with Directional Information.", ["Rongzhi Gu", "Lianwu Chen", "Shi-Xiong Zhang", "Jimeng Zheng", "Yong Xu", "Meng Yu", "Dan Su", "Yuexian Zou", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-2266", 5], ["My Lips Are Concealed: Audio-Visual Speech Enhancement Through Obstructions.", ["Triantafyllos Afouras", "Joon Son Chung", "Andrew Zisserman"], "https://doi.org/10.21437/Interspeech.2019-3114", 5], ["End-to-End Neural Speaker Diarization with Permutation-Free Objectives.", ["Yusuke Fujita", "Naoyuki Kanda", "Shota Horiguchi", "Kenji Nagamatsu", "Shinji Watanabe"], "https://doi.org/10.21437/Interspeech.2019-2899", 5], ["Self Multi-Head Attention for Speaker Recognition.", ["Miquel India", "Pooyan Safari", "Javier Hernando"], "https://doi.org/10.21437/Interspeech.2019-2616", 5], ["Phonetically-Aware Embeddings, Wide Residual Networks with Time-Delay Neural Networks and Self Attention Models for the 2018 NIST Speaker Recognition Evaluation.", ["Ignacio Vinals", "Dayana Ribas", "Victoria Mingote", "Jorge Llombart", "Pablo Gimeno", "Antonio Miguel", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-2417", 5], ["Variational Domain Adversarial Learning for Speaker Verification.", ["Youzhi Tu", "Man-Wai Mak", "Jen-Tzung Chien"], "https://doi.org/10.21437/Interspeech.2019-2168", 5], ["A Unified Framework for Speaker and Utterance Verification.", ["Tianchi Liu", "Maulik C. Madhavi", "Rohan Kumar Das", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1994", 5], ["Analysis of Critical Metadata Factors for the Calibration of Speaker Recognition Systems.", ["Mahesh Kumar Nandwana", "Luciana Ferrer", "Mitchell McLaren", "Diego Castan", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2019-1808", 5], ["Factorization of Discriminatively Trained i-Vector Extractor for Speaker Recognition.", ["Ondrej Novotny", "Oldrich Plchot", "Ondrej Glembek", "Lukas Burget"], "https://doi.org/10.21437/Interspeech.2019-1757", 5], ["End-to-End Speaker Identification in Noisy and Reverberant Environments Using Raw Waveform Convolutional Neural Networks.", ["Daniele Salvati", "Carlo Drioli", "Gian Luca Foresti"], "https://doi.org/10.21437/Interspeech.2019-2403", 5], ["Whisper to Neutral Mapping Using Cosine Similarity Maximization in i-Vector Space for Speaker Verification.", ["Abinay Reddy Naini", "Achuth Rao M. V", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2280", 5], ["Mixup Learning Strategies for Text-Independent Speaker Verification.", ["Yingke Zhu", "Tom Ko", "Brian Mak"], "https://doi.org/10.21437/Interspeech.2019-2250", 5], ["Optimizing a Speaker Embedding Extractor Through Backend-Driven Regularization.", ["Luciana Ferrer", "Mitchell McLaren"], "https://doi.org/10.21437/Interspeech.2019-1820", 5], ["The NEC-TT 2018 Speaker Verification System.", ["Kong Aik Lee", "Hitoshi Yamamoto", "Koji Okabe", "Qiongqiong Wang", "Ling Guo", "Takafumi Koshinaka", "Jiacen Zhang", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2019-1517", 5], ["Autoencoder-Based Semi-Supervised Curriculum Learning for Out-of-Domain Speaker Verification.", ["Siqi Zheng", "Gang Liu", "Hongbin Suo", "Yun Lei"], "https://doi.org/10.21437/Interspeech.2019-1440", 5], ["Multi-Channel Training for End-to-End Speaker Recognition Under Reverberant and Noisy Environment.", ["Danwei Cai", "Xiaoyi Qin", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1437", 5], ["The DKU-SMIIP System for NIST 2018 Speaker Recognition Evaluation.", ["Danwei Cai", "Weicheng Cai", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1436", 5], ["Pretraining by Backtranslation for End-to-End ASR in Low-Resource Settings.", ["Matthew Wiesner", "Adithya Renduchintala", "Shinji Watanabe", "Chunxi Liu", "Najim Dehak", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-3254", 5], ["Cross-Attention End-to-End ASR for Two-Party Conversations.", ["Suyoun Kim", "Siddharth Dalmia", "Florian Metze"], "https://doi.org/10.21437/Interspeech.2019-3173", 5], ["Towards Using Context-Dependent Symbols in CTC Without State-Tying Decision Trees.", ["Jan Chorowski", "Adrian Lancucki", "Bartosz Kostka", "Michal Zapotoczny"], "https://doi.org/10.21437/Interspeech.2019-2720", 5], ["An Online Attention-Based Model for Speech Recognition.", ["Ruchao Fan", "Pan Zhou", "Wei Chen", "Jia Jia", "Gang Liu"], "https://doi.org/10.21437/Interspeech.2019-2218", 5], ["Self-Attention Transducers for End-to-End Speech Recognition.", ["Zhengkun Tian", "Jiangyan Yi", "Jianhua Tao", "Ye Bai", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2019-2203", 5], ["Improving Transformer-Based Speech Recognition Systems with Compressed Structure and Speech Attributes Augmentation.", ["Sheng Li", "Dabre Raj", "Xugang Lu", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2112", 5], ["Extending an Acoustic Data-Driven Phone Set for Spontaneous Speech Recognition.", ["Jeong-Uk Bang", "Mu-Yeol Choi", "Sang-Hun Kim", "Oh-Wook Kwon"], "https://doi.org/10.21437/Interspeech.2019-1979", 5], ["Joint Maximization Decoder with Neural Converters for Fully Neural Network-Based Japanese Speech Recognition.", ["Takafumi Moriya", "Jian Wang", "Tomohiro Tanaka", "Ryo Masumura", "Yusuke Shinohara", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-1558", 5], ["Real to H-Space Encoder for Speech Recognition.", ["Titouan Parcollet", "Mohamed Morchid", "Georges Linares", "Renato De Mori"], "https://doi.org/10.21437/Interspeech.2019-1539", 5], ["Ectc-Docd: An End-to-End Structure with CTC Encoder and OCD Decoder for Speech Recognition.", ["Cheng Yi", "Feng Wang", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2019-1212", 5], ["End-to-End Multi-Speaker Speech Recognition Using Speaker Embeddings and Transfer Learning.", ["Pavel Denisov", "Ngoc Thang Vu"], "https://doi.org/10.21437/Interspeech.2019-1130", 5], ["Pre-Trained Text Embeddings for Enhanced Text-to-Speech Synthesis.", ["Tomoki Hayashi", "Shinji Watanabe", "Tomoki Toda", "Kazuya Takeda", "Shubham Toshniwal", "Karen Livescu"], "https://doi.org/10.21437/Interspeech.2019-3177", 5], ["Spontaneous Conversational Speech Synthesis from Found Data.", ["Eva Szekely", "Gustav Eje Henter", "Jonas Beskow", "Joakim Gustafson"], "https://doi.org/10.21437/Interspeech.2019-2836", 5], ["Fine-Grained Robust Prosody Transfer for Single-Speaker Neural Text-To-Speech.", ["Viacheslav Klimkov", "Srikanth Ronanki", "Jonas Rohnke", "Thomas Drugman"], "https://doi.org/10.21437/Interspeech.2019-2571", 5], ["Speech Driven Backchannel Generation Using Deep Q-Network for Enhancing Engagement in Human-Robot Interaction.", ["Nusrah Hussain", "Engin Erzin", "T. Metin Sezgin", "Yucel Yemez"], "https://doi.org/10.21437/Interspeech.2019-2521", 5], ["Semi-Supervised Prosody Modeling Using Deep Gaussian Process Latent Variable Model.", ["Tomoki Koriyama", "Takao Kobayashi"], "https://doi.org/10.21437/Interspeech.2019-2497", 5], ["Bootstrapping a Text Normalization System for an Inflected Language. Numbers as a Test Case.", ["Anna Bjork Nikulasdottir", "Jon Gudnason"], "https://doi.org/10.21437/Interspeech.2019-2367", 5], ["Exploiting Syntactic Features in a Parsed Tree to Improve End-to-End TTS.", ["Haohan Guo", "Frank K. Soong", "Lei He", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2019-2167", 5], ["Duration Modeling with Global Phoneme-Duration Vectors.", ["Jinfu Ni", "Yoshinori Shiga", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2126", 5], ["Improving Speech Synthesis with Discourse Relations.", ["Adele Aubin", "Alessandra Cervone", "Oliver Watts", "Simon King"], "https://doi.org/10.21437/Interspeech.2019-1945", 5], ["Visualization and Interpretation of Latent Spaces for Controlling Expressive Speech Synthesis Through Audio Analysis.", ["Noe Tits", "Fengna Wang", "Kevin El Haddad", "Vincent Pagel", "Thierry Dutoit"], "https://doi.org/10.21437/Interspeech.2019-1426", 5], ["Pre-Trained Text Representations for Improving Front-End Text Processing in Mandarin Text-to-Speech Synthesis.", ["Bing Yang", "Jiaqi Zhong", "Shan Liu"], "https://doi.org/10.21437/Interspeech.2019-1418", 5], ["A Mandarin Prosodic Boundary Prediction Model Based on Multi-Task Learning.", ["Huashan Pan", "Xiulin Li", "Zhiqiang Huang"], "https://doi.org/10.21437/Interspeech.2019-1400", 4], ["Dual Encoder Classifier Models as Constraints in Neural Text Normalization.", ["Ajda Gokcen", "Hao Zhang", "Richard Sproat"], "https://doi.org/10.21437/Interspeech.2019-1135", 5], ["Knowledge-Based Linguistic Encoding for End-to-End Mandarin Text-to-Speech Synthesis.", ["Jingbei Li", "Zhiyong Wu", "Runnan Li", "Pengpeng Zhi", "Song Yang", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1118", 5], ["Automated Emotion Morphing in Speech Based on Diffeomorphic Curve Registration and Highway Networks.", ["Ravi Shankar", "Hsi-Wei Hsieh", "Nicolas Charon", "Archana Venkataraman"], "https://doi.org/10.21437/Interspeech.2019-2386", 5], ["Use of Beiwe Smartphone App to Identify and Track Speech Decline in Amyotrophic Lateral Sclerosis (ALS).", ["Kathryn P. Connaghan", "Jordan R. Green", "Sabrina Paganoni", "James Chan", "Harli Weber", "Ella Collins", "Brian Richburg", "Marziye Eshghi", "Jukka-Pekka Onnela", "James D. Berry"], "https://doi.org/10.21437/Interspeech.2019-3126", 5], ["Profiling Speech Motor Impairments in Persons with Amyotrophic Lateral Sclerosis: An Acoustic-Based Approach.", ["Hannah P. Rowe", "Jordan R. Green"], "https://doi.org/10.21437/Interspeech.2019-2911", 5], ["Diagnosing Dysarthria with Long Short-Term Memory Networks.", ["Alex Mayle", "Zhiwei Mou", "Razvan C. Bunescu", "Sadegh Mirshekarian", "Li Xu", "Chang Liu"], "https://doi.org/10.21437/Interspeech.2019-2903", 5], ["Modification of Devoicing Error in Cleft Lip and Palate Speech.", ["Protima Nomo Sudro", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2019-2604", 5], ["Reduced Task Adaptation in Alternating Motion Rate Tasks as an Early Marker of Bulbar Involvement in Amyotrophic Lateral Sclerosis.", ["Marziye Eshghi", "Panying Rong", "Antje S. Mefferd", "Kaila L. Stipancic", "Yana Yunusova", "Jordan R. Green"], "https://doi.org/10.21437/Interspeech.2019-2546", 5], ["Towards the Speech Features of Early-Stage Dementia: Design and Application of the Mandarin Elderly Cognitive Speech Database.", ["Tianqi Wang", "Quanlei Yan", "Jingshen Pan", "Feiqi Zhu", "Rongfeng Su", "Yi Guo", "Lan Wang", "Nan Yan"], "https://doi.org/10.21437/Interspeech.2019-2453", 5], ["Acoustic Characteristics of Lexical Tone Disruption in Mandarin Speakers After Brain Damage.", ["Wenjun Chen", "Jeroen van de Weijer", "Shuangshuang Zhu", "Qian Qian", "Manna Wang"], "https://doi.org/10.21437/Interspeech.2019-2432", 5], ["Intragestural Variation in Natural Sentence Production: Essential Tremor Patients Treated with DBS.", ["Anne Hermes", "Doris Mucke", "Tabea Thies", "Michael T. Barbe"], "https://doi.org/10.21437/Interspeech.2019-2389", 5], ["Nasal Air Emission in Sibilant Fricatives of Cleft Lip and Palate Speech.", ["Sishir Kalita", "Protima Nomo Sudro", "S. R. Mahadeva Prasanna", "Samarendra Dandapat"], "https://doi.org/10.21437/Interspeech.2019-2345", 5], ["Parallel vs. Non-Parallel Voice Conversion for Esophageal Speech.", ["Luis Serrano", "Sneha Raman", "David Tavarez", "Eva Navas", "Inma Hernaez"], "https://doi.org/10.21437/Interspeech.2019-2194", 5], ["Hypernasality Severity Detection Using Constant Q Cepstral Coefficients.", ["Akhilesh Kumar Dubey", "S. R. Mahadeva Prasanna", "S. Dandapat"], "https://doi.org/10.21437/Interspeech.2019-2151", 5], ["Automatic Depression Level Detection via \u2113p-Norm Pooling.", ["Mingyue Niu", "Jianhua Tao", "Bin Liu", "Cunhang Fan"], "https://doi.org/10.21437/Interspeech.2019-1617", 5], ["Comparison of Speech Tasks and Recording Devices for Voice Based Automatic Classification of Healthy Subjects and Patients with Amyotrophic Lateral Sclerosis.", ["Suhas B. N.", "Deep Patel", "Nithin Rao Koluguri", "Yamini Belur", "Pradeep Reddy", "Atchayaram Nalini", "Ravi Yadav", "Dipanjan Gope", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-1285", 5], ["A Modified Algorithm for Multiple Input Spectrogram Inversion.", ["Dongxiao Wang", "Hirokazu Kameoka", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2019-3242", 5], ["A Comprehensive Study of Speech Separation: Spectrogram vs Waveform Separation.", ["Fahimeh Bahmaninezhad", "Jian Wu", "Rongzhi Gu", "Shi-Xiong Zhang", "Yong Xu", "Meng Yu", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-3181", 5], ["Evaluating Audiovisual Source Separation in the Context of Video Conferencing.", ["Berkay Inan", "Milos Cernak", "Helmut Grabner", "Helena Peic Tukuljac", "Rodrigo C. G. Pena", "Benjamin Ricaud"], "https://doi.org/10.21437/Interspeech.2019-2671", 5], ["Influence of Speaker-Specific Parameters on Speech Separation Systems.", ["David Ditter", "Timo Gerkmann"], "https://doi.org/10.21437/Interspeech.2019-2459", 5], ["CNN-LSTM Models for Multi-Speaker Source Separation Using Bayesian Hyper Parameter Optimization.", ["Jeroen Zegers", "Hugo Van hamme"], "https://doi.org/10.21437/Interspeech.2019-2423", 5], ["Towards Joint Sound Scene and Polyphonic Sound Event Recognition.", ["Helen L. Bear", "Ines Nolasco", "Emmanouil Benetos"], "https://doi.org/10.21437/Interspeech.2019-2169", 5], ["Discriminative Learning for Monaural Speech Separation Using Deep Embedding Features.", ["Cunhang Fan", "Bin Liu", "Jianhua Tao", "Jiangyan Yi", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2019-1940", 5], ["Probabilistic Permutation Invariant Training for Speech Separation.", ["Midia Yousefi", "Soheil Khorram", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-1827", 5], ["Which Ones Are Speaking? Speaker-Inferred Model for Multi-Talker Speech Separation.", ["Jing Shi", "Jiaming Xu", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2019-1591", 5], ["End-to-End Monaural Speech Separation with Multi-Scale Dynamic Weighted Gated Dilated Convolutional Pyramid Network.", ["Ziqiang Shi", "Huibin Lin", "Liu Liu", "Rujie Liu", "Shoji Hayakawa", "Shouji Harada", "Jiqing Han"], "https://doi.org/10.21437/Interspeech.2019-1292", 5], ["End-to-End Music Source Separation: Is it Possible in the Waveform Domain?", ["Francesc Lluis", "Jordi Pons", "Xavier Serra"], "https://doi.org/10.21437/Interspeech.2019-1177", 5], ["Elpis, an Accessible Speech-to-Text Tool.", ["Ben Foley", "Alina Rakhi", "Nicholas Lambourne", "Nicholas Buckeridge", "Janet Wiles"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8006.html", 2], ["Framework for Conducting Tasks Requiring Human Assessment.", ["Martin Gruber", "Adam Chylek", "Jindrich Matousek"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8009.html", 2], ["Multimedia Simultaneous Translation System for Minority Language Communication with Mandarin.", ["Shen Huang", "Bojie Hu", "Shan Huang", "Pengfei Hu", "Jian Kang", "Zhiqiang Lv", "Jinghao Yan", "Qi Ju", "Shiyin Kang", "Deyi Tuo", "Guangzhi Li", "Nurmemet Yolwas"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8020.html", 2], ["The SAIL LABS Media Mining Indexer and the CAVA Framework.", ["Erinc Dikici", "Gerhard Backfried", "Jurgen Riedler"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8029.html", 2], ["CaptionAI: A Real-Time Multilingual Captioning Application.", ["Nagendra Kumar Goel", "Mousmita Sarma", "Saikiran Valluri", "Dharmeshkumar Agrawal", "Steve Braich", "Tejendra Singh Kuswah", "Zikra Iqbal", "Surbhi Chauhan", "Raj Karbar"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8039.html", 2]]